#!/usr/bin/env python3
"""
æµå¼æ•°æ®è½¬æ¢è„šæœ¬

å°†åŸå§‹æµ‹è¯•æ•°æ®ä¸­çš„æµå¼markdownç‰‡æ®µåˆå¹¶ä¸ºå®Œæ•´å“åº”ï¼Œ
ç”Ÿæˆåˆå¹¶åçš„æµ‹è¯•æ•°æ®æ–‡ä»¶ã€‚

æ”¯æŒå‘½ä»¤è¡Œå‚æ•°:
--input: è¾“å…¥æ–‡ä»¶è·¯å¾„
--output: è¾“å‡ºæ–‡ä»¶è·¯å¾„
--timestamp: æ—¶é—´æˆ³(å¯é€‰)

è¾“å…¥: test_results_all_44_20260119_195143-qwen.json
è¾“å‡º: test_results_merged_20260119_195143.json

Usage:
    python convert_stream_data.py --input input.json --output output.json
    python convert_stream_data.py --input input.json  # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
"""

import json
import sys
import argparse
from datetime import datetime
from collections import defaultdict


def merge_consecutive_markdown(raw_data):
    """
    åˆå¹¶è¿ç»­çš„markdownæ•°æ®

    åˆå¹¶è§„åˆ™ï¼š
    1. åªåˆå¹¶è¿ç»­çš„ã€å…·æœ‰ç›¸åŒmessage_idçš„markdownç‰‡æ®µ
    2. è¢«toolã€cardç­‰åˆ†éš”ç¬¦éš”å¼€çš„markdownç‰‡æ®µä¸ä¼šè¢«åˆå¹¶
    3. åªåˆå¹¶contentå­—æ®µï¼Œå…¶ä»–å­—æ®µä¿æŒç¬¬ä¸€ä¸ªç‰‡æ®µçš„å€¼

    Args:
        raw_data: åŸå§‹æ•°æ®åˆ—è¡¨

    Returns:
        åˆå¹¶åçš„æ•°æ®åˆ—è¡¨
    """
    if not raw_data:
        return raw_data

    print(f"    åŸå§‹æ•°æ®æ¡æ•°: {len(raw_data)}")

    # æŒ‰timestampæ’åº
    try:
        sorted_data = sorted(raw_data, key=lambda x: x.get('timestamp', 0))
    except:
        sorted_data = raw_data

    merged_data = []
    i = 0
    markdown_merge_count = 0

    # ç»Ÿè®¡å„ç§ç±»å‹çš„æ•°é‡
    task_id_count = sum(1 for item in sorted_data if item.get('type') == 'task_id')
    markdown_count = sum(1 for item in sorted_data if item.get('role') == 'assistant' and item.get('type') == 'markdown')
    tool_count = sum(1 for item in sorted_data if (item.get('type') == 'tool') or (item.get('role') == 'assistant' and item.get('type') == 'tool'))
    card_count = sum(1 for item in sorted_data if item.get('type') == 'card')

    print(f"    ç»Ÿè®¡ä¿¡æ¯:")
    print(f"      - task_id: {task_id_count}")
    print(f"      - markdown: {markdown_count}")
    print(f"      - tool: {tool_count}")
    print(f"      - card: {card_count}")

    while i < len(sorted_data):
        current_item = sorted_data[i]

        # æ£€æŸ¥æ˜¯å¦æ˜¯markdownç‰‡æ®µ
        if (current_item.get('role') == 'assistant' and
            current_item.get('type') == 'markdown'):

            current_message_id = current_item.get('message_id', '')

            # æ‰¾åˆ°æ‰€æœ‰å…·æœ‰ç›¸åŒmessage_idä¸”è¿ç»­çš„markdownç‰‡æ®µ
            # é‡åˆ°toolã€cardæˆ–å…¶ä»–émarkdowné¡¹æ—¶åœæ­¢
            markdown_group = [current_item]
            j = i + 1

            while j < len(sorted_data):
                next_item = sorted_data[j]
                # æ£€æŸ¥æ˜¯å¦æ˜¯è¿ç»­ä¸”å…·æœ‰ç›¸åŒmessage_idçš„markdownç‰‡æ®µ
                # åªå…è®¸è¿ç»­çš„markdownï¼Œä¸­é—´ä¸èƒ½æœ‰toolæˆ–cardç­‰åˆ†éš”ç¬¦
                if (next_item.get('role') == 'assistant' and
                    next_item.get('type') == 'markdown' and
                    next_item.get('message_id', '') == current_message_id):
                    markdown_group.append(next_item)
                    j += 1
                else:
                    # é‡åˆ°åˆ†éš”ç¬¦ï¼ˆtoolã€cardç­‰ï¼‰æˆ–ä¸åŒmessage_idï¼Œåœæ­¢
                    break

            # åˆå¹¶markdownç‰‡æ®µ
            if len(markdown_group) > 1:
                markdown_merge_count += 1
                print(f"    ğŸ”— å‘ç°è¿ç»­markdownç»„ (message_id: {current_message_id}, {len(markdown_group)}ä¸ªç‰‡æ®µ)")

                # æŒ‰timestampæ’åºç‰‡æ®µ
                markdown_group.sort(key=lambda x: x.get('timestamp', 0))

                # åˆå¹¶contentï¼ˆåªåˆå¹¶contentå­—æ®µï¼‰
                merged_content = ""
                for fragment in markdown_group:
                    content = fragment.get('content', '')
                    merged_content += content

                # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µä½œä¸ºæ¨¡æ¿ï¼ˆä¿æŒå…¶ä»–å­—æ®µä¸å˜ï¼‰
                merged_item = markdown_group[0].copy()
                merged_item['content'] = merged_content
                merged_item['is_merged'] = True
                merged_item['original_fragments'] = len(markdown_group)

                merged_data.append(merged_item)

                print(f"      âœ… åˆå¹¶å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(merged_content)} å­—ç¬¦")
                print(f"      åˆå¹¶å‰: {''.join([f.get('content', '') for f in markdown_group])}")
                print(f"      åˆå¹¶å: {merged_content}")
                i = j  # è·³è¿‡å·²åˆå¹¶çš„ç‰‡æ®µ
            else:
                # å•ç‰‡æ®µï¼Œä¸éœ€è¦åˆå¹¶
                current_item['is_merged'] = False
                current_item['original_fragments'] = 1
                merged_data.append(current_item)
                i += 1
        else:
            # émarkdowné¡¹ï¼ˆtask_id, tool, cardç­‰ï¼‰ï¼Œç›´æ¥æ·»åŠ 
            current_item['is_merged'] = False
            current_item['original_fragments'] = 1
            merged_data.append(current_item)
            i += 1

    print(f"    âœ… è¿ç»­markdownåˆå¹¶å®Œæˆ:")
    print(f"      - åˆå¹¶çš„ç»„æ•°: {markdown_merge_count}")
    print(f"      - åŸå§‹æ•°æ®æ¡æ•°: {len(raw_data)}")
    print(f"      - åˆå¹¶åæ•°æ®æ¡æ•°: {len(merged_data)}")
    print(f"      - å‡å°‘äº† {len(raw_data) - len(merged_data)} ä¸ªæ•°æ®é¡¹")
    print(f"    ğŸ“‹ åˆå¹¶è§„åˆ™:")
    print(f"      - åªåˆå¹¶è¿ç»­çš„ã€å…·æœ‰ç›¸åŒmessage_idçš„markdownç‰‡æ®µ")
    print(f"      - è¢«toolã€cardç­‰åˆ†éš”ç¬¦éš”å¼€çš„markdownç‰‡æ®µä¸ä¼šè¢«åˆå¹¶")
    print(f"      - åªåˆå¹¶contentå­—æ®µï¼Œå…¶ä»–å­—æ®µä¿æŒç¬¬ä¸€ä¸ªç‰‡æ®µçš„å€¼")

    return merged_data


def process_test_case(test_case):
    """å¤„ç†å•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
    test_case_id = test_case.get('test_case_id', 'unknown')
    print(f"\nå¤„ç†æµ‹è¯•ç”¨ä¾‹: {test_case_id}")

    # æ·±æ‹·è´æµ‹è¯•ç”¨ä¾‹ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    processed_case = test_case.copy()

    # å¤„ç†turn_results
    if 'turn_results' in processed_case:
        for turn_index, turn_result in enumerate(processed_case['turn_results']):
            print(f"  â”€â”€ ç¬¬{turn_index + 1}è½®å¯¹è¯ â”€â”€")

            if 'execution_result' in turn_result and 'raw_data' in turn_result['execution_result']:
                original_raw_data = turn_result['execution_result']['raw_data']
                print(f"  åŸå§‹raw_dataæ¡æ•°: {len(original_raw_data)}")

                # åˆå¹¶markdownæ•°æ®
                merged_raw_data = merge_consecutive_markdown(original_raw_data)

                # æ›¿æ¢åŸå§‹raw_data
                turn_result['execution_result']['raw_data'] = merged_raw_data
                turn_result['execution_result']['is_merged'] = True

                # æ›´æ–°response_analysis
                if 'response_analysis' in turn_result['execution_result']:
                    turn_result['execution_result']['response_analysis']['is_merged'] = True
                    turn_result['execution_result']['response_analysis']['original_count'] = len(original_raw_data)
                    turn_result['execution_result']['response_analysis']['merged_count'] = len(merged_raw_data)

    return processed_case


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æµå¼æ•°æ®è½¬æ¢è„šæœ¬ - åˆå¹¶markdownç‰‡æ®µ')
    parser.add_argument('--input', '-i', type=str, required=True, help='è¾“å…¥æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ)')
    parser.add_argument('--timestamp', '-t', type=str, help='æ—¶é—´æˆ³ (å¯é€‰ï¼Œç”¨äºç”Ÿæˆæ–‡ä»¶å)')
    args = parser.parse_args()

    # è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶
    input_file = args.input
    timestamp = args.timestamp or datetime.now().strftime('%Y%m%d_%H%M%S')

    # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if args.output:
        output_file = args.output
    else:
        # ä»è¾“å…¥æ–‡ä»¶åæå–æ—¶é—´æˆ³
        import os
        input_basename = os.path.basename(input_file)
        output_file = input_basename.replace('test_results_all_44_', 'test_results_merged_')
        if not output_file.endswith('.json'):
            output_file += '.json'

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³ï¼Œæ·»åŠ å½“å‰æ—¶é—´æˆ³
        if 'merged_' not in output_file:
            output_file = f"test_results_merged_{timestamp}.json"

    print("="*80)
    print("æµå¼æ•°æ®è½¬æ¢è„šæœ¬ - åˆå¹¶markdownç‰‡æ®µ")
    print("="*80)
    print(f"è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    print()

    # è¯»å–åŸå§‹æ•°æ®
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            test_cases = json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–è¾“å…¥æ–‡ä»¶å¤±è´¥: {e}")
        return

    print(f"è¯»å–åˆ° {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")

    # å¤„ç†æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹
    processed_cases = []
    total_merges = 0

    for i, test_case in enumerate(test_cases):
        print(f"\n[{i+1}/{len(test_cases)}] ", end="")
        processed_case = process_test_case(test_case)
        processed_cases.append(processed_case)

        # ç»Ÿè®¡åˆå¹¶ä¿¡æ¯
        if 'turn_results' in processed_case:
            for turn_result in processed_case['turn_results']:
                if 'execution_result' in turn_result and 'raw_data' in turn_result['execution_result']:
                    original_count = turn_result['execution_result'].get('response_analysis', {}).get('original_count', 0)
                    merged_count = turn_result['execution_result'].get('response_analysis', {}).get('merged_count', 0)
                    if original_count > 0 and merged_count > 0:
                        total_merges += (original_count - merged_count)

    print(f"\n" + "="*80)
    print("è½¬æ¢å®Œæˆ!")
    print(f"="*80)
    print(f"å¤„ç†äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    print(f"æ€»å…±å‡å°‘äº† {total_merges} ä¸ªæ•°æ®é¡¹")

    # ä¿å­˜åˆå¹¶åçš„æ•°æ®
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(processed_cases, f, ensure_ascii=False, indent=2)
        print(f"åˆå¹¶åçš„æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"é”™è¯¯: ä¿å­˜è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
        return

    print(f"\nâœ… è½¬æ¢æˆåŠŸå®Œæˆ!")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“Š åˆå¹¶ç»Ÿè®¡:")
    print(f"   - æ€»æµ‹è¯•ç”¨ä¾‹: {len(processed_cases)}")
    print(f"   - å‡å°‘æ•°æ®é¡¹: {total_merges}")
    print(f"   - å‹ç¼©ç‡: {(total_merges / sum(len(tc.get('turn_results', [{}])[0].get('execution_result', {}).get('raw_data', [])) for tc in test_cases) * 100):.1f}%" if test_cases else "0%")

    print(f"\nğŸ’¡ æ¥ä¸‹æ¥æ‚¨å¯ä»¥:")
    print(f"   1. ä½¿ç”¨åˆå¹¶åçš„æ•°æ®æ–‡ä»¶è¿è¡ŒéªŒè¯: python validate_test_results.py")
    print(f"   2. æˆ–ä¿®æ”¹éªŒè¯è„šæœ¬è¯»å–åˆå¹¶åçš„æ•°æ®æ–‡ä»¶")


if __name__ == '__main__':
    main()