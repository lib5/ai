#!/usr/bin/env python3
"""
æµ‹è¯•ç»“æœéªŒè¯è„šæœ¬ - å¤šè·¯å¾„æ”¯æŒç‰ˆ
ä½¿ç”¨Azure OpenAI GPT-4.1éªŒè¯chat APIæµ‹è¯•ç»“æœçš„æ­£ç¡®æ€§

åŠŸèƒ½ç‰¹ç‚¹:
- æ”¯æŒä¼ ç»Ÿå•è·¯å¾„æœŸæœ›æ ¼å¼ (stepsæ•°ç»„)
- æ”¯æŒå¤šè·¯å¾„æœŸæœ›æ ¼å¼ (pathsæ•°ç»„ï¼Œæ¯ä¸ªè·¯å¾„åŒ…å«descriptionå’Œsteps)
- åªè¦å®é™…æ‰§è¡Œç¬¦åˆä»»ä¸€è·¯å¾„ï¼Œå³åˆ¤å®šä¸ºæ­£ç¡®
- çµæ´»çš„å·¥å…·è°ƒç”¨éªŒè¯
"""

import json
import asyncio
import aiohttp
import os
import sys
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½.envæ–‡ä»¶
load_dotenv('/home/libo/chatapi/.env')

# è·å–Azure OpenAIé…ç½®
AZURE_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')
AZURE_API_KEY = os.getenv('AZURE_API_KEY') or os.getenv('AZURE_OPENAI_API_KEY')
AZURE_API_VERSION = os.getenv('AZURE_API_VERSION') or os.getenv('AZURE_OPENAI_API_VERSION', '2024-12-01-preview')
DEPLOYMENT_NAME = os.getenv('AZURE_DEPLOYMENT_NAME') or os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME', 'gpt-4.1')

# åˆ›å»ºæ—¥å¿—ç›®å½•
LOG_DIR = Path(__file__).parent / "logs"
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = f"{LOG_DIR}/validation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

# ç®€å•æ—¥å¿—è®°å½•å™¨
class Logger:
    def __init__(self, log_file):
        self.log_file = log_file
        self.buffer = []

    def log(self, message, level="INFO"):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_msg = f"[{timestamp}] [{level}] {message}"
        self.buffer.append(log_msg)

    def save(self):
        with open(self.log_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(self.buffer))

logger = Logger(LOG_FILE)

print("="*60)
print("æµ‹è¯•ç»“æœéªŒè¯å·¥å…· - ä½¿ç”¨ Azure OpenAI GPT-4.1")
print("="*60)

logger.log("å¼€å§‹éªŒè¯è¿‡ç¨‹")
logger.log(f"Azure OpenAIé…ç½®:")
logger.log(f"  ç«¯ç‚¹: {AZURE_ENDPOINT}")
logger.log(f"  æ¨¡å‹: {DEPLOYMENT_NAME}")
logger.log(f"  APIç‰ˆæœ¬: {AZURE_API_VERSION}")
logger.log(f"æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")
print()


async def validate_single_turn(session, test_case_id, turn_result, turn_index, base_timestamp_with_weekday, logger):
    """éªŒè¯å•ä¸ªturn"""
    turn_id = turn_result.get('turn_id', f'turn_{turn_index}')
    user_input = turn_result.get('user_input', {})
    execution_result = turn_result.get('execution_result', {})
    expected_behavior = turn_result.get('expected_behavior', {})

    logger.log(f"  â”€â”€ ç¬¬{turn_index + 1}è½®å¯¹è¯ â”€â”€")
    logger.log(f"  Turn ID: {turn_id}")

    # è®°å½•ç”¨æˆ·è¾“å…¥
    if user_input.get('type') == 'text':
        input_display = f"æ–‡æœ¬è¾“å…¥: {user_input.get('content', '')}"
    elif user_input.get('type') == 'image':
        input_display = f"å›¾åƒè¾“å…¥: {user_input.get('content', '')}"
    else:
        input_display = f"è¾“å…¥: {json.dumps(user_input, ensure_ascii=False, indent=2)}"

    logger.log(f"  ç”¨æˆ·è¾“å…¥: {user_input.get('content', '')}")
    logger.log(f"  è¾“å…¥ç±»å‹: {user_input.get('type')}")

    # ğŸ”§ æ”¯æŒå¤šè·¯å¾„æœŸæœ›æ ¼å¼
    # æ–°æ ¼å¼ï¼šexpected_behavior æ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å«å¤šä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„
    expected_behavior_paths = expected_behavior if isinstance(expected_behavior, list) else []
    # æ—§æ ¼å¼å…¼å®¹ï¼šsteps æ•°ç»„
    expected_steps = expected_behavior.get('steps', []) if isinstance(expected_behavior, dict) else []

    logger.log(f"  å¤šè·¯å¾„æœŸæœ›æ•°: {len(expected_behavior_paths)}")
    logger.log(f"  ä¼ ç»Ÿæ­¥éª¤æœŸæœ›æ•°: {len(expected_steps)}")

    # ä¼˜å…ˆä½¿ç”¨å¤šè·¯å¾„æ ¼å¼
    if expected_behavior_paths:
        logger.log("  âœ… ä½¿ç”¨å¤šè·¯å¾„æœŸæœ›æ ¼å¼:")
        logger.log(f"    ğŸ“ å…±{len(expected_behavior_paths)}ä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„")
        for i, path in enumerate(expected_behavior_paths):
            desc = path.get('description', f'è·¯å¾„{i+1}')
            steps = path.get('steps', [])
            logger.log(f"    è·¯å¾„ {i+1}: {desc}")
            logger.log(f"      æ­¥éª¤æ•°: {len(steps)}")
            for j, step in enumerate(steps):
                step_type = step.get('type', '')
                tool_name = step.get('tool_name', '')
                logger.log(f"        æ­¥éª¤{j+1}: {step_type} - {tool_name}")
        logger.log(f"    ğŸ¯ éªŒè¯è§„åˆ™: åªè¦å®é™…æ‰§è¡Œç¬¦åˆä»»ä¸€è·¯å¾„ï¼Œå³åˆ¤å®šæ­£ç¡®")
    elif expected_steps:
        logger.log("  ğŸ“‹ ä½¿ç”¨ä¼ ç»Ÿæ­¥éª¤æœŸæœ›æ ¼å¼:")
        for i, step in enumerate(expected_steps):
            logger.log(f"    æ­¥éª¤ {i+1}: {json.dumps(step, ensure_ascii=False)}")
    else:
        logger.log("  âš ï¸ æœªæ‰¾åˆ°æœŸæœ›è¡Œä¸ºæ•°æ®")

    # æ ¼å¼åŒ–å®é™…æ‰§è¡Œç»“æœ
    actual_tool_calls = []
    tool_results = []
    assistant_responses = []
    if 'raw_data' in execution_result:
        for item in execution_result['raw_data']:
            if item.get('type') == 'tool' or (item.get('role') == 'assistant' and item.get('type') == 'tool'):
                content = item.get('content', {})
                if content.get('status') == 'start':
                    actual_tool_calls.append({
                        'tool_name': content.get('name', ''),
                        'tool_cn': content.get('name_cn', ''),
                        'arguments': content.get('arguments', ''),
                    })
                elif content.get('status') == 'success':
                    tool_results.append({
                        'tool_name': content.get('name', ''),
                        'observation': content.get('observation', '')
                    })
            elif item.get('type') == 'markdown' or (item.get('role') == 'assistant' and item.get('type') == 'markdown'):
                assistant_responses.append({
                    'message_id': item.get('message_id', ''),
                    'content': item.get('content', ''),
                    'is_merged': item.get('is_merged', False),
                    'original_fragments': item.get('original_fragments', 1)
                })

    logger.log(f"  å®é™…å·¥å…·è°ƒç”¨æ•°: {len(actual_tool_calls)}")
    for i, tool_call in enumerate(actual_tool_calls):
        logger.log(f"    å·¥å…· {i+1}: {tool_call.get('tool_name')} - {tool_call.get('tool_cn', '')}")
        logger.log(f"      å‚æ•°: {tool_call.get('arguments', '')}")

    logger.log(f"  å·¥å…·æ‰§è¡Œç»“æœæ•°: {len(tool_results)}")
    logger.log(f"  Assistantå“åº”æ•°: {len(assistant_responses)}")
    for i, response in enumerate(assistant_responses):
        logger.log(f"    å“åº” {i+1}: {response.get('content', '')[:100]}...")

    # ğŸ”§ æ„å»ºå¤šè·¯å¾„éªŒè¯prompt
    if expected_behavior_paths:
        # ä½¿ç”¨å¤šè·¯å¾„æ ¼å¼
        expected_content = json.dumps(expected_behavior_paths, ensure_ascii=False, indent=2)
        prompt_header = "## æœŸæœ›è¡Œä¸º (å¤šè·¯å¾„æ ¼å¼)\næ³¨æ„ï¼šexpected_behavioræ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å«å¤šä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„ã€‚åªè¦å®é™…æ‰§è¡Œç¬¦åˆå…¶ä¸­ä¸€ä¸ªè·¯å¾„ï¼Œå³ä¸ºæ­£ç¡®ã€‚\n"
    elif expected_steps:
        # ä½¿ç”¨ä¼ ç»Ÿæ ¼å¼
        expected_content = json.dumps(expected_steps, ensure_ascii=False, indent=2)
        prompt_header = "## æœŸæœ›è¡Œä¸º (ä¼ ç»Ÿæ ¼å¼)\n"
    else:
        expected_content = "æœªæ‰¾åˆ°æœŸæœ›è¡Œä¸ºæ•°æ®"
        prompt_header = "## æœŸæœ›è¡Œä¸º\n"

    # æ„å»ºAssistantå“åº”çš„markdownå†…å®¹
    assistant_responses_summary = ""
    if assistant_responses:
        assistant_responses_summary = "\n## åˆå¹¶åçš„Assistantå“åº”\n"
        for i, response in enumerate(assistant_responses):
            # æ„å»ºåˆå¹¶åçš„å“åº”ä¿¡æ¯
            content = response.get('content', '')
            is_merged = response.get('is_merged', False)
            fragments = response.get('original_fragments', 1)

            assistant_responses_summary += f"\n### å“åº” {i+1}:\n"
            assistant_responses_summary += f"{content}\n"

            if is_merged and fragments > 1:
                assistant_responses_summary += f"*(æ³¨: æ­¤å“åº”ç”±{fragments}ä¸ªæµå¼ç‰‡æ®µåˆå¹¶è€Œæˆ)*\n"

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç³»ç»Ÿæµ‹è¯•éªŒè¯ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æµ‹è¯•ç”¨ä¾‹çš„æ‰§è¡Œç»“æœï¼Œåˆ¤æ–­å…¶æ­£ç¡®æ€§ã€‚

## æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯
æµ‹è¯•ID: {test_case_id}
{input_display}

## æ—¶é—´ä¿¡æ¯ 
æµ‹è¯•åŸºå‡†æ—¶é—´: {base_timestamp_with_weekday}
æ³¨ï¼šç”¨æˆ·è¾“å…¥ä¸­çš„"ä»Šå¤©ä¸‹åˆä¸¤ç‚¹"ç­‰ç›¸å¯¹æ—¶é—´è¡¨è¾¾åº”åŸºäºæ­¤åŸºå‡†æ—¶é—´æ¥åˆ¤æ–­
**å…³äºæ—¶é—´åˆ¤æ–­ï¼Œä½ å¿…é¡»éµå®ˆä»¥ä¸‹é¦–è¦è§„åˆ™ï¼š**
1.  **å¿½ç•¥æœŸæœ›æ—¶é—´**ï¼š
    - è¾“å…¥ä¸ºæ–‡æœ¬è¾“å…¥æ—¶å€™ åœ¨è¯„ä¼°"æ—¶é—´åˆ¤æ–­å‡†ç¡®æ€§"æ—¶ï¼Œ**è¯·å®Œå…¨å¿½ç•¥æµ‹è¯•ç”¨ä¾‹ä¸­"æœŸæœ›æ‰§è¡Œæ­¥éª¤"é‡Œçš„start_time,å®ƒå¯èƒ½ä¸æœ¬æ¬¡è¯„æµ‹çš„åŸºå‡†æ—¶é—´ä¸ç¬¦ï¼Œä¸å…·å¤‡å‚è€ƒä»·å€¼
    - å¦‚æœè¾“å…¥æ˜¯å›¾åƒè¾“å…¥æ—¶ è¦ä¿æŒä¸æœŸæœ›start_timeä¸€è‡´ã€‚
2.  **å”¯ä¸€æ—¶é—´åŸºå‡†**ï¼šæ‰€æœ‰å…³äº"ä»Šå¤©"ã€"æ˜å¤©"ã€"ä¸‹å‘¨"ç­‰ç›¸å¯¹æ—¶é—´çš„æ­£ç¡®æ€§åˆ¤æ–­ï¼Œ**æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªæ­£ç¡®æ ‡å‡†ï¼šå³åŸºäºä¸‹æ–¹æä¾›çš„"æµ‹è¯•åŸºå‡†æ—¶é—´"è¿›è¡Œæ¨ç®—çš„ç»“æœ**ã€‚
3.  **éªŒè¯å®é™…æ—¶é—´**ï¼šä½ åªéœ€åˆ¤æ–­"å®é™…è°ƒç”¨çš„å·¥å…·"ä¸­çš„æ—¶é—´å‚æ•°ï¼Œæ˜¯å¦ä¸åŸºäº**æµ‹è¯•åŸºå‡†æ—¶é—´**æ¨ç®—å‡ºçš„æ­£ç¡®æ—¶é—´ç›¸åŒ¹é…ï¼Œå¯ä»¥è¿œè¶…åŸºå‡†æ—¶é—´ åˆç†å°±è¡Œã€‚
å‚è€ƒä¸‹é¢ä¸¤ä¸ªä¾‹å­ ä¸‹é¢ä¸¤ä¸ªä¾‹å­è¯„ä¼°é”™è¯¯ è™½ç„¶ä¸é¢„æœŸä¸ç¬¦ä½†æ˜¯å®é™…ç»“æœæ˜¯æ­£ç¡®çš„ é‚£æ—¶é—´å‡†ç¡®æ€§è¿™ä¸€é¡¹åˆ†æ•°åº”è¯¥æ˜¯10åˆ†
- "æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ï¼š'åå¤©ä¸­åˆ'åŸºäºåŸºå‡†æ—¶é—´2026-01-16T10:45:59åº”ä¸º2026-01-18T12:00:00ï¼Œä½†å®é™…åˆ›å»ºæ—¶é—´ä¸º2026-01-18T12:00:00ï¼Œè¡¨é¢çœ‹ä¼¼æ­£ç¡®ï¼Œä½†å®é™…ä¸Š'åå¤©'åº”ä¸º2026-01-18ï¼Œå®é™…å‚æ•°æ˜¯æ­£ç¡®çš„ã€‚"

- ç”¨æˆ·è¾“å…¥ä¸º'ä¸‹å‘¨å››'ï¼ŒåŸºå‡†æ—¶é—´ä¸º2026-01-16ï¼ˆå‘¨äº”ï¼‰ï¼Œä¸‹å‘¨å››åº”ä¸º2026-01-22ï¼Œä½†å®é™…åˆ›å»ºæ—¶é—´ä¸º2026-01-22ï¼Œå‚æ•°æ­£ç¡®ï¼Œä½†æœŸæœ›è¡Œä¸ºä¸­çš„æ—¶é—´ä¸º2026-01-23ï¼ŒæœŸæœ›è¡Œä¸ºæœ‰è¯¯ã€‚å®é™…æ‰§è¡Œç»“æœæ˜¯æ­£ç¡®çš„ æ—¶é—´å‚æ•°åˆ†æ•°åº”è¯¥ä¸ºé«˜åˆ†

## æœŸæœ›è¡Œä¸º
{prompt_header}
{expected_content}

## å®é™…æ‰§è¡Œç»“æœ
å®é™…è°ƒç”¨çš„å·¥å…·: {json.dumps(actual_tool_calls, ensure_ascii=False, indent=2)}
å·¥å…·æ‰§è¡Œç»“æœ: {json.dumps(tool_results, ensure_ascii=False, indent=2)}
æ‰§è¡ŒçŠ¶æ€: {execution_result.get('status', 'unknown')}
{assistant_responses_summary}
## éªŒè¯æ ‡å‡†
è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼ˆæ¯é¡¹1-10åˆ†ï¼Œ10åˆ†æœ€ä½³ï¼‰ï¼š

1. **å·¥å…·é€‰æ‹©å‡†ç¡®æ€§**: æ˜¯å¦é€‰æ‹©äº†æ­£ç¡®çš„å·¥å…·ï¼Ÿ
2. **å‚æ•°æå–å‡†ç¡®æ€§**: å·¥å…·å‚æ•°æ˜¯å¦å‡†ç¡®åæ˜ äº†ç”¨æˆ·æ„å›¾ï¼Ÿç‰¹åˆ«æ˜¯æ—¶é—´å‚æ•°æ˜¯å¦æ­£ç¡®ï¼Ÿå¯¹äºäººè„‰ é™¤äº†noteä¹‹å¤– å…¶ä»–è¦ä¸¥æ ¼ä¸€è‡´
    - reminder_timeè¦å®Œå…¨ç¬¦åˆç”¨æˆ·æ„å›¾ å¦åˆ™å¿…é¡»åˆ¤æ–­é”™è¯¯  å¦‚æ—¥ç¨‹æé†’æ—¶é—´(reminder_time)è®¾ç½®ä¸º-1dï¼Œæœªå®Œå…¨ç¬¦åˆç”¨æˆ·è¦æ±‚çš„æå‰ä¸€å‘¨(-1w)æé†’ åˆ¤æ–­ä¸ºé”™è¯¯
3. **æ—¶é—´åˆ¤æ–­å‡†ç¡®æ€§**: å¯¹äºæ—¥ç¨‹ç›¸å…³æµ‹è¯•ï¼Œè¯·é‡ç‚¹æ£€æŸ¥ï¼š
   - å®é™…è°ƒç”¨ä¸­çš„æ—¶é—´å‚æ•°æ˜¯å¦åŸºäº**æµ‹è¯•åŸºå‡†æ—¶é—´**æ­£ç¡®è½¬æ¢ï¼Ÿå¦‚æœè½¬åŒ–æ­£ç¡® åˆ™è¿™é¡¹å‡†ç¡®æ€§åˆ†æ•°æ»¡åˆ†ã€‚è¯·ä¸¥æ ¼åº”ç”¨ä¸‹æ–¹"æ—¥æœŸæ˜ŸæœŸè®¡ç®—è§„åˆ™"ã€‚
   -æ³¨æ„æ³¨æ„  å¦‚æœæœŸæœ›æ—¶é—´æœ‰è¯¯ä½†ç¬¦åˆå®é™…å°±è¦ç»™10åˆ† è¿™ç§æƒ…å†µä¸‹ä¸èƒ½è¾“å‡ºæ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯
   -  å¯¹äºè¿™ç§æƒ…å†µ "æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ï¼š'æ˜å¤©æ™šä¸Šå…«ç‚¹'åº”ä¸º2026-01-17 20:00:00ï¼Œä½†å®é™…åˆ›å»ºåœ¨2026-01-17 20:00:00ï¼Œè¡¨é¢çœ‹ä¼¼æ­£ç¡®ï¼Œä½†åŸºå‡†æ—¶é—´ä¸º2026-01-16ï¼Œ'æ˜å¤©'åº”ä¸º2026-01-17ï¼Œå®é™…å‚æ•°æ˜¯æ­£ç¡®çš„ã€‚ è¿™ç§ä¸ç®—æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ ç®—å‚æ•°æå–æ­£ç¡®

4. **æ•°æ®å¤„ç†åˆç†æ€§**: æ•°æ®æ ¼å¼è½¬æ¢ã€é»˜è®¤å€¼å¤„ç†ç­‰æ˜¯å¦åˆç†ï¼Ÿ
5. **ä¸šåŠ¡é€»è¾‘æ­£ç¡®æ€§**: å¯¹ç”¨æˆ·éœ€æ±‚çš„ç†è§£å’Œå¤„ç†æ˜¯å¦æ­£ç¡®ï¼Ÿ
6. **å“åº”å®Œæ•´æ€§**:
   - **Markdownå“åº”å®Œæ•´æ€§**: æ£€æŸ¥Assistantçš„markdownå“åº”å†…å®¹æ˜¯å¦å®Œæ•´ã€å‡†ç¡®ï¼Œæ˜¯å¦é—æ¼é‡è¦ä¿¡æ¯ï¼Ÿ
   - **å“åº”è´¨é‡**: å“åº”å†…å®¹æ˜¯å¦æ¸…æ™°ã€å‡†ç¡®ã€æœ‰æ¡ç†ï¼Ÿ
   - **ä¿¡æ¯å‡†ç¡®æ€§**: å“åº”ä¸­çš„ä¿¡æ¯æ˜¯å¦ä¸å·¥å…·æ‰§è¡Œç»“æœä¸€è‡´ï¼Ÿ


## æ—¶é—´åˆ¤æ–­è¦æ±‚
å¦‚æœæ˜¯æ—¥ç¨‹ã€ä¼šè®®ç›¸å…³çš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¯·ç‰¹åˆ«å…³æ³¨ï¼š
- åŸºå‡†æ—¶é—´ï¼š{base_timestamp_with_weekday}
- ç”¨æˆ·è¯´"ä»Šå¤©ä¸‹åˆä¸¤ç‚¹"ï¼ŒåŸºå‡†æ—¶é—´æ˜¯{base_timestamp_with_weekday}
- é‚£ä¹ˆæœŸæœ›çš„å¼€å§‹æ—¶é—´åº”è¯¥æ˜¯å½“å¤©ä¸‹åˆ2ç‚¹ï¼ˆå³14:00ï¼‰
- å®é™…æ‰§è¡Œçš„æ—¶é—´å‚æ•°åº”è¯¥ä¸æœŸæœ›æ—¶é—´åŒ¹é…æˆ–åˆç†æ¥è¿‘

## æ—¥æœŸæ˜ŸæœŸè®¡ç®—è§„åˆ™
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™è¿›è¡Œæ—¥æœŸè®¡ç®—ï¼š
1. **æ—¥æœŸ-æ˜ŸæœŸå¯¹åº”**ï¼š
   - æ˜ŸæœŸä¸€ = å‘¨ä¸€ = å‘¨1
   - æ˜ŸæœŸäºŒ = å‘¨äºŒ = å‘¨2
   - æ˜ŸæœŸä¸‰ = å‘¨ä¸‰ = å‘¨3
   - æ˜ŸæœŸå›› = å‘¨å›› = å‘¨4
   - æ˜ŸæœŸäº” = å‘¨äº” = å‘¨5
   - æ˜ŸæœŸå…­ = å‘¨å…­ = å‘¨6
   - æ˜ŸæœŸæ—¥ = å‘¨æ—¥ = å‘¨7

2. **ç›¸å¯¹æ—¶é—´å¤„ç†**ï¼š
   - "ä¸‹å‘¨"æŒ‡çš„æ˜¯ï¼šä»åŸºå‡†æ—¶é—´å¼€å§‹é‡åˆ°çš„ç¬¬ä¸€ä¸ªå‘¨ä¸€å¼€å§‹åˆ°å‘¨æ—¥ç»“æŸçš„å®Œæ•´å‘¨  åŸºå‡†æ—¶é—´æ˜¯åœ¨å‘¨ä¸€ é‚£ä¹ˆä¸‹å‘¨æ˜¯ä»ä¸‹ä¸€ä¸ªå‘¨ä¸€å¼€å§‹ å¦‚åŸºå‡†æ—¶é—´ä¸º2026-01-19ï¼Œ'ä¸‹å‘¨'åº”ä¸º2026-01-26è‡³2026-02-01ã€‚
   - "ä¸‹å‘¨å››"æŒ‡çš„æ˜¯ï¼šä¸‹ä¸€å‘¨ä¸­çš„å‘¨å››
   - `"å‘¨X" = åŸºå‡†æ—¶é—´æ‰€åœ¨å‘¨å†…çš„æ˜ŸæœŸX
   - "ä¸‹å‘¨"æŒ‡çš„æ˜¯ï¼šä»ç¬¬ä¸€ä¸ªå‘¨ä¸€å¼€å§‹çš„å®Œæ•´ä¸€å‘¨
   - "ä¸‹ä¸ªæœˆ"æŒ‡çš„æ˜¯ï¼šåŸºå‡†æ—¶é—´æ‰€åœ¨æœˆçš„ä¸‹ä¸€ä¸ªæœˆ

3. **æ—¥æœŸè®¡ç®—ç¤ºä¾‹**ï¼š
   - å¦‚æœåŸºå‡†æ—¶é—´æ˜¯2026-01-19ï¼ˆå‘¨ä¸€ï¼‰
   - "å‘¨ä¸‰" = 2026-01-21 
   - "ä¸‹å‘¨ä¸€" = 2026-01-26
   - "ä¸‹å‘¨å››" = 2026-01-29



## åˆ¤æ–­æ ‡å‡†
- **æ­£ç¡®**: å·¥å…·é€‰æ‹©æ­£ç¡®ï¼Œä¸»è¦å‚æ•°å‡†ç¡®(å¯ä»¥ä¸ä¸€è‡´ä½†åˆç†ã€ç›¸è¿‘å°±å¯ä»¥)ï¼Œæ—¶é—´åˆ¤æ–­æ­£ç¡®ï¼Œä¸šåŠ¡é€»è¾‘æ­£ç¡®
- **é”™è¯¯**: å·¥å…·é€‰æ‹©é”™è¯¯ï¼Œç†è§£å®Œå…¨é”™è¯¯æˆ–è€…æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ã€æŸä¸ªå‚æ•°ä¸åˆç†ã€æŸä¸ªå‚æ•°ä¸é¢„æœŸå®Œå…¨ä¸ä¸€è‡´

## ğŸ”§ å¤šè·¯å¾„éªŒè¯è§„åˆ™
- **å¤šè·¯å¾„éªŒè¯**: å¦‚æœexpected_behavioræ˜¯æ•°ç»„æ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„ï¼Œ**åªè¦å®é™…æ‰§è¡Œç¬¦åˆå…¶ä¸­ä¸€ä¸ªè·¯å¾„ï¼Œå³ä¸ºæ­£ç¡®**
- **è·¯å¾„åŒ¹é…**: æ£€æŸ¥å®é™…å·¥å…·è°ƒç”¨åºåˆ—æ˜¯å¦ä¸ä»»ä¸€è·¯å¾„çš„stepsåŒ¹é…
- **çµæ´»æ‰§è¡Œ**: å…è®¸æ‰§è¡Œé¢å¤–çš„å·¥å…·è°ƒç”¨ï¼Œåªè¦ä¸å½±å“æ ¸å¿ƒé€»è¾‘

## æ³¨æ„
- ç”±äºæœŸæœ›çš„åŸºå‡†æ—¶é—´å’Œè¯„æµ‹åŸºå‡†æ—¶é—´ä¸ä¸€è‡´ å› æ­¤ä¸€åˆ‡ä»¥è¯„æµ‹çš„åŸºå‡†æ—¶é—´ä¸ºå‡† ä¸è€ƒè™‘æœŸæœ›çš„æ—¶é—´
- **ä¸éœ€è¦ç®¡incompleteçŠ¶æ€**ï¼Œå¦‚æœä¸€è½®å¯¹è¯ä¸­incomplete=trueï¼Œè¡¨ç¤ºè¿™ä¸€è½®æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸å½±å“è¯„ä¼°ç»“æœ è‹¥æœŸæœ›ä¸­å­˜åœ¨è°ƒç”¨å·¥å…· éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­æ˜¯å¦ä¸€å®šéœ€è¦è°ƒç”¨è¯¥å·¥å…· è‹¥ä¸€å®šéœ€è¦è°ƒç”¨ åˆ™åˆ¤æ–­é”™è¯¯ã€‚

## è¡¥å……
1. ç”¨æˆ·è¡¨è¾¾å‡ºæ„å›¾å°±å¯ä»¥è°ƒç”¨ ä¸éœ€è¦æ˜ç¡®æŒ‡å‡º
2. å¯¹äºç”Ÿæ—¥çš„å¹´ä»½å¯ä»¥è¡¥å…¨ ä¸ç®—é”™è¯¯
3. ç›¸æ¯”äºé¢„æœŸå¯ä»¥æ·»åŠ å¤šä½™å‚æ•° åªè¦åˆç†å°±å¯ä»¥æ·»åŠ 
4. idå¯ä»¥ä¸ä¸€è‡´
5. åˆ›å»ºäººè„‰æ—¶éœ€è¦å»æŸ¥æ‰¾äººè„‰ è¿™æ˜¯æ­£ç¡®çš„  æœ‰ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ï¼Œæ›´æ–°äººè„‰æ—¶ä¹Ÿå¯ä»¥ä¸æŸ¥æ‰¾,åªè¦å·¥å…·ç»“æœæ‰§è¡Œæ­£ç¡®å³å¯
6. æé†’æ—¶é—´çš„æ ¼å¼å¿…é¡»æ˜¯åé¢10ä¸ªå€¼ä¸­çš„ä¸€ä¸ªï¼š-5mâ€‹ è¡¨ç¤º 5 åˆ†é’Ÿå‰ï¼› -10mâ€‹ è¡¨ç¤º 10 åˆ†é’Ÿå‰ï¼›-15mâ€‹ è¡¨ç¤º 15 åˆ†é’Ÿå‰ï¼›-30mâ€‹ è¡¨ç¤º 30 åˆ†é’Ÿå‰ï¼›-1hâ€‹ è¡¨ç¤º 1 å°æ—¶å‰ï¼›-2hâ€‹ è¡¨ç¤º 2 å°æ—¶å‰ï¼›-1dâ€‹ è¡¨ç¤º 1 å¤©å‰ï¼›-2dâ€‹ è¡¨ç¤º 2 å¤©å‰ï¼›-1wâ€‹ è¡¨ç¤º 1 å‘¨å‰ï¼›-2wâ€‹ è¡¨ç¤º 2 å‘¨å‰ã€‚å•ä½ï¼šd=å¤©ï¼Œm=åˆ†é’Ÿï¼Œw=å‘¨ï¼Œh=å°æ—¶
7. å¯¹äºæ—¥ç¨‹çš„æ—¶é—´ å¦‚æœç”¨æˆ·æœªæ˜ç¡®è¦æ±‚ï¼Œ**ç»“æŸæ—¶é—´ã€æŒç»­æ—¶é•¿ã€æé†’æ—¶é—´ï¼ˆreminder_timeï¼‰å¯ä»¥çµæ´»è®¾ç½®ï¼Œä¹Ÿå¯ä»¥ä¸è®¾ç½® å› ä¸ºé»˜è®¤-5mï¼Œåªè¦é€»è¾‘åˆç†å³å¯ã€‚
8. reminder_timeã€æ—¥ç¨‹ç»“æŸæ—¶é—´ï¼Œå¦‚æœç”¨æˆ·é—®é¢˜ä¸­æ²¡æœ‰æ˜ç¡®è¦æ±‚è¿™ä¸ªæ—¶é•¿ ä¾¿å¯ä»¥å’Œé¢„æœŸä¸ä¸€è‡´
9. noteä¸ä¸€è‡´ä½†ç›¸è¿‘ä¹Ÿæ˜¯å¯ä»¥çš„ å¦‚ ç”¨æˆ·æœŸæœ›ä¸º'æœåŠ¡å™¨ç›¸å…³è¡Œä¸š'ï¼Œå®é™…ä¸º'æœåŠ¡å™¨'æ˜¯æ­£ç¡®çš„
10. å¯¹äºæ—¥ç¨‹åˆ›å»ºçš„æ—¶é—´ ä»¥åŸºå‡†æ—¶é—´ä¸ºå‡† å¦‚æœåˆç†åˆ™ä¸éœ€è¦å’ŒæœŸæœ›æ—¶é—´ä¿æŒä¸€è‡´  å¦‚ ç”¨æˆ·è¯´'ä»Šå¤©ä¸‹åˆå…«ç‚¹'ï¼ŒåŸºå‡†æ—¶é—´ä¸º2026-01-16ï¼Œå®é™…å´åˆ›å»ºåœ¨2026-01-16 20:00:00ï¼ŒæœŸæœ›åº”ä¸º2026-01-16 20:00:00ï¼Œä½†æœŸæœ›è¡Œä¸ºä¸­æ—¶é—´ä¸º2026-01-13 20:00:00ï¼ŒæœŸæœ›è¡Œä¸ºæœ¬èº«æœ‰è¯¯ å› æ­¤ä»–çš„å‚æ•°æå–æ˜¯æ­£ç¡®çš„ åˆ¤æ–­ä¸ºå¯¹
11. æœŸæœ›æœ‰è¯¯ä½†æ‰§è¡Œç»“æœåˆç† åˆ™ä¸éœ€è¦å’ŒæœŸæœ›ä¿æŒä¸€è‡´ å¯ä»¥åˆ¤æ–­ä¸ºæ­£ç¡®
12. full_dayå¯ä»¥æ˜¯æ—¥æœŸ (start_timeã€end_time)ä¸full_dayæœ‰å…¶ä¸­ä¸€ä¸ªå°±å¯ä»¥
13. å“åº”å†…å®¹åœ¨"content"å­—æ®µä¸­æŸ¥çœ‹
14. å¾…æµ‹è¯•æ•°æ®å¯ä»¥ä¸é¢„æœŸä¸ä¸€è‡´ å¯¹äºå¤æ‚ä»»åŠ¡chunks_count>=14 ï¼Œåªè¦æœ€åéƒ½å®Œæˆäº†ç”¨æˆ·çš„æ„å›¾ éƒ½å¯ä»¥ç®—æ­£ç¡®ï¼Œä½¿ç”¨çš„å·¥å…·ã€å‚æ•°å¯ä»¥å’ŒæœŸæœ›ä¸ä¸€è‡´
15. å¤šè½®å¯¹è¯ä¸­å¦‚æœå¯ä»¥ä»å‰1-3è½®ç›´æ¥è·å–å¾—åˆ°æ•°æ®ï¼Œå¯ä»¥ä¸éœ€è¦è°ƒç”¨æŸ¥è¯¢å·¥å…· å¦‚ç¬¬ä¸€è½®è¯´äº†æ±Ÿæ¶µçš„ç”Ÿæ—¥å’Œæ‰‹æœºå· ç¬¬äºŒè½®å¯ä»¥ç›´æ¥è¾“å‡ºè¿™ä¸¤æ¡æ•°æ® ä¹Ÿå¯ä»¥é€šè¿‡æœç´¢è”ç³»äººå¾—åˆ°
16. å¤šä½™åˆ›å»ºçš„æ—¥ç¨‹å’Œäººè„‰ åˆç†ä¹Ÿå¯ä»¥æ¥å— ä¸èƒ½ç»™ä½åˆ†
17. æ ¹æ®idæŸ¥æ‰¾çš„ä¸ä¼šè¯¯åˆ ã€æ‰¾é”™è”ç³»äºº
18. å·¥å…·é€‰æ‹©å’Œå‚æ•°æå–å‡æœªå‘ç”Ÿï¼Œä½†æ˜¯æœ€åè¾“å‡ºçš„ç»“æœåˆç†ï¼Œè¿‡ç¨‹åˆç†(ä»ä¸Šä¸‹æ–‡ä¸­å¾—åˆ°ä¿¡æ¯) è¿™ä¸å½±å“å½±å“ä¸šåŠ¡é€»è¾‘å’Œå“åº”å®Œæ•´æ€§
19. **å¤šè·¯å¾„æ ¼å¼æ”¯æŒ**: å½“expected_behaviorä¸ºæ•°ç»„æ—¶ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«"description"å’Œ"steps"ï¼Œè¡¨ç¤ºä¸€ä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„ã€‚åªè¦å®é™…æ‰§è¡Œç¬¦åˆä»»ä¸€è·¯å¾„ï¼Œå³åˆ¤å®šæ­£ç¡®ã€‚ 

è¯·ä»¥JSONæ ¼å¼è¿”å›éªŒè¯ç»“æœï¼š
```json
{{
  "overall_score": æ€»åˆ†(1-10),
  "is_correct": "æ­£ç¡®/é”™è¯¯",
  "dimension_scores": {{
    "tool_selection": å·¥å…·é€‰æ‹©åˆ†æ•°,
    "parameter_accuracy": å‚æ•°å‡†ç¡®æ€§åˆ†æ•°,
    "time_accuracy": æ—¶é—´å‡†ç¡®æ€§åˆ†æ•°,
    "data_processing": æ•°æ®å¤„ç†åˆ†æ•°,
    "business_logic": ä¸šåŠ¡é€»è¾‘åˆ†æ•°,
    "response_completeness": å“åº”å®Œæ•´æ€§åˆ†æ•°
  }},
  "key_issues": ["å…³é”®é—®é¢˜1", "å…³é”®é—®é¢˜2"],
  "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
  "detailed_analysis": "è¯¦ç»†åˆ†æè¯´æ˜"
}}
```
"""

    url = f"{AZURE_ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={AZURE_API_VERSION}"

    headers = {
        "Authorization": f"Bearer {AZURE_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": DEPLOYMENT_NAME,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç³»ç»Ÿæµ‹è¯•éªŒè¯ä¸“å®¶ã€‚ä½ éœ€è¦åˆ†ææµ‹è¯•ç”¨ä¾‹çš„æ‰§è¡Œç»“æœï¼Œåˆ¤æ–­å…¶æ­£ç¡®æ€§ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.1,
        "max_tokens": 2000
    }

    # è®°å½•å‘é€ç»™GPTçš„è¯·æ±‚ä¿¡æ¯
    logger.log("-" * 60)
    logger.log(f"ç¬¬{turn_index + 1}è½® - å‘é€ç»™GPT-4.1çš„è¯·æ±‚:")
    logger.log(f"URL: {url}")
    logger.log(f"å®Œæ•´Prompt:")
    logger.log(prompt)
    logger.log("-" * 60)

    try:
        async with session.post(url, headers=headers, json=data, timeout=60) as response:
            if response.status != 200:
                error_text = await response.text()
                logger.log(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}", "ERROR")
                raise Exception(f"Azure OpenAI APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}")

            result = await response.json()
            validation_text = result['choices'][0]['message']['content']

            # è®°å½•GPTå“åº”
            logger.log("GPT-4.1åŸå§‹å“åº”:")
            logger.log("-" * 60)
            logger.log(validation_text)
            logger.log("-" * 60)

            # å°è¯•è§£æJSON
            validation_data = None
            try:
                validation_data = json.loads(validation_text)
                logger.log("JSONè§£ææˆåŠŸ")
            except json.JSONDecodeError:
                # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSON
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', validation_text, re.DOTALL)
                if json_match:
                    try:
                        validation_data = json.loads(json_match.group(1))
                        logger.log("ä»ä»£ç å—ä¸­æå–JSONæˆåŠŸ")
                    except json.JSONDecodeError:
                        logger.log("ä»ä»£ç å—æå–JSONå¤±è´¥", "WARNING")
                        validation_data = None

            if validation_data:
                result = {
                    'turn_id': turn_id,
                    'turn_index': turn_index,
                    'is_correct': validation_data.get('is_correct', 'unknown'),
                    'score': validation_data.get('overall_score', 0),
                    'dimension_scores': validation_data.get('dimension_scores', {}),
                    'issues': validation_data.get('key_issues', []),
                    'suggestions': validation_data.get('suggestions', []),
                    'reasoning': validation_data.get('detailed_analysis', ''),
                    'status': 'success',
                    'raw_prompt': prompt,
                    'raw_response': validation_text
                }
                logger.log(f"  ç¬¬{turn_index + 1}è½®éªŒè¯ç»“æœ: {result['is_correct']}, è¯„åˆ†: {result['score']}/10")
                logger.log(f"  ç»´åº¦åˆ†æ•°: {result['dimension_scores']}")
                logger.log(f"  ä¸»è¦é—®é¢˜: {result['issues']}")
                return result
            else:
                logger.log("  æ— æ³•è§£æéªŒè¯ç»“æœ", "ERROR")
                return {
                    'turn_id': turn_id,
                    'turn_index': turn_index,
                    'is_correct': 'unknown',
                    'score': 0,
                    'dimension_scores': {},
                    'issues': ['æ— æ³•è§£æéªŒè¯ç»“æœ'],
                    'suggestions': [],
                    'reasoning': validation_text,
                    'status': 'failed',
                    'raw_prompt': prompt,
                    'raw_response': validation_text
                }

    except Exception as e:
        logger.log(f"  ç¬¬{turn_index + 1}è½®éªŒè¯å¤±è´¥: {str(e)}", "ERROR")
        return {
            'turn_id': turn_id,
            'turn_index': turn_index,
            'is_correct': 'error',
            'score': 0,
            'dimension_scores': {},
            'issues': [f'éªŒè¯å¤±è´¥: {str(e)}'],
            'suggestions': [],
            'reasoning': '',
            'status': 'failed'
        }


async def validate_single_case(session, test_case, case_index=0):
    """éªŒè¯å•ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼ˆæ”¯æŒå¤šè½®ï¼‰"""
    test_case_id = test_case.get('test_case_id', 'unknown')
    turn_results = test_case.get('turn_results', [])

    logger.log("="*80)
    logger.log(f"æµ‹è¯•ç”¨ä¾‹ #{case_index + 1}: {test_case_id}")
    logger.log(f"æ€»è½®æ•°: {len(turn_results)}")
    logger.log("="*80)

    # è·å–åŸºå‡†æ—¶é—´æˆ³ç”¨äºæ—¶é—´åˆ¤æ–­
    base_timestamp = test_case.get('timestamp', '')
    # è§£ææ—¶é—´æˆ³å¹¶è·å–æ˜ŸæœŸå‡ 
    try:
        from datetime import datetime
        dt = datetime.fromisoformat(base_timestamp.replace('Z', '+00:00'))
        weekday_cn = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][dt.weekday()]
        base_timestamp_with_weekday = f"{base_timestamp} ({weekday_cn})"
    except:
        base_timestamp_with_weekday = base_timestamp

    logger.log(f"åŸºå‡†æ—¶é—´æˆ³: {base_timestamp_with_weekday}")

    # éªŒè¯æ‰€æœ‰turns
    turn_validation_results = []
    for turn_index, turn_result in enumerate(turn_results):
        logger.log("")  # ç©ºè¡Œåˆ†éš”
        logger.log(f"å¼€å§‹éªŒè¯ç¬¬{turn_index + 1}è½® (å…±{len(turn_results)}è½®)")
        turn_validation_result = await validate_single_turn(
            session, test_case_id, turn_result, turn_index,
            base_timestamp_with_weekday, logger
        )
        turn_validation_results.append(turn_validation_result)
        logger.log(f"ç¬¬{turn_index + 1}è½®éªŒè¯å®Œæˆï¼ŒçŠ¶æ€: {turn_validation_result['status']}")

    logger.log(f"æ‰€æœ‰è½®æ¬¡éªŒè¯å®Œæˆï¼Œå…±éªŒè¯{len(turn_validation_results)}è½®")

    # èšåˆæ‰€æœ‰turnsçš„åˆ†æ•°
    total_score = sum(r['score'] for r in turn_validation_results if r['status'] == 'success')
    num_successful_turns = sum(1 for r in turn_validation_results if r['status'] == 'success')
    avg_score = (total_score / num_successful_turns) if num_successful_turns > 0 else 0

    # è®¡ç®—ç»´åº¦å¹³å‡åˆ†
    dimension_scores = {}
    if num_successful_turns > 0:
        all_dimensions = set()
        for r in turn_validation_results:
            if r['status'] == 'success':
                all_dimensions.update(r['dimension_scores'].keys())

        for dim in all_dimensions:
            dim_scores = [
                r['dimension_scores'].get(dim, 0)
                for r in turn_validation_results
                if r['status'] == 'success' and dim in r['dimension_scores']
            ]
            dimension_scores[dim] = sum(dim_scores) / len(dim_scores) if dim_scores else 0

    # åˆ¤æ–­æ•´ä½“æ­£ç¡®æ€§ï¼šæ‰€æœ‰turnséƒ½æ­£ç¡®æ‰ç®—æ­£ç¡®
    all_correct = all(r['is_correct'] == 'æ­£ç¡®' for r in turn_validation_results if r['status'] == 'success')
    any_error = any(r['is_correct'] == 'é”™è¯¯' for r in turn_validation_results if r['status'] == 'success')

    overall_is_correct = 'æ­£ç¡®' if all_correct else ('é”™è¯¯' if any_error else 'unknown')

    # æ±‡æ€»æ‰€æœ‰é—®é¢˜å’Œå»ºè®®
    all_issues = []
    all_suggestions = []
    all_reasoning = []
    logger.log(f"å¼€å§‹æ±‡æ€»{len(turn_validation_results)}è½®çš„ç»“æœ")
    for r in turn_validation_results:
        logger.log(f"  å¤„ç†ç¬¬{r['turn_index'] + 1}è½®ï¼ŒçŠ¶æ€: {r['status']}")
        if r['status'] == 'success':
            issue_prefix = f"ç¬¬{r['turn_index'] + 1}è½®: "
            all_issues.extend([issue_prefix + str(issue) for issue in r['issues']])
            all_suggestions.extend([issue_prefix + str(suggestion) for suggestion in r['suggestions']])
            if r.get('reasoning'):
                reasoning_prefix = f"ç¬¬{r['turn_index'] + 1}è½®åˆ†æ: "
                all_reasoning.append(reasoning_prefix + str(r['reasoning']))
        else:
            logger.log(f"    è·³è¿‡ç¬¬{r['turn_index'] + 1}è½®ï¼ŒçŠ¶æ€ésuccess")

    logger.log(f"æ±‡æ€»å®Œæˆï¼Œå…±{len(all_issues)}ä¸ªé—®é¢˜ï¼Œ{len(all_suggestions)}ä¸ªå»ºè®®")

    # æ„å»ºæœ€ç»ˆç»“æœ
    final_result = {
        'test_case_id': test_case_id,
        'is_correct': overall_is_correct,
        'score': avg_score,
        'dimension_scores': dimension_scores,
        'issues': all_issues,
        'suggestions': all_suggestions,
        'reasoning': '\n\n'.join(all_reasoning),
        'status': 'success' if num_successful_turns == len(turn_results) else 'partial',
        'turn_count': len(turn_results),
        'successful_turns': num_successful_turns,
        'turn_details': turn_validation_results,
        'aggregated': True
    }

    # æ‰“å°æ±‡æ€»ç»“æœ
    logger.log("")
    logger.log("="*80)
    logger.log(f"æµ‹è¯•ç”¨ä¾‹æ±‡æ€»: {test_case_id}")
    logger.log(f"æ€»è½®æ•°: {len(turn_results)}")
    logger.log(f"æˆåŠŸéªŒè¯è½®æ•°: {num_successful_turns}")
    logger.log(f"æ•´ä½“æ­£ç¡®æ€§: {overall_is_correct}")
    logger.log(f"å¹³å‡è¯„åˆ†: {avg_score:.2f}/10")
    logger.log(f"ç»´åº¦åˆ†æ•°: {dimension_scores}")
    logger.log("="*80)

    return final_result
async def main():
    """ä¸»å‡½æ•°"""
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    import os
    os.makedirs("test_dataset_quantity/validation_reports", exist_ok=True)

    test_file = "test_dataset_quantity/test_results_74_merged_20260121_201332-gemini.json"

    # è¯»å–æµ‹è¯•æ–‡ä»¶
    try:
        with open(test_file, 'r', encoding='utf-8') as f:
            test_cases = json.load(f)
    except FileNotFoundError:
        logger.log(f"é”™è¯¯: æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}", "ERROR")
        return
    except Exception as e:
        logger.log(f"é”™è¯¯: è¯»å–æµ‹è¯•æ–‡ä»¶å¤±è´¥: {e}", "ERROR")
        return

    logger.log(f"è¯»å–åˆ° {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    print(f"è¯»å–åˆ° {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    print(f"å°†éªŒè¯å‰ 5 ä¸ªæµ‹è¯•ç”¨ä¾‹")
    print()

    # åªå–å‰5ä¸ªæµ‹è¯•ç”¨ä¾‹è¿›è¡Œæµ‹è¯•
    test_cases_to_validate = test_cases[:]

    results = []
    problem_cases = []  # è®°å½•é”™è¯¯ç”¨ä¾‹

    try:
        async with aiohttp.ClientSession() as session:
            for i, test_case in enumerate(test_cases_to_validate):
                logger.log(f"å¼€å§‹éªŒè¯ç¬¬ {i+1}/{len(test_cases_to_validate)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                print(f"æ­£åœ¨éªŒè¯ç¬¬ {i+1}/{len(test_cases_to_validate)} ä¸ª: {test_case.get('test_case_id')}")

                result = await validate_single_case(session, test_case, i)
                results.append(result)

                # è®°å½•é—®é¢˜ç”¨ä¾‹
                if result['is_correct'] == 'é”™è¯¯':
                    problem_cases.append(result)
                    logger.log(f"âš ï¸ å‘ç°é—®é¢˜ç”¨ä¾‹: {result['test_case_id']} - {result['is_correct']}")
                else:
                    logger.log(f"âœ… æ­£å¸¸ç”¨ä¾‹: {result['test_case_id']} - {result['is_correct']}")

                print(f"  ç»“æœ: {result['is_correct']}, è¯„åˆ†: {result['score']}/10")
                if result['issues']:
                    print(f"  é—®é¢˜: {', '.join(result['issues'][:2])}")
                print()

    except Exception as e:
        logger.log(f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", "ERROR")
        print(f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    # æ‰“å°æ‘˜è¦
    logger.log("="*80)
    logger.log("éªŒè¯æ‘˜è¦")
    logger.log("="*80)
    print("="*60)
    print("éªŒè¯æ‘˜è¦")
    print("="*60)

    total = len(results)
    successful = sum(1 for r in results if r['status'] == 'success')
    failed = total - successful

    logger.log(f"æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {total}")
    logger.log(f"éªŒè¯æˆåŠŸ: {successful}")
    logger.log(f"éªŒè¯å¤±è´¥: {failed}")
    print(f"æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {total}")
    print(f"éªŒè¯æˆåŠŸ: {successful}")
    print(f"éªŒè¯å¤±è´¥: {failed}")

    # è®¡ç®—æ­£ç¡®ç‡ï¼ˆåŸºäºæ‰€æœ‰éªŒè¯æˆåŠŸçš„æµ‹è¯•ç”¨ä¾‹ï¼‰
    correct = sum(1 for r in results if r['status'] == 'success' and r['is_correct'] == 'æ­£ç¡®')
    wrong = sum(1 for r in results if r['status'] == 'success' and r['is_correct'] == 'é”™è¯¯')
    accuracy = (correct / total * 100) if total > 0 else 0

    if successful > 0:
        logger.log(f"  æ­£ç¡®: {correct}")
        logger.log(f"  é”™è¯¯: {wrong}")
        logger.log(f"  æ­£ç¡®ç‡: {accuracy:.1f}%")
        print(f"  æ­£ç¡®: {correct}")
        print(f"  é”™è¯¯: {wrong}")
        print(f"  æ­£ç¡®ç‡: {accuracy:.1f}%")

        avg_score = sum(r['score'] for r in results if r['status'] == 'success') / successful
        logger.log(f"å¹³å‡è¯„åˆ†: {avg_score:.2f}/10")
        print(f"å¹³å‡è¯„åˆ†: {avg_score:.2f}/10")

    # è¯¦ç»†å¤„ç†é—®é¢˜ç”¨ä¾‹
    logger.log("")
    logger.log("="*80)
    logger.log("é—®é¢˜ç”¨ä¾‹è¯¦ç»†åˆ†æ")
    logger.log("="*80)
    if problem_cases:
        logger.log(f"å‘ç° {len(problem_cases)} ä¸ªé—®é¢˜ç”¨ä¾‹:")

        for i, case in enumerate(problem_cases):
            logger.log("")
            logger.log(f"é—®é¢˜ç”¨ä¾‹ #{i+1}: {case['test_case_id']}")
            logger.log(f"  æ­£ç¡®æ€§: {case['is_correct']}")
            logger.log(f"  è¯„åˆ†: {case['score']}/10")
            logger.log(f"  é—®é¢˜: {case['issues']}")
            logger.log(f"  æ¨ç†: {case.get('reasoning', '')[:200]}...")

            # è®°å½•åŸå§‹è¾“å…¥è¾“å‡º
            logger.log("  è¯¦ç»†ä¿¡æ¯:")
            logger.log(f"    ç”¨æˆ·è¾“å…¥: {case.get('user_input', {}).get('content', '')}")
            logger.log(f"    æœŸæœ›æ­¥éª¤: {case.get('expected_behavior', {}).get('steps', [])}")
            logger.log(f"    å®Œæ•´åŸå§‹Prompt:")
            logger.log(case.get('raw_prompt', ''))
            logger.log(f"    å®Œæ•´GPTå“åº”:")
            logger.log(case.get('raw_response', ''))
    else:
        logger.log("âœ… æ²¡æœ‰å‘ç°é—®é¢˜ç”¨ä¾‹!")

    print()
    print("è¯¦ç»†ç»“æœ:")

    for result in results:
        print(f"\n{result['test_case_id']}:")
        print(f"  æ­£ç¡®æ€§: {result['is_correct']}")
        print(f"  è¯„åˆ†: {result['score']}/10")
        if 'turn_count' in result and result['turn_count'] > 1:
            print(f"  æ€»è½®æ•°: {result['turn_count']}")
            # æ˜¾ç¤ºæ¯è½®çš„åˆ†æ•°
            if 'turn_details' in result:
                print(f"  å„è½®åˆ†æ•°:")
                for turn in result['turn_details']:
                    if turn.get('status') == 'success':
                        print(f"    ç¬¬{turn['turn_index'] + 1}è½®: {turn['score']}/10 - {turn['is_correct']}")
                    else:
                        print(f"    ç¬¬{turn['turn_index'] + 1}è½®: éªŒè¯å¤±è´¥")
        if result['dimension_scores']:
            print(f"  ç»´åº¦åˆ†æ•°: {result['dimension_scores']}")
        if result['issues']:
            print(f"  é—®é¢˜: {'; '.join(result['issues'])}")
        if result['reasoning']:
            print(f"  åˆ†æ: {result['reasoning'][:100]}...")

    # ä¿å­˜ç»“æœ
    output_file = f"test_dataset_quantity/validation_reports/validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

    final_report = {
        'validation_summary': {
            'total_cases': total,
            'successful': successful,
            'failed': failed,
            'success_rate': successful / total if total > 0 else 0,
            'correct_count': correct,
            'wrong_count': wrong,
            'accuracy_rate': accuracy,
            'average_score': avg_score if successful > 0 else 0
        },
        'validation_details': results,
        'problem_cases': problem_cases,
        'log_file': str(LOG_FILE),  # å°†Pathå¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        'timestamp': datetime.now().isoformat()
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)

    logger.log(f"\néªŒè¯å®Œæˆ!")
    logger.log(f"JSONæŠ¥å‘Š: {output_file}")
    logger.log(f"è¯¦ç»†æ—¥å¿—: {LOG_FILE}")

    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"è¯¦ç»†æ—¥å¿—: {LOG_FILE}")
    print("="*60)

    # ä¿å­˜æ—¥å¿—æ–‡ä»¶
    logger.save()

    return final_report


if __name__ == '__main__':
    asyncio.run(main())
