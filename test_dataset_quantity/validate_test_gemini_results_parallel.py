#!/usr/bin/env python3
"""
æµ‹è¯•ç»“æœéªŒè¯è„šæœ¬ - å¹¶è¡Œå¤„ç†ç‰ˆæœ¬ï¼ˆç®€æ´ç‰ˆï¼‰
ä½¿ç”¨Gemini-3-Flash-PreviewéªŒè¯chat APIæµ‹è¯•ç»“æœçš„æ­£ç¡®æ€§
"""

import json
import asyncio
import aiohttp
import os
import sys
import time
import argparse
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import threading

# åŠ è½½.envæ–‡ä»¶
load_dotenv('/home/libo/chatapi/.env')

# OpenAI é…ç½®ï¼ˆGemini-3-Flash-Previewï¼‰
openai_api_key: str = os.getenv("OPENAI_API_KEY", "sk-hk69mLmsHF6FfIM8cPn2Zitfk0Jca6suzwIptZymPn6h1u6x")
openai_base_url: str = os.getenv("OPENAI_BASE_URL", "https://llm.onerouter.pro/v1")
openai_model: str = os.getenv("OPENAI_MODEL", "gemini-3-flash-preview")

# åˆ›å»ºæ—¥å¿—ç›®å½•
SCRIPT_DIR = Path(__file__).parent
LOG_DIR = SCRIPT_DIR / "logs"
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = LOG_DIR / f"validation_parallel_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

# çº¿ç¨‹é”ç”¨äºæ—¥å¿—å†™å…¥
log_lock = threading.Lock()

# ç®€å•æ—¥å¿—è®°å½•å™¨ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰
class Logger:
    def __init__(self, log_file):
        self.log_file = log_file
        self.buffer = []

    def log(self, message, level="INFO"):
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_msg = f"[{timestamp}] [{level}] {message}"

        # çº¿ç¨‹å®‰å…¨çš„ç¼“å†²
        with log_lock:
            self.buffer.append(log_msg)

    def save(self):
        with log_lock:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(self.buffer))

logger = Logger(LOG_FILE)

print("="*60)
print("æµ‹è¯•ç»“æœéªŒè¯å·¥å…· - å¹¶è¡Œå¤„ç†ç‰ˆæœ¬ (ä½¿ç”¨ Gemini-3-Flash-Preview)")
print("="*60)
print()

logger.log("å¼€å§‹éªŒè¯è¿‡ç¨‹ - å¹¶è¡Œç‰ˆæœ¬")
logger.log(f"OpenAIé…ç½®:")
logger.log(f"  Base URL: {openai_base_url}")
logger.log(f"  æ¨¡å‹: {openai_model}")
logger.log(f"  API Key: {openai_api_key[:10]}...")
logger.log(f"æ—¥å¿—æ–‡ä»¶: {LOG_FILE}")
print()
print("ğŸš€ æ–°å¢åŠŸèƒ½ï¼šå¹¶è¡Œå¤„ç†")
print("  é»˜è®¤å¹¶å‘æ•°ï¼š5ä¸ª")
print("ğŸ”§ å¤±è´¥é‡è¯•æœºåˆ¶ï¼š")
print("  é»˜è®¤é‡è¯•æ¬¡æ•°ï¼š5æ¬¡")
print("  ç¦ç”¨é‡è¯•ï¼š--no-retry")
print("  è‡ªå®šä¹‰é‡è¯•æ¬¡æ•°ï¼š--retry <æ¬¡æ•°>")
print()


async def validate_single_turn(session, test_case_id, turn_result, turn_index, base_timestamp_with_weekday, logger, previous_turns=None):
    """éªŒè¯å•ä¸ªturnï¼ˆæ”¯æŒå¤šè½®ä¸Šä¸‹æ–‡ï¼‰

    Args:
        session: HTTPä¼šè¯
        test_case_id: æµ‹è¯•ç”¨ä¾‹ID
        turn_result: å½“å‰è½®çš„ç»“æœ
        turn_index: å½“å‰è½®ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
        base_timestamp_with_weekday: åŸºå‡†æ—¶é—´
        logger: æ—¥å¿—è®°å½•å™¨
        previous_turns: å‰é¢çš„è½®æ¬¡æ•°æ®åˆ—è¡¨ï¼Œç”¨äºæä¾›ä¸Šä¸‹æ–‡
    """
    turn_id = turn_result.get('turn_id', f'turn_{turn_index}')
    user_input = turn_result.get('user_input', {})
    execution_result = turn_result.get('execution_result', {})
    expected_behavior = turn_result.get('expected_behavior', {})

    # åˆå§‹åŒ–å†å²è½®æ¬¡åˆ—è¡¨
    if previous_turns is None:
        previous_turns = []

    logger.log(f"  â”€â”€ ç¬¬{turn_index + 1}è½®å¯¹è¯ â”€â”€")
    logger.log(f"  Turn ID: {turn_id}")

    # è®°å½•ç”¨æˆ·è¾“å…¥
    if user_input.get('type') == 'text':
        input_display = f"æ–‡æœ¬è¾“å…¥: {user_input.get('content', '')}"
    elif user_input.get('type') == 'image':
        input_display = f"å›¾åƒè¾“å…¥: {user_input.get('content', '')}"
    else:
        input_display = f"è¾“å…¥: {json.dumps(user_input, ensure_ascii=False, indent=2)}"

    logger.log(f"  ç”¨æˆ·è¾“å…¥: {user_input.get('content', '')}")
    logger.log(f"  è¾“å…¥ç±»å‹: {user_input.get('type')}")

    # ğŸ”§ æ”¯æŒå¤šè·¯å¾„æœŸæœ›æ ¼å¼
    # æ–°æ ¼å¼ï¼šexpected_behavior æ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å«å¤šä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„
    expected_behavior_paths = expected_behavior if isinstance(expected_behavior, list) else []
    # æ—§æ ¼å¼å…¼å®¹ï¼šsteps æ•°ç»„
    expected_steps = expected_behavior.get('steps', []) if isinstance(expected_behavior, dict) else []

    logger.log(f"  å¤šè·¯å¾„æœŸæœ›æ•°: {len(expected_behavior_paths)}")
    logger.log(f"  ä¼ ç»Ÿæ­¥éª¤æœŸæœ›æ•°: {len(expected_steps)}")

    # ä¼˜å…ˆä½¿ç”¨å¤šè·¯å¾„æ ¼å¼
    if expected_behavior_paths:
        logger.log("  âœ… ä½¿ç”¨å¤šè·¯å¾„æœŸæœ›æ ¼å¼:")
        logger.log(f"    ğŸ“ å…±{len(expected_behavior_paths)}ä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„")
        for i, path in enumerate(expected_behavior_paths):
            desc = path.get('description', f'è·¯å¾„{i+1}')
            steps = path.get('steps', [])
            logger.log(f"    è·¯å¾„ {i+1}: {desc}")
            logger.log(f"      æ­¥éª¤æ•°: {len(steps)}")
            for j, step in enumerate(steps):
                step_type = step.get('type', '')
                tool_name = step.get('tool_name', '')
                logger.log(f"        æ­¥éª¤{j+1}: {step_type} - {tool_name}")
        logger.log(f"    ğŸ¯ éªŒè¯è§„åˆ™: åªè¦å®é™…æ‰§è¡Œç¬¦åˆä»»ä¸€è·¯å¾„ï¼Œå³åˆ¤å®šæ­£ç¡®")
    elif expected_steps:
        logger.log("  ğŸ“‹ ä½¿ç”¨ä¼ ç»Ÿæ­¥éª¤æœŸæœ›æ ¼å¼:")
        for i, step in enumerate(expected_steps):
            logger.log(f"    æ­¥éª¤ {i+1}: {json.dumps(step, ensure_ascii=False)}")
    else:
        logger.log("  âš ï¸ æœªæ‰¾åˆ°æœŸæœ›è¡Œä¸ºæ•°æ®")

    # æ ¼å¼åŒ–å®é™…æ‰§è¡Œç»“æœ
    actual_tool_calls = []
    tool_results = []
    assistant_responses = []
    if 'raw_data' in execution_result:
        for item in execution_result['raw_data']:
            if item.get('type') == 'tool' or (item.get('role') == 'assistant' and item.get('type') == 'tool'):
                content = item.get('content', {})
                if content.get('status') == 'start':
                    actual_tool_calls.append({
                        'tool_name': content.get('name', ''),
                        'tool_cn': content.get('name_cn', ''),
                        'arguments': content.get('arguments', ''),
                    })
                elif content.get('status') == 'success':
                    tool_results.append({
                        'tool_name': content.get('name', ''),
                        'observation': content.get('observation', '')
                    })
            elif item.get('type') == 'markdown' or (item.get('role') == 'assistant' and item.get('type') == 'markdown'):
                assistant_responses.append({
                    'message_id': item.get('message_id', ''),
                    'content': item.get('content', ''),
                    'is_merged': item.get('is_merged', False),
                    'original_fragments': item.get('original_fragments', 1)
                })

    logger.log(f"  å®é™…å·¥å…·è°ƒç”¨æ•°: {len(actual_tool_calls)}")
    for i, tool_call in enumerate(actual_tool_calls):
        logger.log(f"    å·¥å…· {i+1}: {tool_call.get('tool_name')} - {tool_call.get('tool_cn', '')}")
        logger.log(f"      å‚æ•°: {tool_call.get('arguments', '')}")

    logger.log(f"  å·¥å…·æ‰§è¡Œç»“æœæ•°: {len(tool_results)}")
    logger.log(f"  Assistantå“åº”æ•°: {len(assistant_responses)}")
    for i, response in enumerate(assistant_responses):
        logger.log(f"    å“åº” {i+1}: {response.get('content', '')[:100]}...")

    # ğŸ”§ æ„å»ºå¤šè·¯å¾„éªŒè¯prompt
    if expected_behavior_paths:
        # ä½¿ç”¨å¤šè·¯å¾„æ ¼å¼
        expected_content = json.dumps(expected_behavior_paths, ensure_ascii=False, indent=2)
        prompt_header = "## æœŸæœ›è¡Œä¸º (å¤šè·¯å¾„æ ¼å¼)\næ³¨æ„ï¼šexpected_behavioræ˜¯ä¸€ä¸ªæ•°ç»„ï¼ŒåŒ…å«å¤šä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„ã€‚åªè¦å®é™…æ‰§è¡Œç¬¦åˆå…¶ä¸­ä¸€ä¸ªè·¯å¾„ï¼Œå³ä¸ºæ­£ç¡®ã€‚\n"
    elif expected_steps:
        # ä½¿ç”¨ä¼ ç»Ÿæ ¼å¼
        expected_content = json.dumps(expected_steps, ensure_ascii=False, indent=2)
        prompt_header = "## æœŸæœ›è¡Œä¸º (ä¼ ç»Ÿæ ¼å¼)\n"
    else:
        expected_content = "æœªæ‰¾åˆ°æœŸæœ›è¡Œä¸ºæ•°æ®"
        prompt_header = "## æœŸæœ›è¡Œä¸º\n"

    # æ„å»ºAssistantå“åº”çš„markdownå†…å®¹
    assistant_responses_summary = ""
    if assistant_responses:
        assistant_responses_summary = "\n## åˆå¹¶åçš„Assistantå“åº”\n"
        for i, response in enumerate(assistant_responses):
            # æ„å»ºåˆå¹¶åçš„å“åº”ä¿¡æ¯
            content = response.get('content', '')
            is_merged = response.get('is_merged', False)
            fragments = response.get('original_fragments', 1)

            assistant_responses_summary += f"\n### å“åº” {i+1}:\n"
            assistant_responses_summary += f"{content}\n"

            if is_merged and fragments > 1:
                assistant_responses_summary += f"*(æ³¨: æ­¤å“åº”ç”±{fragments}ä¸ªæµå¼ç‰‡æ®µåˆå¹¶è€Œæˆ)*\n"

    # ğŸ”§ æ„å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡
    history_context = ""
    if previous_turns:
        history_context = "æ³¨æ„ï¼šè¿™æ˜¯å¤šè½®å¯¹è¯ä¸­çš„ç¬¬" + str(turn_index + 1) + "è½®ï¼Œä»¥ä¸‹æ˜¯å‰é¢è½®æ¬¡çš„å¯¹è¯å†å²ä¾›å‚è€ƒï¼š\n\n"
        for i, prev_turn in enumerate(previous_turns):
            history_context += f"### ç¬¬{i + 1}è½®å¯¹è¯\n"

            # è·å–å†å²è½®æ¬¡çš„ç”¨æˆ·è¾“å…¥
            prev_user_input = prev_turn.get('user_input', {})
            if prev_user_input.get('type') == 'text':
                history_context += f"**ç”¨æˆ·è¾“å…¥**: {prev_user_input.get('content', '')}\n"
            elif prev_user_input.get('type') == 'image':
                history_context += f"**å›¾åƒè¾“å…¥**: {prev_user_input.get('content', '')}\n"

            # è·å–å†å²è½®æ¬¡çš„æ‰§è¡Œç»“æœ
            prev_execution_result = prev_turn.get('execution_result', {})
            prev_tool_calls = []
            prev_assistant_responses = []

            if 'raw_data' in prev_execution_result:
                for item in prev_execution_result['raw_data']:
                    if item.get('type') == 'tool' or (item.get('role') == 'assistant' and item.get('type') == 'tool'):
                        content = item.get('content', {})
                        if content.get('status') == 'start':
                            prev_tool_calls.append({
                                'tool_name': content.get('name', ''),
                                'tool_cn': content.get('name_cn', ''),
                                'arguments': content.get('arguments', ''),
                            })
                    elif item.get('type') == 'markdown' or (item.get('role') == 'assistant' and item.get('type') == 'markdown'):
                        prev_assistant_responses.append({
                            'content': item.get('content', ''),
                        })

            # è®°å½•å†å²å·¥å…·è°ƒç”¨
            if prev_tool_calls:
                history_context += f"**å®é™…è°ƒç”¨çš„å·¥å…·**: {json.dumps(prev_tool_calls, ensure_ascii=False, indent=2)}\n"
            else:
                history_context += "**å®é™…è°ƒç”¨çš„å·¥å…·**: []\n"

            # è®°å½•å†å²Assistantå“åº”
            if prev_assistant_responses:
                history_context += "**Assistantå“åº”**:\n"
                for j, response in enumerate(prev_assistant_responses):
                    content = response.get('content', '')
                    history_context += f"- {content}\n"

            history_context += "\n"

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç³»ç»Ÿæµ‹è¯•éªŒè¯ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹æµ‹è¯•ç”¨ä¾‹çš„æ‰§è¡Œç»“æœï¼Œåˆ¤æ–­å…¶æ­£ç¡®æ€§ã€‚

## æµ‹è¯•ç”¨ä¾‹ä¿¡æ¯
æµ‹è¯•ID: {test_case_id}
{input_display}

## æ—¶é—´ä¿¡æ¯
æµ‹è¯•åŸºå‡†æ—¶é—´: {base_timestamp_with_weekday}
æ³¨ï¼šç”¨æˆ·è¾“å…¥ä¸­çš„"ä»Šå¤©ä¸‹åˆä¸¤ç‚¹"ç­‰ç›¸å¯¹æ—¶é—´è¡¨è¾¾åº”åŸºäºæ­¤åŸºå‡†æ—¶é—´æ¥åˆ¤æ–­
**å…³äºæ—¶é—´åˆ¤æ–­ï¼Œä½ å¿…é¡»éµå®ˆä»¥ä¸‹é¦–è¦è§„åˆ™ï¼š**
1.  **å¿½ç•¥æœŸæœ›æ—¶é—´**ï¼š  åœ¨è¯„ä¼°"æ—¶é—´åˆ¤æ–­å‡†ç¡®æ€§"æ—¶ï¼Œ**è¯·å®Œå…¨å¿½ç•¥æµ‹è¯•ç”¨ä¾‹ä¸­"æœŸæœ›æ‰§è¡Œæ­¥éª¤"é‡Œçš„start_time,å®ƒå¯èƒ½ä¸æœ¬æ¬¡è¯„æµ‹çš„åŸºå‡†æ—¶é—´ä¸ç¬¦ï¼Œä¸å…·å¤‡å‚è€ƒä»·å€¼**
2.  **å”¯ä¸€æ—¶é—´åŸºå‡†**ï¼šæ‰€æœ‰å…³äº"ä»Šå¤©"ã€"æ˜å¤©"ã€"ä¸‹å‘¨"ç­‰ç›¸å¯¹æ—¶é—´çš„æ­£ç¡®æ€§åˆ¤æ–­ï¼Œ**æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªæ­£ç¡®æ ‡å‡†ï¼šå³åŸºäºä¸‹æ–¹æä¾›çš„"æµ‹è¯•åŸºå‡†æ—¶é—´"è¿›è¡Œæ¨ç®—çš„ç»“æœ**ã€‚
3.  **éªŒè¯å®é™…æ—¶é—´**ï¼šä½ åªéœ€åˆ¤æ–­"å®é™…è°ƒç”¨çš„å·¥å…·"ä¸­çš„æ—¶é—´å‚æ•°ï¼Œæ˜¯å¦ä¸åŸºäº**æµ‹è¯•åŸºå‡†æ—¶é—´**æ¨ç®—å‡ºçš„æ­£ç¡®æ—¶é—´ç›¸åŒ¹é…ï¼Œå¯ä»¥è¿œè¶…åŸºå‡†æ—¶é—´ åˆç†å°±è¡Œã€‚
å‚è€ƒä¸‹é¢ä¸¤ä¸ªä¾‹å­ ä¸‹é¢ä¸¤ä¸ªä¾‹å­è¯„ä¼°é”™è¯¯ è™½ç„¶ä¸é¢„æœŸä¸ç¬¦ä½†æ˜¯å®é™…ç»“æœæ˜¯æ­£ç¡®çš„ é‚£æ—¶é—´å‡†ç¡®æ€§è¿™ä¸€é¡¹åˆ†æ•°åº”è¯¥æ˜¯10åˆ†
- "æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ï¼š'åå¤©ä¸­åˆ'åŸºäºåŸºå‡†æ—¶é—´2026-01-16T10:45:59åº”ä¸º2026-01-18T12:00:00ï¼Œä½†å®é™…åˆ›å»ºæ—¶é—´ä¸º2026-01-18T12:00:00ï¼Œè¡¨é¢çœ‹ä¼¼æ­£ç¡®ï¼Œä½†å®é™…ä¸Š'åå¤©'åº”ä¸º2026-01-18ï¼Œå®é™…å‚æ•°æ˜¯æ­£ç¡®çš„ã€‚"

- ç”¨æˆ·è¾“å…¥ä¸º'ä¸‹å‘¨å››'ï¼ŒåŸºå‡†æ—¶é—´ä¸º2026-01-16ï¼ˆå‘¨äº”ï¼‰ï¼Œä¸‹å‘¨å››åº”ä¸º2026-01-22ï¼Œä½†å®é™…åˆ›å»ºæ—¶é—´ä¸º2026-01-22ï¼Œå‚æ•°æ­£ç¡®ï¼Œä½†æœŸæœ›è¡Œä¸ºä¸­çš„æ—¶é—´ä¸º2026-01-23ï¼ŒæœŸæœ›è¡Œä¸ºæœ‰è¯¯ã€‚å®é™…æ‰§è¡Œç»“æœæ˜¯æ­£ç¡®çš„ æ—¶é—´å‚æ•°åˆ†æ•°åº”è¯¥ä¸ºé«˜åˆ†

## å†å²å¯¹è¯ä¸Šä¸‹æ–‡
{history_context}

## æœŸæœ›è¡Œä¸º
{prompt_header}
{expected_content}

## å®é™…æ‰§è¡Œç»“æœ
å®é™…è°ƒç”¨çš„å·¥å…·: {json.dumps(actual_tool_calls, ensure_ascii=False, indent=2)}
å·¥å…·æ‰§è¡Œç»“æœ: {json.dumps(tool_results, ensure_ascii=False, indent=2)}
æ‰§è¡ŒçŠ¶æ€: {execution_result.get('status', 'unknown')}
{assistant_responses_summary}
## éªŒè¯æ ‡å‡†
è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼ˆæ¯é¡¹1-10åˆ†ï¼Œ10åˆ†æœ€ä½³ï¼‰ï¼š

1. **å·¥å…·é€‰æ‹©å‡†ç¡®æ€§**: æ˜¯å¦é€‰æ‹©äº†æ­£ç¡®çš„å·¥å…·ï¼Ÿ
2. **å‚æ•°æå–å‡†ç¡®æ€§**: å·¥å…·å‚æ•°æ˜¯å¦å‡†ç¡®åæ˜ äº†ç”¨æˆ·æ„å›¾ï¼Ÿç‰¹åˆ«æ˜¯æ—¶é—´å‚æ•°æ˜¯å¦æ­£ç¡®ï¼Ÿå¯¹äºäººè„‰ é™¤äº†noteä¹‹å¤– å…¶ä»–è¦ä¸¥æ ¼ä¸€è‡´
    - reminder_timeè¦å®Œå…¨ç¬¦åˆç”¨æˆ·æ„å›¾ å¦åˆ™å¿…é¡»åˆ¤æ–­é”™è¯¯  å¦‚æ—¥ç¨‹æé†’æ—¶é—´(reminder_time)è®¾ç½®ä¸º-1dï¼Œæœªå®Œå…¨ç¬¦åˆç”¨æˆ·è¦æ±‚çš„æå‰ä¸€å‘¨(-1w)æé†’ åˆ¤æ–­ä¸ºé”™è¯¯
    - ä½¿ç”¨äº†é”™è¯¯çš„å‚æ•° åˆ¤æ–­ä¸ºé”™è¯¯ å¦‚å·¥å…·è°ƒç”¨æ—¶ä½¿ç”¨äº†é”™è¯¯çš„å‚æ•°å 'industry'ï¼Œå¯¼è‡´ Pydantic æ ¡éªŒå¤±è´¥æŠ¥é”™
3. **æ—¶é—´åˆ¤æ–­å‡†ç¡®æ€§**: å¯¹äºæ—¥ç¨‹ç›¸å…³æµ‹è¯•ï¼Œè¯·é‡ç‚¹æ£€æŸ¥ï¼š
   - å®é™…è°ƒç”¨ä¸­çš„æ—¶é—´å‚æ•°æ˜¯å¦åŸºäº**æµ‹è¯•åŸºå‡†æ—¶é—´**æ­£ç¡®è½¬æ¢ï¼Ÿå¦‚æœè½¬åŒ–æ­£ç¡® åˆ™è¿™é¡¹å‡†ç¡®æ€§åˆ†æ•°æ»¡åˆ†ã€‚è¯·ä¸¥æ ¼åº”ç”¨ä¸‹æ–¹"æ—¥æœŸæ˜ŸæœŸè®¡ç®—è§„åˆ™"ã€‚
   -  å¦‚æœæœŸæœ›æ—¶é—´æœ‰è¯¯ä½†ç¬¦åˆå®é™…å°±è¦ç»™10åˆ† è¿™ç§æƒ…å†µä¸‹ä¸èƒ½è¾“å‡ºæ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯
   -  å¯¹äºè¿™ç§æƒ…å†µ "æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ï¼š'æ˜å¤©æ™šä¸Šå…«ç‚¹'åº”ä¸º2026-01-17 20:00:00ï¼Œä½†å®é™…åˆ›å»ºåœ¨2026-01-17 20:00:00ï¼Œè¡¨é¢çœ‹ä¼¼æ­£ç¡®ï¼Œä½†åŸºå‡†æ—¶é—´ä¸º2026-01-16ï¼Œ'æ˜å¤©'åº”ä¸º2026-01-17ï¼Œå®é™…å‚æ•°æ˜¯æ­£ç¡®çš„ã€‚ è¿™ç§ä¸ç®—æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ ç®—å‚æ•°æå–æ­£ç¡®

4. **æ•°æ®å¤„ç†åˆç†æ€§**: æ•°æ®æ ¼å¼è½¬æ¢ã€é»˜è®¤å€¼å¤„ç†ç­‰æ˜¯å¦åˆç†ï¼Ÿ
5. **ä¸šåŠ¡é€»è¾‘æ­£ç¡®æ€§**: å¯¹ç”¨æˆ·éœ€æ±‚çš„ç†è§£å’Œå¤„ç†æ˜¯å¦æ­£ç¡®ï¼Ÿ
6. **å“åº”å®Œæ•´æ€§**:
   - **Markdownå“åº”å®Œæ•´æ€§**: æ£€æŸ¥Assistantçš„markdownå“åº”å†…å®¹æ˜¯å¦å®Œæ•´ã€å‡†ç¡®ï¼Œæ˜¯å¦é—æ¼é‡è¦ä¿¡æ¯ï¼Ÿ
   - **å“åº”è´¨é‡**: å“åº”å†…å®¹æ˜¯å¦æ¸…æ™°ã€å‡†ç¡®ã€æœ‰æ¡ç†ï¼Ÿ
   - **ä¿¡æ¯å‡†ç¡®æ€§**: å“åº”ä¸­çš„ä¿¡æ¯æ˜¯å¦ä¸å·¥å…·æ‰§è¡Œç»“æœä¸€è‡´ï¼Ÿ


## æ—¶é—´åˆ¤æ–­è¦æ±‚
å¦‚æœæ˜¯æ—¥ç¨‹ã€ä¼šè®®ç›¸å…³çš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¯·ç‰¹åˆ«å…³æ³¨ï¼š
- åŸºå‡†æ—¶é—´ï¼š{base_timestamp_with_weekday}
- ç”¨æˆ·è¯´"ä»Šå¤©ä¸‹åˆä¸¤ç‚¹"ï¼ŒåŸºå‡†æ—¶é—´æ˜¯{base_timestamp_with_weekday}
- é‚£ä¹ˆæœŸæœ›çš„å¼€å§‹æ—¶é—´åº”è¯¥æ˜¯å½“å¤©ä¸‹åˆ2ç‚¹ï¼ˆå³14:00ï¼‰
- å®é™…æ‰§è¡Œçš„æ—¶é—´å‚æ•°åº”è¯¥ä¸æœŸæœ›æ—¶é—´åŒ¹é…æˆ–åˆç†æ¥è¿‘

## æ—¥æœŸæ˜ŸæœŸè®¡ç®—è§„åˆ™
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™è¿›è¡Œæ—¥æœŸè®¡ç®—ï¼š
1. **æ—¥æœŸ-æ˜ŸæœŸå¯¹åº”**ï¼š
   - æ˜ŸæœŸä¸€ = å‘¨ä¸€ = å‘¨1
   - æ˜ŸæœŸäºŒ = å‘¨äºŒ = å‘¨2
   - æ˜ŸæœŸä¸‰ = å‘¨ä¸‰ = å‘¨3
   - æ˜ŸæœŸå›› = å‘¨å›› = å‘¨4
   - æ˜ŸæœŸäº” = å‘¨äº” = å‘¨5
   - æ˜ŸæœŸå…­ = å‘¨å…­ = å‘¨6
   - æ˜ŸæœŸæ—¥ = å‘¨æ—¥ = å‘¨7

2. **ç›¸å¯¹æ—¶é—´å¤„ç†**ï¼š
   - "ä¸‹å‘¨"æŒ‡çš„æ˜¯ï¼šä»åŸºå‡†æ—¶é—´å¼€å§‹é‡åˆ°çš„ç¬¬ä¸€ä¸ªå‘¨ä¸€å¼€å§‹åˆ°å‘¨æ—¥ç»“æŸçš„å®Œæ•´å‘¨  åŸºå‡†æ—¶é—´æ˜¯åœ¨å‘¨ä¸€ é‚£ä¹ˆä¸‹å‘¨æ˜¯ä»ä¸‹ä¸€ä¸ªå‘¨ä¸€å¼€å§‹ å¦‚åŸºå‡†æ—¶é—´ä¸º2026-01-19ï¼Œ'ä¸‹å‘¨'åº”ä¸º2026-01-26è‡³2026-02-01ã€‚
   - "ä¸‹å‘¨å››"æŒ‡çš„æ˜¯ï¼šä¸‹ä¸€å‘¨ä¸­çš„å‘¨å››
   - `"å‘¨X" = åŸºå‡†æ—¶é—´æ‰€åœ¨å‘¨å†…çš„æ˜ŸæœŸX å¦‚æœåŸºå‡†æ—¶é—´è¶…è¿‡å‘¨X åˆ™å¯ä»¥ç†è§£ä¸ºä¸‹å‘¨X
   - "ä¸‹å‘¨"æŒ‡çš„æ˜¯ï¼šä»ç¬¬ä¸€ä¸ªå‘¨ä¸€å¼€å§‹çš„å®Œæ•´ä¸€å‘¨
   - "ä¸‹ä¸ªæœˆ"æŒ‡çš„æ˜¯ï¼šåŸºå‡†æ—¶é—´æ‰€åœ¨æœˆçš„ä¸‹ä¸€ä¸ªæœˆ

3. **æ—¥æœŸè®¡ç®—ç¤ºä¾‹**ï¼š
   - å¦‚æœåŸºå‡†æ—¶é—´æ˜¯2026-01-19ï¼ˆå‘¨ä¸€ï¼‰
   - "å‘¨ä¸‰" = 2026-01-21
   - "ä¸‹å‘¨ä¸€" = 2026-01-26
   - "ä¸‹å‘¨å››" = 2026-01-29




## åˆ¤æ–­æ ‡å‡†
- **æ­£ç¡®**: å·¥å…·é€‰æ‹©æ­£ç¡®ï¼Œä¸»è¦å‚æ•°å‡†ç¡®(å¯ä»¥ä¸ä¸€è‡´ä½†åˆç†ã€ç›¸è¿‘å°±å¯ä»¥)ï¼Œæ—¶é—´åˆ¤æ–­æ­£ç¡®ï¼Œä¸šåŠ¡é€»è¾‘æ­£ç¡®
- **é”™è¯¯**: å·¥å…·é€‰æ‹©é”™è¯¯ï¼Œç†è§£å®Œå…¨é”™è¯¯æˆ–è€…æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯ã€æŸä¸ªå‚æ•°ä¸åˆç†ã€æŸä¸ªå‚æ•°ä¸é¢„æœŸå®Œå…¨ä¸ä¸€è‡´

## ğŸ”§ å¤šè·¯å¾„éªŒè¯è§„åˆ™
- **å¤šè·¯å¾„éªŒè¯**: å¦‚æœexpected_behavioræ˜¯æ•°ç»„æ ¼å¼ï¼ŒåŒ…å«å¤šä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„ï¼Œ**åªè¦å®é™…æ‰§è¡Œç¬¦åˆå…¶ä¸­ä¸€ä¸ªè·¯å¾„ï¼Œå³ä¸ºæ­£ç¡®**
- **è·¯å¾„åŒ¹é…**: æ£€æŸ¥å®é™…å·¥å…·è°ƒç”¨åºåˆ—æ˜¯å¦ä¸ä»»ä¸€è·¯å¾„çš„stepsåŒ¹é…
- **çµæ´»æ‰§è¡Œ**: å…è®¸æ‰§è¡Œé¢å¤–çš„å·¥å…·è°ƒç”¨ï¼Œåªè¦ä¸å½±å“æ ¸å¿ƒé€»è¾‘

 ç”±äºæœŸæœ›çš„åŸºå‡†æ—¶é—´å’Œè¯„æµ‹åŸºå‡†æ—¶é—´ä¸ä¸€è‡´ å› æ­¤ä¸€åˆ‡ä»¥è¯„æµ‹çš„åŸºå‡†æ—¶é—´ä¸ºå‡† ä¸è€ƒè™‘æœŸæœ›çš„æ—¶é—´
- **## æ³¨æ„
-ä¸éœ€è¦ç®¡incompleteçŠ¶æ€**ï¼Œå¦‚æœä¸€è½®å¯¹è¯ä¸­incomplete=trueï¼Œè¡¨ç¤ºè¿™ä¸€è½®æ²¡æœ‰è°ƒç”¨å·¥å…·ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸å½±å“è¯„ä¼°ç»“æœ è‹¥æœŸæœ›ä¸­å­˜åœ¨è°ƒç”¨å·¥å…· éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­æ˜¯å¦ä¸€å®šéœ€è¦è°ƒç”¨è¯¥å·¥å…· è‹¥ä¸€å®šéœ€è¦è°ƒç”¨ åˆ™åˆ¤æ–­é”™è¯¯ã€‚

## è¡¥å……
1. ç”¨æˆ·è¡¨è¾¾å‡ºæ„å›¾å°±å¯ä»¥è°ƒç”¨ ä¸éœ€è¦æ˜ç¡®æŒ‡å‡º
2. å¯¹äºç”Ÿæ—¥çš„å¹´ä»½å¯ä»¥è¡¥å…¨ ä¸ç®—é”™è¯¯
3. ç›¸æ¯”äºé¢„æœŸå¯ä»¥æ·»åŠ å¤šä½™å‚æ•° åªè¦åˆç†å°±å¯ä»¥æ·»åŠ 
4. idå¯ä»¥ä¸ä¸€è‡´
5. åˆ›å»ºäººè„‰æ—¶éœ€è¦å»æŸ¥æ‰¾äººè„‰ è¿™æ˜¯æ­£ç¡®çš„  æœ‰ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ï¼Œæ›´æ–°äººè„‰æ—¶ä¹Ÿå¯ä»¥ä¸æŸ¥æ‰¾,åªè¦å·¥å…·ç»“æœæ‰§è¡Œæ­£ç¡®å³å¯
6. æé†’æ—¶é—´çš„æ ¼å¼å¿…é¡»æ˜¯åé¢10ä¸ªå€¼ä¸­çš„ä¸€ä¸ªï¼š-5mâ€‹ è¡¨ç¤º 5 åˆ†é’Ÿå‰ï¼› -10mâ€‹ è¡¨ç¤º 10 åˆ†é’Ÿå‰ï¼›-15mâ€‹ è¡¨ç¤º 15 åˆ†é’Ÿå‰ï¼›-30mâ€‹ è¡¨ç¤º 30 åˆ†é’Ÿå‰ï¼›-1hâ€‹ è¡¨ç¤º 1 å°æ—¶å‰ï¼›-2hâ€‹ è¡¨ç¤º 2 å°æ—¶å‰ï¼›-1dâ€‹ è¡¨ç¤º 1 å¤©å‰ï¼›-2dâ€‹ è¡¨ç¤º 2 å¤©å‰ï¼›-1wâ€‹ è¡¨ç¤º 1 å‘¨å‰ï¼›-2wâ€‹ è¡¨ç¤º 2 å‘¨å‰ã€‚å•ä½ï¼šd=å¤©ï¼Œm=åˆ†é’Ÿï¼Œw=å‘¨ï¼Œh=å°æ—¶ å¦‚æœä¸æ˜¯ é‚£ä¹ˆis_correctå¿…é¡»åˆ¤ä¸ºé”™è¯¯
7. å¯¹äºæ—¥ç¨‹çš„æ—¶é—´ å¦‚æœç”¨æˆ·æœªæ˜ç¡®è¦æ±‚ï¼Œ**ç»“æŸæ—¶é—´ã€æŒç»­æ—¶é•¿ã€æé†’æ—¶é—´ï¼ˆreminder_timeï¼‰å¯ä»¥çµæ´»è®¾ç½®ï¼Œä¹Ÿå¯ä»¥ä¸è®¾ç½® å› ä¸ºé»˜è®¤-5mï¼Œåªè¦é€»è¾‘åˆç†å³å¯ã€‚
8. reminder_timeã€æ—¥ç¨‹ç»“æŸæ—¶é—´ï¼Œå¦‚æœç”¨æˆ·é—®é¢˜ä¸­æ²¡æœ‰æ˜ç¡®è¦æ±‚è¿™ä¸ªæ—¶é•¿ ä¾¿å¯ä»¥å’Œé¢„æœŸä¸ä¸€è‡´
9. noteä¸ä¸€è‡´ä½†ç›¸è¿‘ä¹Ÿæ˜¯å¯ä»¥çš„ å¦‚ ç”¨æˆ·æœŸæœ›ä¸º'æœåŠ¡å™¨ç›¸å…³è¡Œä¸š'ï¼Œå®é™…ä¸º'æœåŠ¡å™¨'æ˜¯æ­£ç¡®çš„
10. å¯¹äºæ—¥ç¨‹åˆ›å»ºçš„æ—¶é—´ ä»¥åŸºå‡†æ—¶é—´ä¸ºå‡† å¦‚æœåˆç†åˆ™ä¸éœ€è¦å’ŒæœŸæœ›æ—¶é—´ä¿æŒä¸€è‡´  å¦‚ ç”¨æˆ·è¯´'ä»Šå¤©ä¸‹åˆå…«ç‚¹'ï¼ŒåŸºå‡†æ—¶é—´ä¸º2026-01-16ï¼Œå®é™…å´åˆ›å»ºåœ¨2026-01-16 20:00:00ï¼ŒæœŸæœ›åº”ä¸º2026-01-16 20:00:00ï¼Œä½†æœŸæœ›è¡Œä¸ºä¸­æ—¶é—´ä¸º2026-01-13 20:00:00ï¼ŒæœŸæœ›è¡Œä¸ºæœ¬èº«æœ‰è¯¯ å› æ­¤ä»–çš„å‚æ•°æå–æ˜¯æ­£ç¡®çš„ åˆ¤æ–­ä¸ºå¯¹
11. æœŸæœ›æœ‰è¯¯ä½†æ‰§è¡Œç»“æœåˆç† åˆ™ä¸éœ€è¦å’ŒæœŸæœ›ä¿æŒä¸€è‡´ å¯ä»¥åˆ¤æ–­ä¸ºæ­£ç¡®
12. full_dayå¯ä»¥æ˜¯æ—¥æœŸ (start_timeã€end_time)ä¸full_dayæœ‰å…¶ä¸­ä¸€ä¸ªå°±å¯ä»¥
13. å“åº”å†…å®¹åœ¨"content"å­—æ®µä¸­æŸ¥çœ‹
14. å¾…æµ‹è¯•æ•°æ®å¯ä»¥ä¸é¢„æœŸä¸ä¸€è‡´ å¯¹äºå¤æ‚ä»»åŠ¡chunks_count>=14 ï¼Œåªè¦æœ€åéƒ½å®Œæˆäº†ç”¨æˆ·çš„æ„å›¾ éƒ½å¯ä»¥ç®—æ­£ç¡®ï¼Œä½¿ç”¨çš„å·¥å…·ã€å‚æ•°å¯ä»¥å’ŒæœŸæœ›ä¸ä¸€è‡´
15. å¤šè½®å¯¹è¯ä¸­å¦‚æœå¯ä»¥ä»å‰å‡ è½®ç›´æ¥è·å–å¾—åˆ°æ•°æ®ï¼ŒAssistantä¹Ÿå¯ä»¥ä¸éœ€è¦è°ƒç”¨æŸ¥è¯¢å·¥å…·ç›´æ¥å¾—åˆ°ç»“æœ å¦‚ç¬¬ä¸€è½®è¯´äº†æ±Ÿæ¶µçš„ç”Ÿæ—¥å’Œæ‰‹æœºå· ç¬¬äºŒè½®å¯ä»¥ç›´æ¥è¾“å‡ºè¿™ä¸¤æ¡æ•°æ® ä¹Ÿå¯ä»¥é€šè¿‡æœç´¢è”ç³»äººå¾—åˆ°
16. å¤šä½™åˆ›å»ºçš„æ—¥ç¨‹å’Œäººè„‰ åˆç†ä¹Ÿå¯ä»¥æ¥å— ä¸èƒ½ç»™ä½åˆ†
17. æ ¹æ®idæŸ¥æ‰¾çš„ä¸ä¼šè¯¯åˆ ã€æ‰¾é”™è”ç³»äºº
18. å·¥å…·é€‰æ‹©å’Œå‚æ•°æå–å‡æœªå‘ç”Ÿï¼Œä½†æ˜¯æœ€åè¾“å‡ºçš„ç»“æœåˆç†ï¼Œè¿‡ç¨‹åˆç†(ä»ä¸Šä¸‹æ–‡ä¸­å¾—åˆ°ä¿¡æ¯) è¿™ä¸å½±å“å½±å“ä¸šåŠ¡é€»è¾‘å’Œå“åº”å®Œæ•´æ€§
19. **å¤šè·¯å¾„æ ¼å¼æ”¯æŒ**: å½“expected_behaviorä¸ºæ•°ç»„æ—¶ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«"description"å’Œ"steps"ï¼Œè¡¨ç¤ºä¸€ä¸ªå¯èƒ½çš„æ‰§è¡Œè·¯å¾„ã€‚åªè¦å®é™…æ‰§è¡Œç¬¦åˆä»»ä¸€è·¯å¾„ï¼Œå³åˆ¤å®šæ­£ç¡®ã€‚
20. ç”¨æˆ·æä¾›å…·ä½“æ—¶é—´ç‚¹ï¼ˆå¦‚ä¸­åˆã€ä¸‹åˆï¼‰æ—¶ ä½¿ç”¨ start_time å’Œ end_time è€Œé full_day å¦‚æœä½¿ç”¨full_dayåˆ™æ—¶é—´å‚æ•°ä¸¥é‡é”™è¯¯
21. å¯¹äºæŸ¥è¯¢äººè„‰/æ—¥ç¨‹ æŸ¥æ‰¾èŒƒå›´ä¸èƒ½ç‰¹åˆ«é™åˆ¶ å¦åˆ™ç®—é”™è¯¯ å¦‚ ç”¨æˆ·é—®äº§å“ä¾‹ä¼šå®‰æ’äº†å—ï¼Ÿ æœç´¢æ¡ä»¶åº”è¯¥åªæœ‰\"title\": \"äº§å“ä¾‹ä¼š\" è€Œæ²¡æœ‰æ—¶é—´ å› ä¸ºå¯èƒ½ä¼šæ¼æ‰ä¸€äº›æ—¥ç¨‹


è¯·ä»¥JSONæ ¼å¼è¿”å›éªŒè¯ç»“æœï¼š
```json
{{
  "overall_score": æ€»åˆ†(1-10),
  "is_correct": "æ­£ç¡®/é”™è¯¯",
  "dimension_scores": {{
    "tool_selection": å·¥å…·é€‰æ‹©åˆ†æ•°,
    "parameter_accuracy": å‚æ•°å‡†ç¡®æ€§åˆ†æ•°,
    "time_accuracy": æ—¶é—´å‡†ç¡®æ€§åˆ†æ•°,
    "data_processing": æ•°æ®å¤„ç†åˆ†æ•°,
    "business_logic": ä¸šåŠ¡é€»è¾‘åˆ†æ•°,
    "response_completeness": å“åº”å®Œæ•´æ€§åˆ†æ•°
  }},
  "key_issues": ["å…³é”®é—®é¢˜1", "å…³é”®é—®é¢˜2"],
  "suggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2"],
  "detailed_analysis": "ç®€è¦åˆ†æè¯´æ˜(50å­—ä»¥å†…)"
}}
```
"""

    url = f"{openai_base_url}/chat/completions"

    headers = {
        "Authorization": f"Bearer {openai_api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": openai_model,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç³»ç»Ÿæµ‹è¯•éªŒè¯ä¸“å®¶ã€‚ä½ éœ€è¦åˆ†ææµ‹è¯•ç”¨ä¾‹çš„æ‰§è¡Œç»“æœï¼Œåˆ¤æ–­å…¶æ­£ç¡®æ€§ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æœã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0,
        "max_tokens": 4000
    }

    # è®°å½•å‘é€ç»™Geminiçš„è¯·æ±‚ä¿¡æ¯
    logger.log("-" * 60)
    logger.log(f"ç¬¬{turn_index + 1}è½® - å‘é€ç»™Geminiçš„è¯·æ±‚:")
    logger.log(f"URL: {url}")
    logger.log(f"å®Œæ•´Prompt:")
    logger.log(prompt)
    logger.log("-" * 60)

    try:
        async with session.post(url, headers=headers, json=data, timeout=60) as response:
            if response.status != 200:
                error_text = await response.text()
                logger.log(f"APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}", "ERROR")
                raise Exception(f"OpenAI APIè°ƒç”¨å¤±è´¥: {response.status} - {error_text}")

            result = await response.json()
            validation_text = result['choices'][0]['message']['content']

            # è®°å½•Geminiå“åº”
            logger.log("GeminiåŸå§‹å“åº”:")
            logger.log("-" * 60)
            logger.log(validation_text)
            logger.log("-" * 60)

            # å°è¯•è§£æJSON
            validation_data = None
            try:
                validation_data = json.loads(validation_text)
                logger.log("JSONè§£ææˆåŠŸ")
            except json.JSONDecodeError:
                # å°è¯•ä»æ–‡æœ¬ä¸­æå–JSON
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', validation_text, re.DOTALL)
                if json_match:
                    try:
                        validation_data = json.loads(json_match.group(1))
                        logger.log("ä»ä»£ç å—ä¸­æå–JSONæˆåŠŸ")
                    except json.JSONDecodeError:
                        logger.log("ä»ä»£ç å—æå–JSONå¤±è´¥", "WARNING")
                        validation_data = None

            if validation_data:
                result = {
                    'turn_id': turn_id,
                    'turn_index': turn_index,
                    'is_correct': validation_data.get('is_correct', 'unknown'),
                    'score': validation_data.get('overall_score', 0),
                    'dimension_scores': validation_data.get('dimension_scores', {}),
                    'issues': validation_data.get('key_issues', []),
                    'suggestions': validation_data.get('suggestions', []),
                    'reasoning': validation_data.get('detailed_analysis', ''),
                    'status': 'success',
                    'raw_prompt': prompt,
                    'raw_response': validation_text
                }
                logger.log(f"  ç¬¬{turn_index + 1}è½®éªŒè¯ç»“æœ: {result['is_correct']}, è¯„åˆ†: {result['score']}/10")
                logger.log(f"  ç»´åº¦åˆ†æ•°: {result['dimension_scores']}")
                logger.log(f"  ä¸»è¦é—®é¢˜: {result['issues']}")
                return result
            else:
                logger.log("  æ— æ³•è§£æéªŒè¯ç»“æœ", "ERROR")
                return {
                    'turn_id': turn_id,
                    'turn_index': turn_index,
                    'is_correct': 'unknown',
                    'score': 0,
                    'dimension_scores': {},
                    'issues': ['æ— æ³•è§£æéªŒè¯ç»“æœ'],
                    'suggestions': [],
                    'reasoning': validation_text,
                    'status': 'failed',
                    'raw_prompt': prompt,
                    'raw_response': validation_text
                }

    except Exception as e:
        logger.log(f"  ç¬¬{turn_index + 1}è½®éªŒè¯å¤±è´¥: {str(e)}", "ERROR")
        return {
            'turn_id': turn_id,
            'turn_index': turn_index,
            'is_correct': 'error',
            'score': 0,
            'dimension_scores': {},
            'issues': [f'éªŒè¯å¤±è´¥: {str(e)}'],
            'suggestions': [],
            'reasoning': '',
            'status': 'failed'
        }


async def validate_single_case(session, test_case, case_index=0):
    """éªŒè¯å•ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼ˆæ”¯æŒå¤šè½®ï¼‰"""
    test_case_id = test_case.get('test_case_id', 'unknown')
    turn_results = test_case.get('turn_results', [])

    logger.log("="*80)
    logger.log(f"æµ‹è¯•ç”¨ä¾‹ #{case_index + 1}: {test_case_id}")
    logger.log(f"æ€»è½®æ•°: {len(turn_results)}")
    logger.log("="*80)

    # è·å–åŸºå‡†æ—¶é—´æˆ³ç”¨äºæ—¶é—´åˆ¤æ–­
    base_timestamp = test_case.get('timestamp', '')
    # è§£ææ—¶é—´æˆ³å¹¶è·å–æ˜ŸæœŸå‡ 
    try:
        from datetime import datetime
        dt = datetime.fromisoformat(base_timestamp.replace('Z', '+00:00'))
        weekday_cn = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][dt.weekday()]
        base_timestamp_with_weekday = f"{base_timestamp} ({weekday_cn})"
    except:
        base_timestamp_with_weekday = base_timestamp

    logger.log(f"åŸºå‡†æ—¶é—´æˆ³: {base_timestamp_with_weekday}")

    # éªŒè¯æ‰€æœ‰turns
    turn_validation_results = []
    for turn_index, turn_result in enumerate(turn_results):
        logger.log("")  # ç©ºè¡Œåˆ†éš”
        logger.log(f"å¼€å§‹éªŒè¯ç¬¬{turn_index + 1}è½® (å…±{len(turn_results)}è½®)")

        # æ„å»ºå†å²è½®æ¬¡æ•°æ®ï¼ˆå‰é¢çš„æ‰€æœ‰è½®æ¬¡ï¼‰
        previous_turns = turn_results[:turn_index] if turn_index > 0 else []

        turn_validation_result = await validate_single_turn(
            session, test_case_id, turn_result, turn_index,
            base_timestamp_with_weekday, logger, previous_turns
        )
        turn_validation_results.append(turn_validation_result)
        logger.log(f"ç¬¬{turn_index + 1}è½®éªŒè¯å®Œæˆï¼ŒçŠ¶æ€: {turn_validation_result['status']}")

    logger.log(f"æ‰€æœ‰è½®æ¬¡éªŒè¯å®Œæˆï¼Œå…±éªŒè¯{len(turn_validation_results)}è½®")

    # èšåˆæ‰€æœ‰turnsçš„åˆ†æ•°
    total_score = sum(r['score'] for r in turn_validation_results if r['status'] == 'success')
    num_successful_turns = sum(1 for r in turn_validation_results if r['status'] == 'success')
    avg_score = (total_score / num_successful_turns) if num_successful_turns > 0 else 0

    # è®¡ç®—ç»´åº¦å¹³å‡åˆ†
    dimension_scores = {}
    if num_successful_turns > 0:
        all_dimensions = set()
        for r in turn_validation_results:
            if r['status'] == 'success':
                all_dimensions.update(r['dimension_scores'].keys())

        for dim in all_dimensions:
            dim_scores = [
                r['dimension_scores'].get(dim, 0)
                for r in turn_validation_results
                if r['status'] == 'success' and dim in r['dimension_scores']
            ]
            dimension_scores[dim] = sum(dim_scores) / len(dim_scores) if dim_scores else 0

    # åˆ¤æ–­æ•´ä½“æ­£ç¡®æ€§ï¼šæ‰€æœ‰turnséƒ½æ­£ç¡®æ‰ç®—æ­£ç¡®
    all_correct = all(r['is_correct'] == 'æ­£ç¡®' for r in turn_validation_results if r['status'] == 'success')
    any_error = any(r['is_correct'] == 'é”™è¯¯' for r in turn_validation_results if r['status'] == 'success')

    overall_is_correct = 'æ­£ç¡®' if all_correct else ('é”™è¯¯' if any_error else 'unknown')

    # æ±‡æ€»æ‰€æœ‰é—®é¢˜å’Œå»ºè®®
    all_issues = []
    all_suggestions = []
    all_reasoning = []
    logger.log(f"å¼€å§‹æ±‡æ€»{len(turn_validation_results)}è½®çš„ç»“æœ")
    for r in turn_validation_results:
        logger.log(f"  å¤„ç†ç¬¬{r['turn_index'] + 1}è½®ï¼ŒçŠ¶æ€: {r['status']}")
        if r['status'] == 'success':
            issue_prefix = f"ç¬¬{r['turn_index'] + 1}è½®: "
            all_issues.extend([issue_prefix + str(issue) for issue in r['issues']])
            all_suggestions.extend([issue_prefix + str(suggestion) for suggestion in r['suggestions']])
            if r.get('reasoning'):
                reasoning_prefix = f"ç¬¬{r['turn_index'] + 1}è½®åˆ†æ: "
                all_reasoning.append(reasoning_prefix + str(r['reasoning']))
        else:
            logger.log(f"    è·³è¿‡ç¬¬{r['turn_index'] + 1}è½®ï¼ŒçŠ¶æ€ésuccess")

    logger.log(f"æ±‡æ€»å®Œæˆï¼Œå…±{len(all_issues)}ä¸ªé—®é¢˜ï¼Œ{len(all_suggestions)}ä¸ªå»ºè®®")

    # æ„å»ºæœ€ç»ˆç»“æœ
    final_result = {
        'test_case_id': test_case_id,
        'is_correct': overall_is_correct,
        'score': avg_score,
        'dimension_scores': dimension_scores,
        'issues': all_issues,
        'suggestions': all_suggestions,
        'reasoning': '\n\n'.join(all_reasoning),
        'status': 'success' if num_successful_turns == len(turn_results) else 'partial',
        'turn_count': len(turn_results),
        'successful_turns': num_successful_turns,
        'turn_details': turn_validation_results,
        'aggregated': True
    }

    # æ‰“å°æ±‡æ€»ç»“æœ
    logger.log("")
    logger.log("="*80)
    logger.log(f"æµ‹è¯•ç”¨ä¾‹æ±‡æ€»: {test_case_id}")
    logger.log(f"æ€»è½®æ•°: {len(turn_results)}")
    logger.log(f"æˆåŠŸéªŒè¯è½®æ•°: {num_successful_turns}")
    logger.log(f"æ•´ä½“æ­£ç¡®æ€§: {overall_is_correct}")
    logger.log(f"å¹³å‡è¯„åˆ†: {avg_score:.2f}/10")
    logger.log(f"ç»´åº¦åˆ†æ•°: {dimension_scores}")
    logger.log("="*80)

    return final_result


# å¹¶å‘å¤„ç†å•ä¸ªæµ‹è¯•ç”¨ä¾‹
async def process_single_case(args):
    """å¹¶å‘å¤„ç†å•ä¸ªæµ‹è¯•ç”¨ä¾‹çš„åŒ…è£…å‡½æ•°"""
    session, test_case, case_index, enable_retry, max_retries = args
    return await validate_single_case_with_retry(session, test_case, case_index, enable_retry, max_retries)


async def validate_single_case_with_retry(session, test_case, case_index, enable_retry, max_retries):
    """éªŒè¯å•ä¸ªæµ‹è¯•ç”¨ä¾‹å¹¶å¤„ç†é‡è¯•"""
    result = await validate_single_case(session, test_case, case_index)

    # é‡è¯•æœºåˆ¶
    if enable_retry and result['status'] != 'success':
        retry_attempt = 1
        retry_cases = [(case_index, test_case)]

        while retry_cases and retry_attempt <= max_retries:
            logger.log(f"ğŸ”„ ç¬¬{retry_attempt}è½®é‡è¯•å¼€å§‹ï¼Œå…±{len(retry_cases)}ä¸ªç”¨ä¾‹")
            current_retry_cases = retry_cases.copy()
            retry_cases = []

            for original_index, test_case_item in current_retry_cases:
                retry_result = await validate_single_case(session, test_case_item, original_index)

                if retry_result['status'] != 'success':
                    if retry_attempt < max_retries:
                        retry_cases.append((original_index, test_case_item))
                    logger.log(f"âŒ ç¬¬{retry_attempt}è½®é‡è¯•ä»å¤±è´¥")
                else:
                    result = retry_result
                    logger.log(f"âœ… é‡è¯•æˆåŠŸï¼ç”¨ä¾‹ {test_case.get('test_case_id')} ç°åœ¨éªŒè¯é€šè¿‡")
                    break

            retry_attempt += 1

    return result


async def main():
    """ä¸»å‡½æ•°"""
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    start_datetime = datetime.now()

    parser = argparse.ArgumentParser(description='æµ‹è¯•ç»“æœéªŒè¯è„šæœ¬ - å¹¶è¡Œç‰ˆæœ¬')
    parser.add_argument('--input', '-i', type=str, help='è¾“å…¥æµ‹è¯•ç»“æœæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', type=str, help='è¾“å‡ºéªŒè¯æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ (å¯é€‰ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ)')
    parser.add_argument('--limit', '-l', type=int, help='é™åˆ¶éªŒè¯çš„æµ‹è¯•ç”¨ä¾‹æ•°é‡ (é»˜è®¤: å…¨éƒ¨)')
    parser.add_argument('--timestamp', '-t', type=str, help='æ—¶é—´æˆ³ (å¯é€‰ï¼Œç”¨äºç”Ÿæˆæ–‡ä»¶å)')
    parser.add_argument('--retry', '-r', type=int, default=5, help='å¤±è´¥é‡è¯•æ¬¡æ•° (é»˜è®¤: 5æ¬¡)')
    parser.add_argument('--no-retry', action='store_true', help='ç¦ç”¨é‡è¯•æœºåˆ¶')
    parser.add_argument('--concurrency', '-c', type=int, default=5, help='å¹¶å‘æ•° (é»˜è®¤: 5ä¸ªå¹¶å‘)')
    args = parser.parse_args()

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    import os
    os.makedirs("validation_reports", exist_ok=True)

    # è‡ªåŠ¨å‘ç°è¾“å…¥æ–‡ä»¶
    if args.input:
        test_file = args.input
    else:
        # æ™ºèƒ½æŸ¥æ‰¾æœ€æ–°çš„æµ‹è¯•ç»“æœæ–‡ä»¶
        import glob
        pattern = str(SCRIPT_DIR / "test_results_merged_*.json")
        matching_files = glob.glob(pattern)

        if matching_files:
            # è·å–æœ€æ–°çš„æ–‡ä»¶
            test_file = max(matching_files, key=os.path.getmtime)
            print(f"ğŸ” è‡ªåŠ¨å‘ç°è¾“å…¥æ–‡ä»¶: {test_file}")
        else:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•ç»“æœæ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ --input å‚æ•°æŒ‡å®š")
            return

    # è¯»å–æµ‹è¯•æ–‡ä»¶
    try:
        with open(test_file, 'r', encoding='utf-8') as f:
            test_cases = json.load(f)
    except FileNotFoundError:
        logger.log(f"é”™è¯¯: æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}", "ERROR")
        return
    except Exception as e:
        logger.log(f"é”™è¯¯: è¯»å–æµ‹è¯•æ–‡ä»¶å¤±è´¥: {e}", "ERROR")
        return

    logger.log(f"è¯»å–åˆ° {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    print(f"è¯»å–åˆ° {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")

    # é™åˆ¶æµ‹è¯•ç”¨ä¾‹æ•°é‡
    if args.limit:
        test_cases_to_validate = test_cases[:args.limit]
        print(f"å°†éªŒè¯å‰ {args.limit} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    else:
        test_cases_to_validate = test_cases
        print(f"å°†éªŒè¯å…¨éƒ¨ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")

    print()

    # å¹¶å‘é…ç½®
    enable_retry = not args.no_retry
    max_retries = args.retry if enable_retry else 0
    concurrency = args.concurrency

    logger.log(f"å¹¶å‘æœºåˆ¶: å¯ç”¨, å¹¶å‘æ•°: {concurrency}")
    logger.log(f"é‡è¯•æœºåˆ¶: {'å¯ç”¨' if enable_retry else 'ç¦ç”¨'}, æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")

    print(f"ğŸš€ å¹¶å‘æ•°: {concurrency}")
    print(f"ğŸ”§ é‡è¯•æœºåˆ¶: {'å¯ç”¨' if enable_retry else 'ç¦ç”¨'}, æœ€å¤§é‡è¯•æ¬¡æ•°: {max_retries}")
    print()

    results = []
    problem_cases = []

    # ğŸ”„ æ‰§è¡Œå¹¶è¡ŒéªŒè¯
    try:
        async with aiohttp.ClientSession() as session:
            # å‡†å¤‡å¹¶å‘ä»»åŠ¡
            tasks = []
            semaphore = asyncio.Semaphore(concurrency)
            completed_count = 0
            total_count = len(test_cases_to_validate)

            # å®æ—¶è¿›åº¦æ˜¾ç¤º
            progress_lock = asyncio.Lock()

            async def update_progress():
                async with progress_lock:
                    nonlocal completed_count
                    progress = (completed_count / total_count * 100) if total_count > 0 else 0
                    bar_length = 40
                    filled_length = int(bar_length * completed_count / total_count)
                    bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)
                    print(f"\rğŸš€ éªŒè¯è¿›åº¦: |{bar}| {completed_count}/{total_count} ({progress:.1f}%)", end='', flush=True)

            # åˆå§‹åŒ–è¿›åº¦æ¡
            print(f"ğŸš€ éªŒè¯è¿›åº¦: |{'-' * 40}| 0/{total_count} (0.0%)")
            print("ğŸš€ å¼€å§‹å¹¶è¡ŒéªŒè¯...")
            print()

            # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
            for i, test_case in enumerate(test_cases_to_validate):
                # ä½¿ç”¨ä¿¡å·é‡åŒ…è£…
                async def create_task(sem, session, test_case, case_index):
                    nonlocal completed_count
                    async with sem:
                        result = await validate_single_case_with_retry(
                            session, test_case, case_index, enable_retry, max_retries
                        )

                        # å®Œæˆä»»åŠ¡åæ›´æ–°è¿›åº¦
                        async with progress_lock:
                            completed_count += 1
                            count = completed_count

                        # æ›´æ–°è¿›åº¦æ¡
                        await update_progress()

                        # å®æ—¶æ˜¾ç¤ºå®Œæˆçš„ç»“æœ
                        print(f"\nâœ… å®Œæˆ #{count}: {result['test_case_id']}")
                        print(f"   çŠ¶æ€: {result['status']}, æ­£ç¡®æ€§: {result['is_correct']}, è¯„åˆ†: {result['score']}/10")
                        if result['issues']:
                            print(f"   é—®é¢˜: {', '.join(result['issues'][:2])}")

                        return result

                task = create_task(semaphore, session, test_case, i)
                tasks.append(task)

            start_parallel_time = time.time()

            # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            results = await asyncio.gather(*tasks, return_exceptions=True)

            parallel_time = time.time() - start_parallel_time
            print(f"\nâœ… å¹¶è¡ŒéªŒè¯å®Œæˆï¼ç”¨æ—¶: {parallel_time:.2f}ç§’")

        # å¤„ç†ç»“æœ
        final_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.log(f"æµ‹è¯•ç”¨ä¾‹ {i+1} å¤„ç†å¤±è´¥: {result}", "ERROR")
                final_results.append({
                    'test_case_id': test_cases_to_validate[i].get('test_case_id', 'unknown'),
                    'is_correct': 'error',
                    'score': 0,
                    'dimension_scores': {},
                    'issues': [f'å¤„ç†å¼‚å¸¸: {str(result)}'],
                    'suggestions': [],
                    'reasoning': '',
                    'status': 'failed',
                    'turn_count': 0,
                    'successful_turns': 0,
                    'turn_details': []
                })
            else:
                final_results.append(result)

                # è®°å½•é—®é¢˜ç”¨ä¾‹
                if result['is_correct'] == 'é”™è¯¯':
                    problem_cases.append(result)

    except Exception as e:
        logger.log(f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}", "ERROR")
        print(f"éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return

    # æ‰“å°æ‘˜è¦
    logger.log("="*80)
    logger.log("éªŒè¯æ‘˜è¦")
    logger.log("="*80)
    print("\n" + "="*60)
    print("éªŒè¯æ‘˜è¦")
    print("="*60)

    total = len(final_results)
    successful = sum(1 for r in final_results if r['status'] == 'success')
    failed = total - successful

    logger.log(f"æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {total}")
    logger.log(f"éªŒè¯æˆåŠŸ: {successful}")
    logger.log(f"éªŒè¯å¤±è´¥: {failed}")
    print(f"æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {total}")
    print(f"éªŒè¯æˆåŠŸ: {successful}")
    print(f"éªŒè¯å¤±è´¥: {failed}")

    # è®¡ç®—æ­£ç¡®ç‡
    correct = sum(1 for r in final_results if r['status'] == 'success' and r['is_correct'] == 'æ­£ç¡®')
    wrong = sum(1 for r in final_results if r['status'] == 'success' and r['is_correct'] == 'é”™è¯¯')
    accuracy = (correct / total * 100) if total > 0 else 0

    if successful > 0:
        logger.log(f"  æ­£ç¡®: {correct}")
        logger.log(f"  é”™è¯¯: {wrong}")
        logger.log(f"  æ­£ç¡®ç‡: {accuracy:.1f}%")
        print(f"  æ­£ç¡®: {correct}")
        print(f"  é”™è¯¯: {wrong}")
        print(f"  æ­£ç¡®ç‡: {accuracy:.1f}%")

        avg_score = sum(r['score'] for r in final_results if r['status'] == 'success') / successful
        logger.log(f"å¹³å‡è¯„åˆ†: {avg_score:.2f}/10")
        print(f"å¹³å‡è¯„åˆ†: {avg_score:.2f}/10")

    # ä¿å­˜ç»“æœ
    timestamp = args.timestamp or datetime.now().strftime('%Y%m%d_%H%M%S')

    if args.output:
        output_file = args.output
    else:
        output_file = f"validation_reports/validation_report_parallel_{timestamp}.json"

    final_report = {
        'validation_summary': {
            'total_cases': total,
            'successful': successful,
            'failed': failed,
            'success_rate': successful / total if total > 0 else 0,
            'correct_count': correct,
            'wrong_count': wrong,
            'accuracy_rate': accuracy,
            'average_score': avg_score if successful > 0 else 0,
            'parallel_config': {
                'concurrency': concurrency,
                'retry_enabled': enable_retry,
                'max_retries': max_retries
            }
        },
        'validation_details': final_results,
        'problem_cases': problem_cases,
        'log_file': str(LOG_FILE),
        'timestamp': datetime.now().isoformat()
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)

    logger.log(f"\néªŒè¯å®Œæˆ!")
    logger.log(f"JSONæŠ¥å‘Š: {output_file}")
    logger.log(f"è¯¦ç»†æ—¥å¿—: {LOG_FILE}")

    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    print(f"è¯¦ç»†æ—¥å¿—: {LOG_FILE}")
    print("="*60)

    # ä¿å­˜æ—¥å¿—æ–‡ä»¶
    logger.save()

    # è®¡ç®—å¹¶æ˜¾ç¤ºæ‰§è¡Œæ—¶é—´
    end_time = time.time()
    end_datetime = datetime.now()
    execution_time = end_time - start_time

    print("\n" + "="*60)
    print("â±ï¸  æ‰§è¡Œæ—¶é—´ç»Ÿè®¡")
    print("="*60)
    print(f"å¼€å§‹æ—¶é—´: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ç»“æŸæ—¶é—´: {end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æ€»æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’ ({execution_time/60:.2f}åˆ†é’Ÿ)")
    print(f"å¹³å‡æ¯ä¸ªæµ‹è¯•: {execution_time/len(final_results):.2f}ç§’")
    if parallel_time > 0:
        print(f"å¹¶è¡Œä¼˜åŒ–æå‡: {(len(final_results) * 10) / parallel_time:.1f} ä¸ªæµ‹è¯•/ç§’")
    print("="*60)

    return final_report


if __name__ == '__main__':
    print("""
ğŸš€ å¹¶è¡Œå¤„ç†ç‰ˆæœ¬ä½¿ç”¨è¯´æ˜ï¼š

1. åŸºæœ¬ä½¿ç”¨ï¼ˆ5ä¸ªå¹¶å‘ï¼‰ï¼š
   python validate_test_gemini_results_parallel.py

2. è‡ªå®šä¹‰å¹¶å‘æ•°ï¼ˆä¾‹å¦‚10ä¸ªå¹¶å‘ï¼‰ï¼š
   python validate_test_gemini_results_parallel.py --concurrency 10

3. ç¦ç”¨é‡è¯•æœºåˆ¶ï¼š
   python validate_test_gemini_results_parallel.py --no-retry

4. è‡ªå®šä¹‰é‡è¯•æ¬¡æ•°ï¼ˆä¾‹å¦‚3æ¬¡ï¼‰ï¼š
   python validate_test_gemini_results_parallel.py --retry 3

5. æŒ‡å®šè¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶ï¼š
   python validate_test_gemini_results_parallel.py -i test_results.json -o report.json

6. é™åˆ¶éªŒè¯æ•°é‡ï¼ˆä¾‹å¦‚åªéªŒè¯å‰10ä¸ªï¼‰ï¼š
   python validate_test_gemini_results_parallel.py --limit 10

ç»„åˆä½¿ç”¨ç¤ºä¾‹ï¼š
- 10ä¸ªå¹¶å‘ + 3æ¬¡é‡è¯•ï¼š
  python validate_test_gemini_results_parallel.py --concurrency 10 --retry 3

- 5ä¸ªå¹¶å‘ + ç¦ç”¨é‡è¯•ï¼š
  python validate_test_gemini_results_parallel.py --concurrency 5 --no-retry

ä¼˜åŠ¿ï¼š
âœ… å¤§å¹…æå‡éªŒè¯æ•ˆç‡ï¼ˆ5-10å€é€Ÿåº¦æå‡ï¼‰
âœ… æ™ºèƒ½å¹¶å‘æ§åˆ¶ï¼Œé¿å…APIé™åˆ¶
âœ… ä¿æŒæ‰€æœ‰åŸæœ‰åŠŸèƒ½ï¼ˆå¤šè·¯å¾„éªŒè¯ã€é‡è¯•æœºåˆ¶ç­‰ï¼‰
âœ… å®æ—¶è¿›åº¦æ˜¾ç¤º
""")
    asyncio.run(main())
