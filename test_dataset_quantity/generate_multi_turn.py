#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šè½®Excelæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨
- æ”¯æŒå¤šè½®å¯¹è¯çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
- æ¯è¡Œæ˜¯ä¸€æ¡å¤šè½®æµ‹è¯•æ•°æ®ï¼Œæ¯åˆ—æ˜¯ä¸€ä¸ªè½®æ¬¡çš„ç”¨æˆ·é—®é¢˜

ä½¿ç”¨æ–¹å¼:
python generate_multi_turn.py --count 2 --excel å¤šè½®.xlsx
python generate_multi_turn.py --all --excel å¤šè½®.xlsx
"""

import json
import asyncio
import sys
import os
import pandas as pd
import argparse
import base64
from datetime import datetime
from typing import Dict, List, Optional
from dotenv import load_dotenv
import openai

# åŠ è½½.envæ–‡ä»¶
load_dotenv('/home/libo/chatapi/.env')

# OpenAI é…ç½®ï¼ˆGemini-3-Flash-Previewï¼‰
openai_api_key: str = os.getenv("OPENAI_API_KEY", "sk-hk69mLmsHF6FfIM8cPn2Zitfk0Jca6suzwIptZymPn6h1u6x")
openai_base_url: str = os.getenv("OPENAI_BASE_URL", "https://llm.onerouter.pro/v1")
openai_model: str = os.getenv("OPENAI_MODEL", "gemini-3-flash-preview")


class MultiTurnTestCaseGenerator:
    """å¤šè½®æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨"""

    def __init__(self):
        self.client = None

    async def initialize(self):
        """åˆå§‹åŒ–"""
        print(f"æ­£åœ¨åˆå§‹åŒ–Gemini-3-Flash-Preview...")
        print(f"  Base URL: {openai_base_url}")
        print(f"  æ¨¡å‹: {openai_model}")
        print(f"  API Key: {openai_api_key[:10]}...")

        self.client = openai.AsyncOpenAI(
            api_key=openai_api_key,
            base_url=openai_base_url
        )

    def _generate_unique_user_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„user_id"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        return f"user_{timestamp}"

    def _is_image_url(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ¬åœ°å›¾ç‰‡æ–‡ä»¶"""
        image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']

        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°å›¾ç‰‡æ–‡ä»¶
        if os.path.isfile(text):
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            return any(text.lower().endswith(ext) for ext in image_extensions)

        return False

    def _get_current_time_info(self) -> str:
        """è·å–å½“å‰æ—¶é—´ä¿¡æ¯"""
        current_time = datetime.now()
        current_date_str = current_time.strftime('%Y-%m-%d')
        weekday_str = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][current_time.weekday()]
        return f"ä»Šå¤©å½“å‰æ—¶é—´ï¼š{current_date_str}ï¼Œä»Šå¤©æ˜¯æ˜ŸæœŸ{weekday_str}"

    def _download_and_convert_image(self, url: str) -> str:
        """è¯»å–æœ¬åœ°å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64æ ¼å¼"""
        try:
            print(f"   ğŸ“ æ­£åœ¨è¯»å–æœ¬åœ°å›¾ç‰‡: {url[:80]}...")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.isfile(url):
                print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {url}")
                return ""

            # è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶
            with open(url, 'rb') as f:
                image_data = f.read()

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šcontent_type
            if url.lower().endswith('.png'):
                content_type = 'image/png'
            elif url.lower().endswith('.gif'):
                content_type = 'image/gif'
            elif url.lower().endswith('.jpg') or url.lower().endswith('.jpeg'):
                content_type = 'image/jpeg'
            elif url.lower().endswith('.webp'):
                content_type = 'image/webp'
            else:
                content_type = 'image/jpeg'  # é»˜è®¤

            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            base64_data = f"data:{content_type};base64,{image_base64}"

            print(f"   âœ… æœ¬åœ°å›¾ç‰‡è¯»å–æˆåŠŸï¼Œå¤§å°: {len(image_data)} bytes")
            return base64_data

        except Exception as e:
            print(f"   âŒ å›¾ç‰‡è¯»å–å¤±è´¥: {e}")
            return ""

    def _build_prompt_for_turn(self, query: str, turn_number: int, total_turns: int, is_first_turn: bool, previous_context: List[Dict] = None) -> str:
        """ä¸ºç‰¹å®šè½®æ¬¡æ„å»ºæç¤ºè¯"""
        time_info = self._get_current_time_info()

        if self._is_image_url(query):
            image_base64 = self._download_and_convert_image(query)

            if image_base64:
                base_prompt = f"""è¯·åˆ†æä»¥ä¸‹æœ¬åœ°å›¾ç‰‡å†…å®¹ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

å›¾ç‰‡æ–‡ä»¶ï¼š{query}
å›¾ç‰‡å†…å®¹å·²è½¬æ¢ä¸ºbase64æ ¼å¼ï¼Œè¯·åˆ†æå›¾ç‰‡ä¸­çš„ä¿¡æ¯ã€‚

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
ç›´æ¥åŸºäºå›¾ç‰‡å†…å®¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œå›¾ç‰‡å†…å®¹åº”è¯¥è¢«Agentç›´æ¥ç†è§£å¹¶æ‰§è¡Œç›¸åº”æ“ä½œã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨å›¾ç‰‡ä¸­æ˜ç¡®æ˜¾ç¤ºçš„ä¿¡æ¯
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""

                # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
                if not is_first_turn and previous_context:
                    context_info = self._format_previous_context(previous_context)
                    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹æœ¬åœ°å›¾ç‰‡å†…å®¹ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context_info}

å›¾ç‰‡æ–‡ä»¶ï¼š{query}
å›¾ç‰‡å†…å®¹å·²è½¬æ¢ä¸ºbase64æ ¼å¼ï¼Œè¯·åˆ†æå›¾ç‰‡ä¸­çš„ä¿¡æ¯ã€‚

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
ç›´æ¥åŸºäºå›¾ç‰‡å†…å®¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œå›¾ç‰‡å†…å®¹åº”è¯¥è¢«Agentç›´æ¥ç†è§£å¹¶æ‰§è¡Œç›¸åº”æ“ä½œã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨å›¾ç‰‡ä¸­æ˜ç¡®æ˜¾ç¤ºçš„ä¿¡æ¯ï¼Œä»¥åŠå‰é¢è½®æ¬¡ä¸­å·²ç»åˆ›å»ºæˆ–è·å–çš„ä¿¡æ¯
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""
                else:
                    user_prompt = base_prompt
            else:
                base_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼Œç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

âš ï¸ é‡è¦è¯´æ˜ï¼šå›¾ç‰‡æ–‡ä»¶æ— æ³•è¯»å–ã€‚

å›¾ç‰‡æ–‡ä»¶ï¼š{query}

ğŸš¨ é‡è¦çº¦æŸï¼š
1. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
2. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
3. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
è¯·ç”Ÿæˆä¸€ä¸ªåˆç†çš„æµ‹è¯•ç”¨ä¾‹ã€‚

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""

                # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
                if not is_first_turn and previous_context:
                    context_info = self._format_previous_context(previous_context)
                    user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼Œç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context_info}

âš ï¸ é‡è¦è¯´æ˜ï¼šå›¾ç‰‡æ–‡ä»¶æ— æ³•è¯»å–ã€‚

å›¾ç‰‡æ–‡ä»¶ï¼š{query}

ğŸš¨ é‡è¦çº¦æŸï¼š
1. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
2. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
3. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
è¯·ç”Ÿæˆä¸€ä¸ªåˆç†çš„æµ‹è¯•ç”¨ä¾‹ã€‚

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""
                else:
                    user_prompt = base_prompt
        else:
            # æ„å»ºåŸºç¡€æç¤º
            base_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨ç”¨æˆ·æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼ˆå§“åã€ç”Ÿæ—¥ã€ç”µè¯ç­‰ï¼‰
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""

            # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            if not is_first_turn and previous_context:
                context_info = self._format_previous_context(previous_context)
                user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context_info}

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨ç”¨æˆ·æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä»¥åŠå‰é¢è½®æ¬¡ä¸­å·²ç»åˆ›å»ºæˆ–è·å–çš„ä¿¡æ¯
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""
            else:
                user_prompt = base_prompt

        return user_prompt

    def _format_previous_context(self, previous_context: List[Dict]) -> str:
        """æ ¼å¼åŒ–å‰é¢è½®æ¬¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        if not previous_context:
            return ""

        context_parts = []
        for ctx in previous_context:
            if ctx['type'] == 'contact_created':
                contact_info = ctx['contact_info']
                context_parts.append(f"- åœ¨ç¬¬{ctx['turn_id']}è½®å·²åˆ›å»ºè”ç³»äººï¼š{contact_info['name']}")
                for key, value in contact_info.items():
                    if key != 'name' and value is not None:
                        context_parts.append(f"  â€¢ {key}: {value}")
            elif ctx['type'] == 'contact_searched':
                contact_info = ctx['contact_info']
                context_parts.append(f"- åœ¨ç¬¬{ctx['turn_id']}è½®å·²æœç´¢åˆ°è”ç³»äººï¼š{contact_info['name']}")
                for key, value in contact_info.items():
                    if key != 'name' and value is not None:
                        context_parts.append(f"  â€¢ {key}: {value}")
            elif ctx['type'] == 'schedule_created':
                schedule_info = ctx['schedule_info']
                context_parts.append(f"- åœ¨ç¬¬{ctx['turn_id']}è½®å·²åˆ›å»ºæ—¥ç¨‹ï¼š{schedule_info['title']}")
                for key, value in schedule_info.items():
                    if key != 'title' and value is not None:
                        context_parts.append(f"  â€¢ {key}: {value}")

        return "\n".join(context_parts) if context_parts else ""

    def _store_turn_context(self, turn: Dict, previous_context: List[Dict]):
        """å­˜å‚¨è½®æ¬¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        steps = turn.get("expected_behavior", {}).get("steps", [])

        for step in steps:
            if step.get("type") == "tool_result":
                result_data = step.get("result", {}).get("data", {})

                # å¦‚æœæ˜¯åˆ›å»ºè”ç³»äºº
                if "name" in result_data and "id" in result_data:
                    # æå–æœ‰ç”¨çš„ä¿¡æ¯
                    contact_info = {
                        "name": result_data.get("name"),
                        "birthday": result_data.get("birthday"),
                        "phone": result_data.get("phone"),
                        "email": result_data.get("email"),
                        "company": result_data.get("company"),
                        "position": result_data.get("position"),
                        "notes": result_data.get("notes")
                    }
                    # è¿‡æ»¤æ‰Noneå€¼
                    contact_info = {k: v for k, v in contact_info.items() if v is not None}

                    previous_context.append({
                        "type": "contact_created",
                        "turn_id": turn["turn_id"],
                        "contact_info": contact_info
                    })

                # å¦‚æœæ˜¯æœç´¢è”ç³»äºº
                elif "contacts" in result_data:
                    contacts = result_data["contacts"]
                    if contacts and isinstance(contacts, list) and contacts[0]:
                        contact = contacts[0]
                        # æå–æœ‰ç”¨çš„ä¿¡æ¯
                        contact_info = {
                            "name": contact.get("name"),
                            "birthday": contact.get("birthday"),
                            "phone": contact.get("phone"),
                            "email": contact.get("email"),
                            "company": contact.get("company"),
                            "position": contact.get("position"),
                            "notes": contact.get("notes")
                        }
                        # è¿‡æ»¤æ‰Noneå€¼
                        contact_info = {k: v for k, v in contact_info.items() if v is not None}

                        previous_context.append({
                            "type": "contact_searched",
                            "turn_id": turn["turn_id"],
                            "contact_info": contact_info
                        })

                # å¦‚æœæ˜¯åˆ›å»ºæ—¥ç¨‹
                elif "title" in result_data and "id" in result_data:
                    schedule_info = {
                        "title": result_data.get("title"),
                        "description": result_data.get("description"),
                        "start_time": result_data.get("start_time"),
                        "end_time": result_data.get("end_time"),
                        "location": result_data.get("location"),
                        "category": result_data.get("category")
                    }
                    # è¿‡æ»¤æ‰Noneå€¼
                    schedule_info = {k: v for k, v in schedule_info.items() if v is not None}

                    previous_context.append({
                        "type": "schedule_created",
                        "turn_id": turn["turn_id"],
                        "schedule_info": schedule_info
                    })

    async def generate_multi_turn_test_case(self, row_data: Dict, test_case_id: str) -> Dict:
        """ç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹"""
        # ç”Ÿæˆå”¯ä¸€çš„user_id
        unique_user_id = self._generate_unique_user_id()

        # è·å–æ‰€æœ‰è½®æ¬¡çš„æŸ¥è¯¢
        turn_queries = []
        for col_name, query in row_data.items():
            if pd.notna(query) and str(query).strip():
                turn_queries.append(str(query).strip())

        if not turn_queries:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æŸ¥è¯¢æ•°æ®")

        total_turns = len(turn_queries)
        turns = []

        # å­˜å‚¨å‰é¢è½®æ¬¡çš„é‡è¦ä¿¡æ¯ï¼Œç”¨äºåç»­è½®æ¬¡çš„ä¸Šä¸‹æ–‡
        previous_turns_context = []

        for turn_idx, query in enumerate(turn_queries):
            turn_number = turn_idx + 1
            print(f"\n   ğŸ“ ç”Ÿæˆç¬¬ {turn_number} è½®æµ‹è¯•ç”¨ä¾‹")
            print(f"      Query: {query[:100]}...")

            # æ„å»ºæç¤ºè¯
            user_prompt = self._build_prompt_for_turn(query, turn_number, total_turns, turn_idx == 0, previous_turns_context)

            # æ„å»ºè¯·æ±‚
            messages = [
                {"role": "system", "content": self._build_system_prompt()},
                {"role": "user", "content": user_prompt}
            ]

            max_retries = 5
            retry_count = 0
            api_success = False

            while retry_count < max_retries and not api_success:
                try:
                    print(f"   ğŸ”„ ç¬¬ {turn_number} è½®ç¬¬ {retry_count + 1} æ¬¡å°è¯•...")
                    # è°ƒç”¨Geminiç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
                    response = await self.client.chat.completions.create(
                        model=openai_model,
                        messages=messages,
                        max_tokens=4000,
                        temperature=0.1
                    )

                    content = response.choices[0].message.content
                    print(f"   âœ… Gemini APIè°ƒç”¨æˆåŠŸ")
                    print(f"   ğŸ“„ å“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
                    print(f"   ğŸ“„ å“åº”é¢„è§ˆ: {content[:500]}...")

                    # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«æ— æ³•ç†è§£çš„æç¤º
                    if self._is_unclear_response(content):
                        print(f"   âš ï¸  æ£€æµ‹åˆ°æ— æ³•ç†è§£çš„å“åº”ï¼Œå°†é‡è¯•...")
                        retry_count += 1
                        if retry_count < max_retries:
                            await asyncio.sleep(2 * retry_count)  # é€’å¢ç­‰å¾…æ—¶é—´
                            continue

                    # æ£€æŸ¥å“åº”æ˜¯å¦å®Œæ•´ï¼ˆåŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥ï¼‰
                    if not self._is_response_complete(content):
                        print(f"   âš ï¸  å“åº”å¯èƒ½è¢«æˆªæ–­ï¼Œå°†åœ¨1ç§’åé‡è¯•...")
                        retry_count += 1
                        if retry_count < max_retries:
                            await asyncio.sleep(1)
                            continue

                    api_success = True

                    # è§£æJSONå“åº” (ä½¿ç”¨æ–°çš„é‡è¯•æœºåˆ¶)
                    test_case_json = await self._parse_json_with_retry(content)

                    # éªŒè¯JSONç»“æ„å’Œè§£æç»“æœ
                    if test_case_json.get("id") == "PARSE_ERROR":
                        print(f"   âš ï¸  JSONè§£æå¤±è´¥ï¼Œå°†é‡è¯•...")
                        retry_count += 1
                        if retry_count < max_retries:
                            await asyncio.sleep(2 * retry_count)
                            continue

                    if "conversation" not in test_case_json or "turns" not in test_case_json["conversation"]:
                        print(f"   âš ï¸  JSONç»“æ„ä¸å®Œæ•´ï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
                        test_case_json = {
                            "id": "STRUCTURE_ERROR",
                            "conversation": {
                                "turns": [{
                                    "user_input": {
                                        "type": "text",
                                        "content": query
                                    },
                                    "context": {
                                        "requires_context": False,
                                        "depends_on": []
                                    },
                                    "expected_behavior": {
                                        "steps": [{
                                            "step": 1,
                                            "type": "finish",
                                            "expected_response": "æˆ‘æ­£åœ¨ç†è§£æ‚¨çš„éœ€æ±‚ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»æˆ–å°è¯•é‡æ–°æè¿°æ‚¨çš„è¯·æ±‚ã€‚"
                                        }]
                                    }
                                }]
                            }
                        }

                            # æ„å»ºturnç»“æ„
                    is_first_turn = (turn_idx == 0)
                    turn = {
                        "turn_id": turn_number,
                        "user_input": test_case_json["conversation"]["turns"][0]["user_input"],
                        "context": {
                            "requires_context": not is_first_turn,
                            "depends_on": list(range(1, turn_number)) if not is_first_turn else []
                        },
                        "expected_behavior": test_case_json["conversation"]["turns"][0]["expected_behavior"]
                    }

                    # å¦‚æœæ˜¯å›¾ç‰‡ç±»å‹ï¼Œå¼ºåˆ¶å°†contentæ›¿æ¢ä¸ºåŸå§‹è·¯å¾„
                    if turn["user_input"].get("type") == "image":
                        turn["user_input"]["content"] = query

                    turns.append(turn)

                    # å­˜å‚¨è½®æ¬¡çš„é‡è¦ä¿¡æ¯ç”¨äºåç»­ä¸Šä¸‹æ–‡
                    self._store_turn_context(turn, previous_turns_context)

                    print(f"   âœ… ç¬¬ {turn_number} è½®å¤„ç†å®Œæˆ")

                except Exception as e:
                    retry_count += 1
                    error_msg = str(e)[:200]
                    print(f"   âŒ ç¬¬ {turn_number} è½®ç¬¬ {retry_count} æ¬¡å°è¯•å¤±è´¥: {error_msg}")

                    if retry_count >= max_retries:
                        print(f"   ğŸ’¥ ç¬¬ {turn_number} è½®è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆ{max_retries}ï¼‰ï¼Œä½¿ç”¨é”™è¯¯å¤„ç†ç»“æ„")

                        # åˆ›å»ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                        error_response = f"è¯·æ±‚å¤„ç†é‡åˆ°é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•æˆ–é‡æ–°æè¿°æ‚¨çš„éœ€æ±‚ã€‚ï¼ˆé”™è¯¯æ¬¡æ•°ï¼š{retry_count}ï¼‰"

                        # åˆ›å»ºåŸºæœ¬çš„turnç»“æ„
                        turn = {
                            "turn_id": turn_number,
                            "user_input": {
                                "type": "text",
                                "content": query
                            },
                            "context": {
                                "requires_context": False,
                                "depends_on": []
                            },
                            "expected_behavior": {
                                "steps": [
                                    {
                                        "step": 1,
                                        "type": "finish",
                                        "expected_response": error_response
                                    }
                                ]
                            }
                        }
                        turns.append(turn)
                    else:
                        print(f"   â³ ç­‰å¾… {2 * retry_count} ç§’åé‡è¯•...")
                        await asyncio.sleep(2 * retry_count)

        # æ„å»ºæœ€ç»ˆæµ‹è¯•ç”¨ä¾‹
        test_case = {
            "id": test_case_id,
            "user_id": unique_user_id,
            "name": f"å¤šè½®å¯¹è¯æµ‹è¯•ç”¨ä¾‹ - {len(turns)} è½®",
            "description": f"å¤šè½®å¯¹è¯æµ‹è¯•ï¼ŒåŒ…å« {len(turns)} ä¸ªè½®æ¬¡çš„äº¤äº’",
            "mode": "multi_turn",
            "conversation": {
                "turns": turns
            },
            "metadata": {
                "conversation_type": "multi_turn",
                "turns": len(turns),
                "context_complexity": "high",
                "required_tools": self._extract_required_tools(turns)
            }
        }

        return test_case

    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼Œä¸“é—¨ä¸ºç§˜ä¹¦Agentç³»ç»Ÿç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚

## ç§˜ä¹¦Agentå®Œæ•´ç³»ç»Ÿä¿¡æ¯

### æ—¥æœŸæ˜ŸæœŸå¯¹ç…§è¡¨ï¼ˆ2025å¹´12æœˆ-2026å¹´2æœˆï¼‰
12æœˆ01æ—¥ = æ˜ŸæœŸä¸€ åˆ° 12æœˆ31æ—¥ = æ˜ŸæœŸä¸‰
1æœˆ01æ—¥ = æ˜ŸæœŸå›› åˆ° 1æœˆ31æ—¥ = æ˜ŸæœŸå…­
2æœˆ01æ—¥ = æ˜ŸæœŸæ—¥ åˆ° 2æœˆ28æ—¥ = æ˜ŸæœŸå…­

### æ—¶é—´è®¡ç®—è§„åˆ™
- æŸ¥æ‰¾æŸä¸€å¤©æ˜¯æ˜ŸæœŸå‡ ï¼šæ ¹æ®ä¸Šé¢çš„æ—¥æœŸèŒƒå›´è®¡ç®—
- "ä¸‹å‘¨"æŒ‡çš„æ˜¯ä»å½“å‰æ—¥æœŸå¼€å§‹é‡åˆ°çš„ç¬¬ä¸€ä¸ªå‘¨ä¸€å¼€å§‹åˆ°å‘¨æ—¥ç»“æŸçš„å®Œæ•´å‘¨

## å¯ç”¨å·¥å…·ï¼ˆç§˜ä¹¦Agentä¼šä½¿ç”¨ï¼‰

### 1. contacts_create - åˆ›å»ºè”ç³»äºº
- å‚æ•°ï¼šname(å¯é€‰), company(å¯é€‰), position(å¯é€‰), phone(å¯é€‰), email(å¯é€‰), address(å¯é€‰), notes(å¯é€‰), relationship_type(å¯é€‰), birthday(å¯é€‰), gender(å¯é€‰), industry(å¯é€‰)
- è¯´æ˜ï¼šæ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥åªæä¾›éƒ¨åˆ†ä¿¡æ¯

### 2. contacts_update - æ›´æ–°è”ç³»äºº
- å‚æ•°ï¼šid(å¿…éœ€), name(å¯é€‰), company(å¯é€‰), position(å¯é€‰), phone(å¯é€‰), email(å¯é€‰), address(å¯é€‰), notes(å¯é€‰), relationship_type(å¯é€‰), birthday(å¯é€‰), gender(å¯é€‰), industry(å¯é€‰)
- è¯´æ˜ï¼šidæ˜¯å¿…éœ€çš„ï¼Œå…¶ä»–å‚æ•°å¯é€‰

### 3. contacts_delete - åˆ é™¤è”ç³»äºº
- å‚æ•°ï¼šid(å¿…éœ€)
- è¯´æ˜ï¼šéœ€è¦æä¾›è”ç³»äººID

### 4. contacts_search - æœç´¢è”ç³»äºº
- å‚æ•°ï¼šcontact_id(å¯é€‰), name(å¯é€‰), company(å¯é€‰), position(å¯é€‰), phone(å¯é€‰), email(å¯é€‰), address(å¯é€‰), context_search(å¯é€‰)
- è¯´æ˜ï¼šæ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥æ¨¡ç³ŠæŸ¥è¯¢

### 5. schedules_create - åˆ›å»ºæ—¥ç¨‹
- å‚æ•°ï¼štitle(å¿…éœ€), description(å¯é€‰), start_time(å¯é€‰), end_time(å¯é€‰), full_day(å¯é€‰), reminder_time(å¯é€‰), location(å¯é€‰), category(å¯é€‰)
- è¯´æ˜ï¼š
  * titleæ˜¯å¿…éœ€çš„
  * start_timeå’Œend_timeå¿…é¡»åŒæ—¶è®¾ç½®ï¼ˆè¦ä¹ˆéƒ½å¡«ï¼Œè¦ä¹ˆéƒ½ä¸å¡«ï¼‰
  * ä¸èƒ½åŒæ—¶è®¾ç½®start_time/end_timeå’Œfull_day
  * descriptionå¿…é¡»åŒ…å«æ—¥ç¨‹çš„å¤§æ¦‚å†…å®¹ã€æ—¥ç¨‹çš„ç›¸å…³äººå‘˜

### 6. schedules_update - æ›´æ–°æ—¥ç¨‹
- å‚æ•°ï¼šid(å¿…éœ€), title(å¯é€‰), description(å¯é€‰), start_time(å¯é€‰), end_time(å¯é€‰), full_day(å¯é€‰), reminder_time(å¯é€‰), location(å¯é€‰), category(å¯é€‰)
- è¯´æ˜ï¼šidæ˜¯å¿…éœ€çš„ï¼Œå…¶ä»–å‚æ•°å¯é€‰

### 7. schedules_delete - åˆ é™¤æ—¥ç¨‹
- å‚æ•°ï¼šid(å¿…éœ€)
- è¯´æ˜ï¼šéœ€è¦æä¾›æ—¥ç¨‹ID

### 8. schedules_search - æœç´¢æ—¥ç¨‹
- å‚æ•°ï¼štitle(å¯é€‰), description(å¯é€‰), start_time(å¯é€‰), end_time(å¯é€‰), location(å¯é€‰), category(å¯é€‰), query(å¯é€‰)
- è¯´æ˜ï¼š
  * è‡³å°‘è¦åŒ…å«ä¸€ä¸ªä»¥ä¸Šçš„å‚æ•°
  * å¦‚æœæœ‰start_timeå‚æ•°å¿…é¡»è®¾ç½®end_timeå‚æ•°
  * end_timeå€¼é»˜è®¤æ˜¯start_timeçš„å½“å¤©çš„æœ€åæ—¶åˆ»
  * ä¼˜å…ˆä½¿ç”¨queryä»¥å¤–çš„å‚æ•°ï¼Œå¦‚æœé€‰æ‹©äº†é™¤queryä»¥å¤–çš„å‚æ•°å°±ä¸è¦å†ä½¿ç”¨queryå‚æ•°äº†


### 9. finish - å®Œæˆä»»åŠ¡å¹¶è¿”å›æœ€ç»ˆç­”æ¡ˆ
- å‚æ•°ï¼šanswer(å¿…éœ€)
- è¯´æ˜ï¼šå½“å·²ç»æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”é—®é¢˜æ—¶ä½¿ç”¨

## ç§˜ä¹¦Agentè§„åˆ™

### æ ¸å¿ƒè§„åˆ™
1. æ¯æ¬¡è¿­ä»£åªèƒ½é€‰æ‹©ä¸€ä¸ªå·¥å…·
2. å½“è®¤ä¸ºå·²ç»å¯ä»¥å›ç­”é—®é¢˜æ—¶ï¼Œä½¿ç”¨finishå·¥å…·å¹¶æä¾›å®Œæ•´ç­”æ¡ˆ
3. ä¸èƒ½è¿ç»­ä½¿ç”¨åŒä¸€ä¸ªå·¥å…·è¶…è¿‡3æ¬¡
4. å¦‚æœä¸€ä¸ªå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨å…¶ä»–å·¥å…·
5. æ—¶é—´ç›¸å…³æŸ¥è¯¢å¯ä»¥å‚è€ƒæ—¥æœŸæ˜ŸæœŸå¯¹ç…§è¡¨

## æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡

### è¾“å‡ºï¼šå®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹JSON

### åˆ†ææ­¥éª¤
1. **ç†è§£æŸ¥è¯¢æ„å›¾**ï¼šåˆ†æç”¨æˆ·æƒ³è¦å®Œæˆä»€ä¹ˆä»»åŠ¡
2. **é€‰æ‹©åˆé€‚å·¥å…·**ï¼šæ ¹æ®æ„å›¾é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
3. **ç¡®å®šå·¥å…·è°ƒç”¨**ï¼šæ ¹æ®æ“ä½œç±»å‹é€‰æ‹©åˆé€‚çš„å·¥å…·
4. **æ„å»ºé¢„æœŸè¡Œä¸º**ï¼šè®¾è®¡å®Œæ•´çš„ReActæµç¨‹ï¼ˆæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿï¼‰
5. **å¤„ç†æ—¶é—´ä¿¡æ¯**ï¼šæ­£ç¡®å¤„ç†ç›¸å¯¹æ—¶é—´ï¼ˆå¦‚ä¸‹å‘¨ã€æ˜å¤©ä¸‹åˆç­‰ï¼‰
6. **éµå¾ªè§„åˆ™**ï¼šç¡®ä¿å·¥å…·è°ƒç”¨ç¬¦åˆæ‰€æœ‰çº¦æŸæ¡ä»¶

## æµ‹è¯•ç”¨ä¾‹JSONæ ¼å¼
```json
{
  "id": "TEST_CASE_ID",
  "user_id": "user_18600241181",
  "name": "æµ‹è¯•ç”¨ä¾‹åç§°",
  "description": "æµ‹è¯•ç”¨ä¾‹æè¿°",
  "mode": "single_turn",
  "conversation": {
    "turns": [
      {
        "turn_id": 1,
        "user_input": {
          "type": "text | image | mixed",
          "content": "ç”¨æˆ·è¾“å…¥å†…å®¹"
        },
        "context": {
          "requires_context": false,
          "depends_on": []
        },
        "expected_behavior": {
          "steps": [
            {
              "step": 1,
              "type": "tool_call",
              "tool_name": "å·¥å…·åç§°",
              "parameters": {
                "å‚æ•°": "å€¼"
              }
            },
            {
              "step": 2,
              "type": "tool_result",
              "result": {
                "success": true,
                "data": {
                  "è¿”å›æ•°æ®": "æ¨¡æ‹Ÿçš„çœŸå®è¿”å›æ•°æ®"
                }
              }
            },
            {
              "step": 3,
              "type": "finish",
              "expected_response": "ç”¨æˆ·æœŸæœ›çœ‹åˆ°çš„æœ€ç»ˆå›å¤"
            }
          ]
        }
      }
    ]
  },
  "metadata": {
    "conversation_type": "single_turn",
    "turns": 1,
    "context_complexity": "low | medium | high",
    "required_tools": ["å·¥å…·1", "å·¥å…·2"]
  }
}
```

## è¾“å‡ºè¦æ±‚
- ä¸¥æ ¼åˆ†ææŸ¥è¯¢çš„æ„å›¾ï¼Œæ­£ç¡®é€‰æ‹©å·¥å…·
- å‡†ç¡®æå–æŸ¥è¯¢ä¸­çš„å®ä½“ä¿¡æ¯ï¼ˆå§“åã€ç”Ÿæ—¥ã€ç”µè¯ç­‰ï¼‰
- ğŸš¨ é‡è¦çº¦æŸï¼šåªèƒ½ä½¿ç”¨ç”¨æˆ·æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä¸èƒ½ç¼–é€ è™šå‡æ•°æ®
- ğŸš¨ å¦‚æœå·¥å…·è¿”å›çš„æ•°æ®åŒ…å«ç”¨æˆ·æœªæåˆ°çš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
- æ ¹æ®ç§˜ä¹¦Agentçš„ReActæ¨¡å¼è®¾è®¡åˆç†çš„æ­¥éª¤æµç¨‹
- æ¯ä¸¤ä¸ªstepæ˜¯ä¸€ä¸ªå·¥å…·è°ƒç”¨çš„è¿‡ç¨‹åŒ…æ‹¬è¾“å…¥å‚æ•°ä»¥åŠå·¥å…·æ‰§è¡Œçš„ç»“æœ finishå·¥å…·åªæœ‰ä¸€ä¸ªstep
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå­—æ®µå®Œæ•´
- æè¿°è¦ç®€æ´æ˜äº†
- åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ€§æ–‡å­—
- ä¸è¦ä½¿ç”¨markdownä»£ç å—æ ‡è®°
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
- è¾“å‡ºå·¥å…·è¿”å›æ•°æ®è¦æ¨¡æ‹Ÿ ä¸èƒ½ç›´æ¥è¿”å›ä¸€å¥è¯
- æ¯æ¡æµ‹è¯•éƒ½æ˜¯ç‹¬ç«‹çš„æ•°æ® ä¸éœ€è¦æœ‰ä»»ä½•ä¾èµ–
- ğŸš¨ user_idå¿…é¡»ç‹¬ä¸€æ— äºŒï¼šæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½å¿…é¡»ä½¿ç”¨ä¸åŒçš„user_idï¼Œå»ºè®®ä½¿ç”¨æ—¶é—´æˆ³æ ¼å¼ï¼ˆå¦‚ï¼šuser_20260113_152922_311ï¼‰
- ğŸš¨ ä¸¥æ ¼ç¦æ­¢ï¼šä¸è¦åœ¨å·¥å…·è¿”å›æ•°æ®ä¸­ç¼–é€ ä»»ä½•ç”¨æˆ·æœªæåŠçš„ä¿¡æ¯
"""

    def _extract_json_from_response(self, response: str) -> Dict:
        """ä»Geminiå“åº”ä¸­æå–JSON (å·²å¼ƒç”¨ï¼Œæ”¹ç”¨_parse_json_with_retry)"""
        import re

        print(f"   ğŸ“„ åŸå§‹å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")
        print(f"   ğŸ“„ å“åº”å‰200å­—ç¬¦: {response[:200]}...")

        # å°è¯•ç›´æ¥è§£æJSON
        try:
            result = json.loads(response)
            print(f"   âœ… ç›´æ¥JSONè§£ææˆåŠŸ")
            return result
        except Exception as e:
            print(f"   âš ï¸  ç›´æ¥JSONè§£æå¤±è´¥: {str(e)[:50]}")

        # å°è¯•ä»ä»£ç å—ä¸­æå–JSON - ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼å¤„ç†åµŒå¥—å¤§æ‹¬å·
        json_pattern = r'```(?:json)?\s*(\{[\s\S]*?\})\s*```'
        match = re.search(json_pattern, response, re.DOTALL)
        if match:
            try:
                result = json.loads(match.group(1))
                print(f"   âœ… ä»ä»£ç å—JSONè§£ææˆåŠŸ")
                return result
            except Exception as e:
                print(f"   âš ï¸  ä»£ç å—JSONè§£æå¤±è´¥: {str(e)[:50]}")

        # å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡ï¼ˆæ”¹è¿›çš„æ­£åˆ™è¡¨è¾¾å¼ï¼‰
        json_pattern = r'\{(?:[^{}]|\{[^{}]*\})*\}'
        match = re.search(json_pattern, response, re.DOTALL)
        if match:
            try:
                result = json.loads(match.group())
                print(f"   âœ… æå–JSONå¯¹è±¡è§£ææˆåŠŸ")
                return result
            except Exception as e:
                print(f"   âš ï¸  æå–JSONå¯¹è±¡è§£æå¤±è´¥: {str(e)[:50]}")
                # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                fixed_json = self._try_fix_json(match.group())
                if fixed_json:
                    try:
                        result = json.loads(fixed_json)
                        print(f"   âœ… ä¿®å¤åJSONè§£ææˆåŠŸ")
                        return result
                    except Exception as e2:
                        print(f"   âš ï¸  ä¿®å¤åJSONè§£æä»ç„¶å¤±è´¥: {str(e2)[:50]}")

        # å¦‚æœéƒ½æ— æ³•è§£æï¼Œè¿”å›é»˜è®¤ç»“æ„
        print(f"   âŒ æ‰€æœ‰JSONè§£ææ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é”™è¯¯ç»“æ„")
        # è¿”å›ä¸€ä¸ªå®Œæ•´çš„ã€æœ‰æ•ˆæ ¼å¼çš„JSONç»“æ„
        return {
            "id": "PARSE_ERROR",
            "conversation": {
                "turns": [{
                    "user_input": {
                        "type": "text",
                        "content": "æ— æ³•è§£æAPIå“åº”å†…å®¹"
                    },
                    "context": {
                        "requires_context": False,
                        "depends_on": []
                    },
                    "expected_behavior": {
                        "steps": [{
                            "step": 1,
                            "type": "finish",
                            "expected_response": "æˆ‘æ­£åœ¨ç†è§£æ‚¨çš„éœ€æ±‚ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»æˆ–å°è¯•é‡æ–°æè¿°æ‚¨çš„è¯·æ±‚ã€‚"
                        }]
                    }
                }]
            }
        }

    def _try_fix_json(self, json_str: str) -> Optional[str]:
        """å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜"""
        import re
        try:
            # ç§»é™¤å¯èƒ½çš„å°¾éšé€—å·
            fixed = re.sub(r',(\s*[}\]])', r'\1', json_str)
            # ä¿®å¤å•å¼•å·ä¸ºåŒå¼•å·
            fixed = re.sub(r"'([^']*)':", r'"\1":', fixed)
            fixed = re.sub(r": '([^']*)'", r': "\1"', fixed)
            # ä¿®å¤æœªé—­åˆçš„å­—ç¬¦ä¸²
            fixed = self._fix_unclosed_strings(fixed)
            # ä¿®å¤æ¢è¡Œç¬¦
            fixed = fixed.replace('\n', '\\n').replace('\r', '\\r')
            # ä¿®å¤åˆ¶è¡¨ç¬¦
            fixed = fixed.replace('\t', '\\t')
            return fixed
        except Exception as e:
            print(f"   âš ï¸  JSONä¿®å¤å°è¯•å¤±è´¥: {str(e)[:50]}")
            return None

    def _fix_unclosed_strings(self, json_str: str) -> str:
        """ä¿®å¤æœªé—­åˆçš„å­—ç¬¦ä¸²"""
        # è®¡ç®—å­—ç¬¦ä¸²ä¸­æœªé—­åˆçš„åŒå¼•å·æ•°é‡
        double_quotes = json_str.count('"') - json_str.count('\\"')
        # å¦‚æœæ˜¯å¥‡æ•°ï¼Œè¯´æ˜æœ‰æœªé—­åˆçš„å­—ç¬¦ä¸²
        if double_quotes % 2 == 1:
            # åœ¨æœ€åæ·»åŠ é—­åˆå¼•å·
            json_str = json_str.rstrip() + '"'
        return json_str

    async def _parse_json_with_retry(self, response: str, max_retries: int = 3) -> Dict:
        """ä½¿ç”¨å¤šç§ç­–ç•¥é‡è¯•è§£æJSON"""
        import json
        import re

        print(f"   ğŸ“„ å¼€å§‹JSONè§£æï¼Œå“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

        # ç­–ç•¥1: ç›´æ¥è§£æ
        try:
            result = json.loads(response)
            print(f"   âœ… ç­–ç•¥1æˆåŠŸ: ç›´æ¥JSONè§£æ")
            return result
        except Exception as e:
            print(f"   âš ï¸  ç­–ç•¥1å¤±è´¥: {str(e)[:100]}")

        # ç­–ç•¥2: ä»ä»£ç å—ä¸­æå–
        try:
            json_pattern = r'```(?:json)?\s*(\{[\s\S]*?\})\s*```'
            match = re.search(json_pattern, response, re.DOTALL)
            if match:
                result = json.loads(match.group(1))
                print(f"   âœ… ç­–ç•¥2æˆåŠŸ: ä»ä»£ç å—æå–JSON")
                return result
        except Exception as e:
            print(f"   âš ï¸  ç­–ç•¥2å¤±è´¥: {str(e)[:100]}")

        # ç­–ç•¥3: æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
        try:
            json_pattern = r'\{(?:[^{}]|\{[^{}]*\})*\}'
            match = re.search(json_pattern, response, re.DOTALL)
            if match:
                # å°è¯•ä¿®å¤JSON
                fixed_json = self._try_fix_json(match.group())
                if fixed_json:
                    result = json.loads(fixed_json)
                    print(f"   âœ… ç­–ç•¥3æˆåŠŸ: æå–å¹¶ä¿®å¤JSONå¯¹è±¡")
                    return result
        except Exception as e:
            print(f"   âš ï¸  ç­–ç•¥3å¤±è´¥: {str(e)[:100]}")

        # ç­–ç•¥4: é€è¡Œæ¸…ç†å’Œä¿®å¤
        for retry in range(max_retries):
            try:
                print(f"   ğŸ”„ ç­–ç•¥4é‡è¯• {retry + 1}/{max_retries}")

                # æ¸…ç†å“åº”æ–‡æœ¬
                cleaned = response.strip()

                # å¦‚æœæœ‰markdownä»£ç å—æ ‡è®°ï¼Œæå–å†…å®¹
                if cleaned.startswith('```'):
                    # ç§»é™¤å¼€å¤´çš„```å’Œå¯èƒ½çš„jsonæ ‡è®°
                    cleaned = re.sub(r'^```[a-zA-Z]*\s*', '', cleaned)
                    # ç§»é™¤ç»“å°¾çš„```
                    cleaned = re.sub(r'\s*```$', '', cleaned)

                # å°è¯•ç›´æ¥è§£æ
                result = json.loads(cleaned)
                print(f"   âœ… ç­–ç•¥4æˆåŠŸ: æ¸…ç†åè§£æ")
                return result
            except Exception as e:
                error_msg = str(e)[:100]
                print(f"   âš ï¸  ç­–ç•¥4é‡è¯• {retry + 1} å¤±è´¥: {error_msg}")

                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡é‡è¯•ï¼Œç­‰å¾…ä¸€ä¸‹
                if retry < max_retries - 1:
                    await asyncio.sleep(0.5)

        # ç­–ç•¥5: å°è¯•æå–éƒ¨åˆ†JSONå¹¶è¡¥å…¨
        try:
            print(f"   ğŸ”„ ç­–ç•¥5: å°è¯•æå–éƒ¨åˆ†JSON")

            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ª{
            first_brace = response.find('{')
            last_brace = response.rfind('}')

            if first_brace != -1 and last_brace != -1:
                partial = response[first_brace:last_brace + 1]

                # å°è¯•ä¿®å¤
                fixed = self._try_fix_json(partial)
                if fixed:
                    result = json.loads(fixed)
                    print(f"   âœ… ç­–ç•¥5æˆåŠŸ: æå–éƒ¨åˆ†JSONå¹¶ä¿®å¤")
                    return result
        except Exception as e:
            print(f"   âš ï¸  ç­–ç•¥5å¤±è´¥: {str(e)[:100]}")
            import traceback
            traceback.print_exc()

        # æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤é”™è¯¯ç»“æ„
        print(f"   âŒ æ‰€æœ‰JSONè§£æç­–ç•¥éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é”™è¯¯ç»“æ„")

        return {
            "id": "PARSE_ERROR",
            "conversation": {
                "turns": [{
                    "user_input": {
                        "type": "text",
                        "content": "æ— æ³•è§£æAPIå“åº”å†…å®¹"
                    },
                    "context": {
                        "requires_context": False,
                        "depends_on": []
                    },
                    "expected_behavior": {
                        "steps": [{
                            "step": 1,
                            "type": "finish",
                            "expected_response": "æˆ‘æ­£åœ¨ç†è§£æ‚¨çš„éœ€æ±‚ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»æˆ–å°è¯•é‡æ–°æè¿°æ‚¨çš„è¯·æ±‚ã€‚"
                        }]
                    }
                }]
            }
        }

    def _is_response_complete(self, response: str) -> bool:
        """æ£€æŸ¥APIå“åº”æ˜¯å¦å®Œæ•´"""
        # åŸºæœ¬å®Œæ•´æ€§æ£€æŸ¥
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰æœªé—­åˆçš„å¤§æ‹¬å·
        open_braces = response.count('{')
        close_braces = response.count('}')
        if open_braces != close_braces:
            return False

        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœªé—­åˆçš„æ–¹æ‹¬å·
        open_brackets = response.count('[')
        close_brackets = response.count(']')
        if open_brackets != close_brackets:
            return False

        # 3. æ£€æŸ¥æ˜¯å¦ä»¥å®Œæ•´JSONç»“æ„ç»“å°¾ï¼ˆä»¥}ç»“å°¾ï¼‰
        stripped = response.strip()
        if not stripped.endswith('}') and not stripped.endswith(']'):
            return False

        # 4. æ£€æŸ¥å“åº”é•¿åº¦æ˜¯å¦è¿‡çŸ­ï¼ˆå¯èƒ½æˆªæ–­ï¼‰
        if len(response) < 200:
            return False

        return True

    def _is_unclear_response(self, response: str) -> bool:
        """æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«æ— æ³•ç†è§£çš„æç¤º"""
        unclear_patterns = [
            "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç†è§£",
            "æ— æ³•ç†è§£æ‚¨çš„è¯·æ±‚",
            "é‡æ–°æè¿°",
            "æ— æ³•å¤„ç†",
            "æ— æ³•è§£æ",
            "æˆ‘æ— æ³•ç†è§£",
            "æŠ±æ­‰ï¼Œæ— æ³•",
            "æ— æ³•å¸®åŠ©æ‚¨",
            "æ— æ³•å®Œæˆ",
            "æ— æ³•è¯†åˆ«",
            "ä¸æ¸…æ¥šæ‚¨çš„éœ€æ±‚",
            "è¯·é‡æ–°æè¿°",
            "é‡æ–°æé—®",
            "I cannot understand",
            "Sorry, I can't",
            "Unable to understand",
            "I'm sorry, I cannot"
        ]

        response_lower = response.lower()
        for pattern in unclear_patterns:
            if pattern.lower() in response_lower:
                return True

        # æ£€æŸ¥å“åº”æ˜¯å¦è¿‡çŸ­ä¸”æ²¡æœ‰JSONç»“æ„
        if len(response.strip()) < 50 and '{' not in response and '[' not in response:
            return True

        return False

    def _extract_required_tools(self, turns: List[Dict]) -> List[str]:
        """æå–æ‰€æœ‰éœ€è¦çš„å·¥å…·"""
        tools = set()
        for turn in turns:
            steps = turn.get("expected_behavior", {}).get("steps", [])
            for step in steps:
                if step.get("type") == "tool_call":
                    tool_name = step.get("tool_name")
                    if tool_name and tool_name != "finish":
                        tools.add(tool_name)
        return list(tools)


async def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å¤šè½®Excelæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨')
    parser.add_argument('--count', type=int, help='æµ‹è¯•æŒ‡å®šæ•°é‡çš„æ•°æ®ï¼ˆä¾‹å¦‚ï¼š--count 2ï¼‰')
    parser.add_argument('--all', action='store_true', help='æµ‹è¯•æ‰€æœ‰æ•°æ®')
    parser.add_argument('--failed', action='store_true', help='åªç”Ÿæˆä¹‹å‰å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹')
    parser.add_argument('--excel', required=True, help='Excelæ–‡ä»¶è·¯å¾„ï¼ˆä¾‹å¦‚ï¼šå¤šè½®.xlsxï¼‰')
    parser.add_argument('--output', default='multi_turn_test_cases.json', help='è¾“å‡ºJSONæ–‡ä»¶åï¼ˆé»˜è®¤ï¼šmulti_turn_test_cases.jsonï¼‰')
    args = parser.parse_args()

    if not args.count and not args.all and not args.failed:
        print("é”™è¯¯ï¼šå¿…é¡»æŒ‡å®š --countã€--all æˆ– --failed å‚æ•°")
        return

    print("=" * 80)
    print("å¤šè½®Excelæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨")
    print("=" * 80)
    print("ç‰¹æ€§ï¼š")
    print("  âœ“ æ”¯æŒå¤šè½®å¯¹è¯æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ")
    print("  âœ“ æ¯è¡Œä¸€æ¡æµ‹è¯•æ•°æ®ï¼Œæ¯åˆ—ä¸€ä¸ªè½®æ¬¡")
    print("  âœ“ æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è‡ªåŠ¨å¤„ç†")
    print("  âœ“ åŠ¨æ€æ—¶é—´æˆ³")
    print("=" * 80)
    print()

    generator = MultiTurnTestCaseGenerator()

    # åˆå§‹åŒ–
    print("æ­£åœ¨åˆå§‹åŒ–Gemini-3-Flash-Preview...")
    await generator.initialize()
    print("åˆå§‹åŒ–å®Œæˆï¼\n")

    # è¯»å–Excel
    excel_path = args.excel
    print(f"ğŸ“– è¯»å–Excelæ–‡ä»¶: {excel_path}")
    df = pd.read_excel(excel_path)
    print(f"   æ€»è¡Œæ•°: {len(df)}")
    print(f"   åˆ—å: {df.columns.tolist()}\n")

    # ç¡®å®šè¦å¤„ç†çš„æ•°æ®èŒƒå›´
    if args.all:
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹ (å…¨éƒ¨æ•°æ®)")
        start_idx = 0
        end_idx = len(df)
        total_count = end_idx - start_idx
    elif args.failed:
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹ (åªé‡æ–°ç”Ÿæˆå¤±è´¥çš„ç”¨ä¾‹)")
        # æœ‰é—®é¢˜çš„æµ‹è¯•ç”¨ä¾‹å¯¹åº”çš„è¡Œç´¢å¼•
        # MULTI_TURN_028, MULTI_TURN_034
        failed_indices = [1, 7]  # å¯¹åº”Excelä¸­çš„è¡Œå·-1
        start_idx = min(failed_indices)
        end_idx = max(failed_indices) + 1
        total_count = len(failed_indices)
        print(f"   å¤±è´¥çš„è¡Œç´¢å¼•: {failed_indices}")
    else:
        count = args.count
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹ (æŒ‡å®šæ•°é‡: {count})")
        start_idx = 0
        end_idx = min(count, len(df))
        total_count = count

    print("=" * 80)

    all_test_cases = []
    successful = 0
    failed = 0

    # ç¡®å®šè¦å¤„ç†çš„å…·ä½“è¡Œ
    if args.failed:
        # åªå¤„ç†å¤±è´¥çš„è¡Œ
        indices_to_process = [1, 7]  # Excelè¡Œç´¢å¼•-1
    else:
        # å¤„ç†æŒ‡å®šèŒƒå›´å†…çš„æ‰€æœ‰è¡Œ
        indices_to_process = list(range(start_idx, end_idx))

    # å¤„ç†æ•°æ®
    for idx in indices_to_process:
        try:
            # è·å–ä¸€è¡Œæ•°æ®ï¼ˆåŒ…å«å¤šä¸ªè½®æ¬¡ï¼‰
            row_data = df.iloc[idx].to_dict()

            test_case_id = f"MULTI_TURN_{idx + 27:03d}"

            print(f"\n[è¿›åº¦] {indices_to_process.index(idx) + 1}/{total_count}")
            print(f"   æµ‹è¯•ç”¨ä¾‹ID: {test_case_id}")
            print(f"   User IDå°†ä½¿ç”¨: {generator._generate_unique_user_id()[:30]}...")

            # è®¡ç®—è½®æ¬¡æ•°é‡
            turn_count = len([v for v in row_data.values() if pd.notna(v) and str(v).strip()])
            print(f"   è½®æ¬¡æ•°é‡: {turn_count}")

            test_case = await generator.generate_multi_turn_test_case(row_data, test_case_id)

            # æ·»åŠ åˆ°æ•°ç»„
            all_test_cases.append(test_case)

            print(f"âœ… æˆåŠŸç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹")
            print(f"   å®é™…User ID: {test_case['user_id']}")
            print(f"   è½®æ¬¡æ•°é‡: {test_case['metadata']['turns']}")
            successful += 1

        except Exception as e:
            print(f"âŒ å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            failed += 1

    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    if args.failed:
        # å¦‚æœæ˜¯é‡æ–°ç”Ÿæˆå¤±è´¥çš„ç”¨ä¾‹ï¼Œä½¿ç”¨ä¸åŒçš„è¾“å‡ºæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = f'multi_turn_failed_retries_{timestamp}.json'
    else:
        output_file = args.output

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_test_cases, f, ensure_ascii=False, indent=2)

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š å¤šè½®æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ")
    print("=" * 80)
    print(f"âœ… æˆåŠŸ: {successful} ä¸ª")
    print(f"âŒ å¤±è´¥: {failed} ä¸ª")
    print(f"ğŸ“ æ€»è®¡: {successful + failed} ä¸ª")
    print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“Š JSONç»“æ„: æ•°ç»„åŒ…å« {len(all_test_cases)} ä¸ªå¤šè½®æµ‹è¯•ç”¨ä¾‹")
    print("\nğŸ“ ç‰¹ç‚¹:")
    print(f"   â€¢ æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½æœ‰å”¯ä¸€çš„user_id")
    print(f"   â€¢ æ”¯æŒå¤šè½®å¯¹è¯")
    print(f"   â€¢ æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è‡ªåŠ¨å¤„ç†")
    print(f"   â€¢ åŠ¨æ€æ—¶é—´æˆ³")
    print(f"\nğŸ”§ ä½¿ç”¨æ–¹å¼:")
    print(f"   â€¢ æµ‹è¯•å‰2æ¡: python generate_multi_turn.py --count 2 --excel {args.excel}")
    print(f"   â€¢ æµ‹è¯•æ‰€æœ‰æ•°æ®: python generate_multi_turn.py --all --excel {args.excel}")
    print(f"   â€¢ é‡æ–°ç”Ÿæˆå¤±è´¥ç”¨ä¾‹: python generate_multi_turn.py --failed --excel {args.excel}")


if __name__ == "__main__":
    asyncio.run(main())
