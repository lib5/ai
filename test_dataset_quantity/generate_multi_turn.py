#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šè½®Excelæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨
- æ”¯æŒå¤šè½®å¯¹è¯çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ
- æ¯è¡Œæ˜¯ä¸€æ¡å¤šè½®æµ‹è¯•æ•°æ®ï¼Œæ¯åˆ—æ˜¯ä¸€ä¸ªè½®æ¬¡çš„ç”¨æˆ·é—®é¢˜

ä½¿ç”¨æ–¹å¼:
python generate_multi_turn.py --count 2 --excel å¤šè½®.xlsx
python generate_multi_turn.py --all --excel å¤šè½®.xlsx
"""

import json
import asyncio
import sys
import os
import pandas as pd
import argparse
import base64
from datetime import datetime
from typing import Dict, List, Optional

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.true_react_agent import TrueReActAgent


class MultiTurnTestCaseGenerator:
    """å¤šè½®æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨"""

    def __init__(self):
        self.agent = None

    async def initialize(self):
        """åˆå§‹åŒ–"""
        self.agent = TrueReActAgent()
        await self.agent.initialize()

    def _generate_unique_user_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„user_id"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        return f"user_{timestamp}"

    def _is_image_url(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ¬åœ°å›¾ç‰‡æ–‡ä»¶"""
        image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp']

        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°å›¾ç‰‡æ–‡ä»¶
        if os.path.isfile(text):
            # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            return any(text.lower().endswith(ext) for ext in image_extensions)

        return False

    def _get_current_time_info(self) -> str:
        """è·å–å½“å‰æ—¶é—´ä¿¡æ¯"""
        current_time = datetime.now()
        current_date_str = current_time.strftime('%Y-%m-%d')
        weekday_str = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'æ—¥'][current_time.weekday()]
        return f"ä»Šå¤©å½“å‰æ—¶é—´ï¼š{current_date_str}ï¼Œä»Šå¤©æ˜¯æ˜ŸæœŸ{weekday_str}"

    def _download_and_convert_image(self, url: str) -> str:
        """è¯»å–æœ¬åœ°å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64æ ¼å¼"""
        try:
            print(f"   ğŸ“ æ­£åœ¨è¯»å–æœ¬åœ°å›¾ç‰‡: {url[:80]}...")

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.isfile(url):
                print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨: {url}")
                return ""

            # è¯»å–æœ¬åœ°å›¾ç‰‡æ–‡ä»¶
            with open(url, 'rb') as f:
                image_data = f.read()

            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®šcontent_type
            if url.lower().endswith('.png'):
                content_type = 'image/png'
            elif url.lower().endswith('.gif'):
                content_type = 'image/gif'
            elif url.lower().endswith('.jpg') or url.lower().endswith('.jpeg'):
                content_type = 'image/jpeg'
            elif url.lower().endswith('.webp'):
                content_type = 'image/webp'
            else:
                content_type = 'image/jpeg'  # é»˜è®¤

            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(image_data).decode('utf-8')
            base64_data = f"data:{content_type};base64,{image_base64}"

            print(f"   âœ… æœ¬åœ°å›¾ç‰‡è¯»å–æˆåŠŸï¼Œå¤§å°: {len(image_data)} bytes")
            return base64_data

        except Exception as e:
            print(f"   âŒ å›¾ç‰‡è¯»å–å¤±è´¥: {e}")
            return ""

    def _build_prompt_for_turn(self, query: str, turn_number: int, total_turns: int, is_first_turn: bool, previous_context: List[Dict] = None) -> str:
        """ä¸ºç‰¹å®šè½®æ¬¡æ„å»ºæç¤ºè¯"""
        time_info = self._get_current_time_info()

        if self._is_image_url(query):
            image_base64 = self._download_and_convert_image(query)

            if image_base64:
                base_prompt = f"""è¯·åˆ†æä»¥ä¸‹æœ¬åœ°å›¾ç‰‡å†…å®¹ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

å›¾ç‰‡æ–‡ä»¶ï¼š{query}
å›¾ç‰‡å†…å®¹å·²è½¬æ¢ä¸ºbase64æ ¼å¼ï¼Œè¯·åˆ†æå›¾ç‰‡ä¸­çš„ä¿¡æ¯ã€‚

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
ç›´æ¥åŸºäºå›¾ç‰‡å†…å®¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œå›¾ç‰‡å†…å®¹åº”è¯¥è¢«Agentç›´æ¥ç†è§£å¹¶æ‰§è¡Œç›¸åº”æ“ä½œã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨å›¾ç‰‡ä¸­æ˜ç¡®æ˜¾ç¤ºçš„ä¿¡æ¯
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""

                # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
                if not is_first_turn and previous_context:
                    context_info = self._format_previous_context(previous_context)
                    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹æœ¬åœ°å›¾ç‰‡å†…å®¹ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context_info}

å›¾ç‰‡æ–‡ä»¶ï¼š{query}
å›¾ç‰‡å†…å®¹å·²è½¬æ¢ä¸ºbase64æ ¼å¼ï¼Œè¯·åˆ†æå›¾ç‰‡ä¸­çš„ä¿¡æ¯ã€‚

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
ç›´æ¥åŸºäºå›¾ç‰‡å†…å®¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œå›¾ç‰‡å†…å®¹åº”è¯¥è¢«Agentç›´æ¥ç†è§£å¹¶æ‰§è¡Œç›¸åº”æ“ä½œã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨å›¾ç‰‡ä¸­æ˜ç¡®æ˜¾ç¤ºçš„ä¿¡æ¯ï¼Œä»¥åŠå‰é¢è½®æ¬¡ä¸­å·²ç»åˆ›å»ºæˆ–è·å–çš„ä¿¡æ¯
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""
                else:
                    user_prompt = base_prompt
            else:
                base_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼Œç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

âš ï¸ é‡è¦è¯´æ˜ï¼šå›¾ç‰‡æ–‡ä»¶æ— æ³•è¯»å–ã€‚

å›¾ç‰‡æ–‡ä»¶ï¼š{query}

ğŸš¨ é‡è¦çº¦æŸï¼š
1. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
2. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
3. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
è¯·ç”Ÿæˆä¸€ä¸ªåˆç†çš„æµ‹è¯•ç”¨ä¾‹ã€‚

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""

                # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
                if not is_first_turn and previous_context:
                    context_info = self._format_previous_context(previous_context)
                    user_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼Œç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context_info}

âš ï¸ é‡è¦è¯´æ˜ï¼šå›¾ç‰‡æ–‡ä»¶æ— æ³•è¯»å–ã€‚

å›¾ç‰‡æ–‡ä»¶ï¼š{query}

ğŸš¨ é‡è¦çº¦æŸï¼š
1. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
2. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
3. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

âš ï¸ é‡è¦ï¼šä¸è¦ç”Ÿæˆ image_analysis å·¥å…·è°ƒç”¨æ­¥éª¤ã€‚
è¯·ç”Ÿæˆä¸€ä¸ªåˆç†çš„æµ‹è¯•ç”¨ä¾‹ã€‚

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""
                else:
                    user_prompt = base_prompt
        else:
            # æ„å»ºåŸºç¡€æç¤º
            base_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨ç”¨æˆ·æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼ˆå§“åã€ç”Ÿæ—¥ã€ç”µè¯ç­‰ï¼‰
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""

            # å¦‚æœä¸æ˜¯ç¬¬ä¸€è½®ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            if not is_first_turn and previous_context:
                context_info = self._format_previous_context(previous_context)
                user_prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„æµ‹è¯•ç”¨ä¾‹JSONï¼š

{time_info}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context_info}

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¿™æ˜¯ç¬¬ {turn_number} è½®å¯¹è¯ï¼ˆæ€»å…± {total_turns} è½®ï¼‰ã€‚

ğŸš¨ é‡è¦çº¦æŸï¼š
1. åªèƒ½ä½¿ç”¨ç”¨æˆ·æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä»¥åŠå‰é¢è½®æ¬¡ä¸­å·²ç»åˆ›å»ºæˆ–è·å–çš„ä¿¡æ¯
2. ğŸš« ä¸¥æ ¼ç¦æ­¢ç¼–é€ è™šå‡æ•°æ®ï¼šå…¬å¸ã€èŒä½ã€é‚®ç®±ã€åœ°å€ç­‰
3. ğŸš« å¦‚æœå·¥å…·è¿”å›æ•°æ®åŒ…å«æœªæåŠçš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
4. ğŸš« ä¸è¦ç¼–é€ è”ç³»äººIDã€åˆ›å»ºæ—¶é—´ç­‰è™šå‡ä¿¡æ¯

è¯·ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¾“å‡ºæµ‹è¯•ç”¨ä¾‹ã€‚"""
            else:
                user_prompt = base_prompt

        return user_prompt

    def _format_previous_context(self, previous_context: List[Dict]) -> str:
        """æ ¼å¼åŒ–å‰é¢è½®æ¬¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        if not previous_context:
            return ""

        context_parts = []
        for ctx in previous_context:
            if ctx['type'] == 'contact_created':
                contact_info = ctx['contact_info']
                context_parts.append(f"- åœ¨ç¬¬{ctx['turn_id']}è½®å·²åˆ›å»ºè”ç³»äººï¼š{contact_info['name']}")
                for key, value in contact_info.items():
                    if key != 'name' and value is not None:
                        context_parts.append(f"  â€¢ {key}: {value}")
            elif ctx['type'] == 'contact_searched':
                contact_info = ctx['contact_info']
                context_parts.append(f"- åœ¨ç¬¬{ctx['turn_id']}è½®å·²æœç´¢åˆ°è”ç³»äººï¼š{contact_info['name']}")
                for key, value in contact_info.items():
                    if key != 'name' and value is not None:
                        context_parts.append(f"  â€¢ {key}: {value}")
            elif ctx['type'] == 'schedule_created':
                schedule_info = ctx['schedule_info']
                context_parts.append(f"- åœ¨ç¬¬{ctx['turn_id']}è½®å·²åˆ›å»ºæ—¥ç¨‹ï¼š{schedule_info['title']}")
                for key, value in schedule_info.items():
                    if key != 'title' and value is not None:
                        context_parts.append(f"  â€¢ {key}: {value}")

        return "\n".join(context_parts) if context_parts else ""

    def _store_turn_context(self, turn: Dict, previous_context: List[Dict]):
        """å­˜å‚¨è½®æ¬¡çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        steps = turn.get("expected_behavior", {}).get("steps", [])

        for step in steps:
            if step.get("type") == "tool_result":
                result_data = step.get("result", {}).get("data", {})

                # å¦‚æœæ˜¯åˆ›å»ºè”ç³»äºº
                if "name" in result_data and "id" in result_data:
                    # æå–æœ‰ç”¨çš„ä¿¡æ¯
                    contact_info = {
                        "name": result_data.get("name"),
                        "birthday": result_data.get("birthday"),
                        "phone": result_data.get("phone"),
                        "email": result_data.get("email"),
                        "company": result_data.get("company"),
                        "position": result_data.get("position"),
                        "notes": result_data.get("notes")
                    }
                    # è¿‡æ»¤æ‰Noneå€¼
                    contact_info = {k: v for k, v in contact_info.items() if v is not None}

                    previous_context.append({
                        "type": "contact_created",
                        "turn_id": turn["turn_id"],
                        "contact_info": contact_info
                    })

                # å¦‚æœæ˜¯æœç´¢è”ç³»äºº
                elif "contacts" in result_data:
                    contacts = result_data["contacts"]
                    if contacts and isinstance(contacts, list) and contacts[0]:
                        contact = contacts[0]
                        # æå–æœ‰ç”¨çš„ä¿¡æ¯
                        contact_info = {
                            "name": contact.get("name"),
                            "birthday": contact.get("birthday"),
                            "phone": contact.get("phone"),
                            "email": contact.get("email"),
                            "company": contact.get("company"),
                            "position": contact.get("position"),
                            "notes": contact.get("notes")
                        }
                        # è¿‡æ»¤æ‰Noneå€¼
                        contact_info = {k: v for k, v in contact_info.items() if v is not None}

                        previous_context.append({
                            "type": "contact_searched",
                            "turn_id": turn["turn_id"],
                            "contact_info": contact_info
                        })

                # å¦‚æœæ˜¯åˆ›å»ºæ—¥ç¨‹
                elif "title" in result_data and "id" in result_data:
                    schedule_info = {
                        "title": result_data.get("title"),
                        "description": result_data.get("description"),
                        "start_time": result_data.get("start_time"),
                        "end_time": result_data.get("end_time"),
                        "location": result_data.get("location"),
                        "category": result_data.get("category")
                    }
                    # è¿‡æ»¤æ‰Noneå€¼
                    schedule_info = {k: v for k, v in schedule_info.items() if v is not None}

                    previous_context.append({
                        "type": "schedule_created",
                        "turn_id": turn["turn_id"],
                        "schedule_info": schedule_info
                    })

    async def generate_multi_turn_test_case(self, row_data: Dict, test_case_id: str) -> Dict:
        """ç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹"""
        # ç”Ÿæˆå”¯ä¸€çš„user_id
        unique_user_id = self._generate_unique_user_id()

        # è·å–æ‰€æœ‰è½®æ¬¡çš„æŸ¥è¯¢
        turn_queries = []
        for col_name, query in row_data.items():
            if pd.notna(query) and str(query).strip():
                turn_queries.append(str(query).strip())

        if not turn_queries:
            raise ValueError("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æŸ¥è¯¢æ•°æ®")

        total_turns = len(turn_queries)
        turns = []

        # å­˜å‚¨å‰é¢è½®æ¬¡çš„é‡è¦ä¿¡æ¯ï¼Œç”¨äºåç»­è½®æ¬¡çš„ä¸Šä¸‹æ–‡
        previous_turns_context = []

        for turn_idx, query in enumerate(turn_queries):
            turn_number = turn_idx + 1
            print(f"\n   ğŸ“ ç”Ÿæˆç¬¬ {turn_number} è½®æµ‹è¯•ç”¨ä¾‹")
            print(f"      Query: {query[:100]}...")

            # æ„å»ºæç¤ºè¯
            user_prompt = self._build_prompt_for_turn(query, turn_number, total_turns, turn_idx == 0, previous_turns_context)

            # æ„å»ºè¯·æ±‚
            messages = [
                {"role": "system", "content": self._build_system_prompt()},
                {"role": "user", "content": user_prompt}
            ]

            try:
                # è°ƒç”¨GPTç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
                response = await self.agent.openai_service.chat_completion(
                    messages,
                    max_tokens=4000,
                    temperature=0.1
                )

                content = response.get("choices", [{}])[0].get("message", {}).get("content", "")
                print(f"   âœ… GPTå“åº”å®Œæˆ")

                # è§£æJSONå“åº”
                test_case_json = self._extract_json_from_response(content)

                # æ„å»ºturnç»“æ„
                turn = {
                    "turn_id": turn_number,
                    "user_input": test_case_json["conversation"]["turns"][0]["user_input"],
                    "context": {
                        "requires_context": False,
                        "depends_on": []
                    },
                    "expected_behavior": test_case_json["conversation"]["turns"][0]["expected_behavior"]
                }

                # å¦‚æœæ˜¯å›¾ç‰‡ç±»å‹ï¼Œå¼ºåˆ¶å°†contentæ›¿æ¢ä¸ºåŸå§‹è·¯å¾„
                if turn["user_input"].get("type") == "image":
                    turn["user_input"]["content"] = query

                turns.append(turn)

                # å­˜å‚¨è½®æ¬¡çš„é‡è¦ä¿¡æ¯ç”¨äºåç»­ä¸Šä¸‹æ–‡
                self._store_turn_context(turn, previous_turns_context)

            except Exception as e:
                print(f"   âŒ ç¬¬ {turn_number} è½®ç”Ÿæˆå¤±è´¥: {e}")
                # åˆ›å»ºåŸºæœ¬çš„turnç»“æ„
                turn = {
                    "turn_id": turn_number,
                    "user_input": {
                        "type": "text",
                        "content": query
                    },
                    "context": {
                        "requires_context": False,
                        "depends_on": []
                    },
                    "expected_behavior": {
                        "steps": [
                            {
                                "step": 1,
                                "type": "finish",
                                "expected_response": f"æ— æ³•ç”Ÿæˆç¬¬ {turn_number} è½®çš„æµ‹è¯•ç”¨ä¾‹"
                            }
                        ]
                    }
                }
                turns.append(turn)

        # æ„å»ºæœ€ç»ˆæµ‹è¯•ç”¨ä¾‹
        test_case = {
            "id": test_case_id,
            "user_id": unique_user_id,
            "name": f"å¤šè½®å¯¹è¯æµ‹è¯•ç”¨ä¾‹ - {len(turns)} è½®",
            "description": f"å¤šè½®å¯¹è¯æµ‹è¯•ï¼ŒåŒ…å« {len(turns)} ä¸ªè½®æ¬¡çš„äº¤äº’",
            "mode": "multi_turn",
            "conversation": {
                "turns": turns
            },
            "metadata": {
                "conversation_type": "multi_turn",
                "turns": len(turns),
                "context_complexity": "high",
                "required_tools": self._extract_required_tools(turns)
            }
        }

        return test_case

    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼Œä¸“é—¨ä¸ºç§˜ä¹¦Agentç³»ç»Ÿç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚

## ç§˜ä¹¦Agentå®Œæ•´ç³»ç»Ÿä¿¡æ¯

### æ—¥æœŸæ˜ŸæœŸå¯¹ç…§è¡¨ï¼ˆ2025å¹´12æœˆ-2026å¹´2æœˆï¼‰
12æœˆ01æ—¥ = æ˜ŸæœŸä¸€ åˆ° 12æœˆ31æ—¥ = æ˜ŸæœŸä¸‰
1æœˆ01æ—¥ = æ˜ŸæœŸå›› åˆ° 1æœˆ31æ—¥ = æ˜ŸæœŸå…­
2æœˆ01æ—¥ = æ˜ŸæœŸæ—¥ åˆ° 2æœˆ28æ—¥ = æ˜ŸæœŸå…­

### æ—¶é—´è®¡ç®—è§„åˆ™
- æŸ¥æ‰¾æŸä¸€å¤©æ˜¯æ˜ŸæœŸå‡ ï¼šæ ¹æ®ä¸Šé¢çš„æ—¥æœŸèŒƒå›´è®¡ç®—
- "ä¸‹å‘¨"æŒ‡çš„æ˜¯ä»å½“å‰æ—¥æœŸå¼€å§‹é‡åˆ°çš„ç¬¬ä¸€ä¸ªå‘¨ä¸€å¼€å§‹åˆ°å‘¨æ—¥ç»“æŸçš„å®Œæ•´å‘¨

## å¯ç”¨å·¥å…·ï¼ˆç§˜ä¹¦Agentä¼šä½¿ç”¨ï¼‰

### 1. contacts_create - åˆ›å»ºè”ç³»äºº
- å‚æ•°ï¼šname(å¯é€‰), company(å¯é€‰), position(å¯é€‰), phone(å¯é€‰), email(å¯é€‰), address(å¯é€‰), notes(å¯é€‰), relationship_type(å¯é€‰), birthday(å¯é€‰), gender(å¯é€‰), industry(å¯é€‰)
- è¯´æ˜ï¼šæ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥åªæä¾›éƒ¨åˆ†ä¿¡æ¯

### 2. contacts_update - æ›´æ–°è”ç³»äºº
- å‚æ•°ï¼šid(å¿…éœ€), name(å¯é€‰), company(å¯é€‰), position(å¯é€‰), phone(å¯é€‰), email(å¯é€‰), address(å¯é€‰), notes(å¯é€‰), relationship_type(å¯é€‰), birthday(å¯é€‰), gender(å¯é€‰), industry(å¯é€‰)
- è¯´æ˜ï¼šidæ˜¯å¿…éœ€çš„ï¼Œå…¶ä»–å‚æ•°å¯é€‰

### 3. contacts_delete - åˆ é™¤è”ç³»äºº
- å‚æ•°ï¼šid(å¿…éœ€)
- è¯´æ˜ï¼šéœ€è¦æä¾›è”ç³»äººID

### 4. contacts_search - æœç´¢è”ç³»äºº
- å‚æ•°ï¼šcontact_id(å¯é€‰), name(å¯é€‰), company(å¯é€‰), position(å¯é€‰), phone(å¯é€‰), email(å¯é€‰), address(å¯é€‰), context_search(å¯é€‰)
- è¯´æ˜ï¼šæ‰€æœ‰å‚æ•°éƒ½æ˜¯å¯é€‰çš„ï¼Œå¯ä»¥æ¨¡ç³ŠæŸ¥è¯¢

### 5. schedules_create - åˆ›å»ºæ—¥ç¨‹
- å‚æ•°ï¼štitle(å¿…éœ€), description(å¯é€‰), start_time(å¯é€‰), end_time(å¯é€‰), full_day(å¯é€‰), reminder_time(å¯é€‰), location(å¯é€‰), category(å¯é€‰)
- è¯´æ˜ï¼š
  * titleæ˜¯å¿…éœ€çš„
  * start_timeå’Œend_timeå¿…é¡»åŒæ—¶è®¾ç½®ï¼ˆè¦ä¹ˆéƒ½å¡«ï¼Œè¦ä¹ˆéƒ½ä¸å¡«ï¼‰
  * ä¸èƒ½åŒæ—¶è®¾ç½®start_time/end_timeå’Œfull_day
  * descriptionå¿…é¡»åŒ…å«æ—¥ç¨‹çš„å¤§æ¦‚å†…å®¹ã€æ—¥ç¨‹çš„ç›¸å…³äººå‘˜

### 6. schedules_update - æ›´æ–°æ—¥ç¨‹
- å‚æ•°ï¼šid(å¿…éœ€), title(å¯é€‰), description(å¯é€‰), start_time(å¯é€‰), end_time(å¯é€‰), full_day(å¯é€‰), reminder_time(å¯é€‰), location(å¯é€‰), category(å¯é€‰)
- è¯´æ˜ï¼šidæ˜¯å¿…éœ€çš„ï¼Œå…¶ä»–å‚æ•°å¯é€‰

### 7. schedules_delete - åˆ é™¤æ—¥ç¨‹
- å‚æ•°ï¼šid(å¿…éœ€)
- è¯´æ˜ï¼šéœ€è¦æä¾›æ—¥ç¨‹ID

### 8. schedules_search - æœç´¢æ—¥ç¨‹
- å‚æ•°ï¼štitle(å¯é€‰), description(å¯é€‰), start_time(å¯é€‰), end_time(å¯é€‰), location(å¯é€‰), category(å¯é€‰), query(å¯é€‰)
- è¯´æ˜ï¼š
  * è‡³å°‘è¦åŒ…å«ä¸€ä¸ªä»¥ä¸Šçš„å‚æ•°
  * å¦‚æœæœ‰start_timeå‚æ•°å¿…é¡»è®¾ç½®end_timeå‚æ•°
  * end_timeå€¼é»˜è®¤æ˜¯start_timeçš„å½“å¤©çš„æœ€åæ—¶åˆ»
  * ä¼˜å…ˆä½¿ç”¨queryä»¥å¤–çš„å‚æ•°ï¼Œå¦‚æœé€‰æ‹©äº†é™¤queryä»¥å¤–çš„å‚æ•°å°±ä¸è¦å†ä½¿ç”¨queryå‚æ•°äº†


### 9. finish - å®Œæˆä»»åŠ¡å¹¶è¿”å›æœ€ç»ˆç­”æ¡ˆ
- å‚æ•°ï¼šanswer(å¿…éœ€)
- è¯´æ˜ï¼šå½“å·²ç»æœ‰è¶³å¤Ÿä¿¡æ¯å›ç­”é—®é¢˜æ—¶ä½¿ç”¨

## ç§˜ä¹¦Agentè§„åˆ™

### æ ¸å¿ƒè§„åˆ™
1. æ¯æ¬¡è¿­ä»£åªèƒ½é€‰æ‹©ä¸€ä¸ªå·¥å…·
2. å½“è®¤ä¸ºå·²ç»å¯ä»¥å›ç­”é—®é¢˜æ—¶ï¼Œä½¿ç”¨finishå·¥å…·å¹¶æä¾›å®Œæ•´ç­”æ¡ˆ
3. ä¸èƒ½è¿ç»­ä½¿ç”¨åŒä¸€ä¸ªå·¥å…·è¶…è¿‡3æ¬¡
4. å¦‚æœä¸€ä¸ªå·¥å…·è°ƒç”¨å¤±è´¥ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨å…¶ä»–å·¥å…·
5. æ—¶é—´ç›¸å…³æŸ¥è¯¢å¯ä»¥å‚è€ƒæ—¥æœŸæ˜ŸæœŸå¯¹ç…§è¡¨

## æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡

### è¾“å‡ºï¼šå®Œæ•´çš„æµ‹è¯•ç”¨ä¾‹JSON

### åˆ†ææ­¥éª¤
1. **ç†è§£æŸ¥è¯¢æ„å›¾**ï¼šåˆ†æç”¨æˆ·æƒ³è¦å®Œæˆä»€ä¹ˆä»»åŠ¡
2. **é€‰æ‹©åˆé€‚å·¥å…·**ï¼šæ ¹æ®æ„å›¾é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·
3. **ç¡®å®šå·¥å…·è°ƒç”¨**ï¼šæ ¹æ®æ“ä½œç±»å‹é€‰æ‹©åˆé€‚çš„å·¥å…·
4. **æ„å»ºé¢„æœŸè¡Œä¸º**ï¼šè®¾è®¡å®Œæ•´çš„ReActæµç¨‹ï¼ˆæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿï¼‰
5. **å¤„ç†æ—¶é—´ä¿¡æ¯**ï¼šæ­£ç¡®å¤„ç†ç›¸å¯¹æ—¶é—´ï¼ˆå¦‚ä¸‹å‘¨ã€æ˜å¤©ä¸‹åˆç­‰ï¼‰
6. **éµå¾ªè§„åˆ™**ï¼šç¡®ä¿å·¥å…·è°ƒç”¨ç¬¦åˆæ‰€æœ‰çº¦æŸæ¡ä»¶

## æµ‹è¯•ç”¨ä¾‹JSONæ ¼å¼
```json
{
  "id": "TEST_CASE_ID",
  "user_id": "user_18600241181",
  "name": "æµ‹è¯•ç”¨ä¾‹åç§°",
  "description": "æµ‹è¯•ç”¨ä¾‹æè¿°",
  "mode": "single_turn",
  "conversation": {
    "turns": [
      {
        "turn_id": 1,
        "user_input": {
          "type": "text | image | mixed",
          "content": "ç”¨æˆ·è¾“å…¥å†…å®¹"
        },
        "context": {
          "requires_context": false,
          "depends_on": []
        },
        "expected_behavior": {
          "steps": [
            {
              "step": 1,
              "type": "tool_call",
              "tool_name": "å·¥å…·åç§°",
              "parameters": {
                "å‚æ•°": "å€¼"
              }
            },
            {
              "step": 2,
              "type": "tool_result",
              "result": {
                "success": true,
                "data": {
                  "è¿”å›æ•°æ®": "æ¨¡æ‹Ÿçš„çœŸå®è¿”å›æ•°æ®"
                }
              }
            },
            {
              "step": 3,
              "type": "finish",
              "expected_response": "ç”¨æˆ·æœŸæœ›çœ‹åˆ°çš„æœ€ç»ˆå›å¤"
            }
          ]
        }
      }
    ]
  },
  "metadata": {
    "conversation_type": "single_turn",
    "turns": 1,
    "context_complexity": "low | medium | high",
    "required_tools": ["å·¥å…·1", "å·¥å…·2"]
  }
}
```

## è¾“å‡ºè¦æ±‚
- ä¸¥æ ¼åˆ†ææŸ¥è¯¢çš„æ„å›¾ï¼Œæ­£ç¡®é€‰æ‹©å·¥å…·
- å‡†ç¡®æå–æŸ¥è¯¢ä¸­çš„å®ä½“ä¿¡æ¯ï¼ˆå§“åã€ç”Ÿæ—¥ã€ç”µè¯ç­‰ï¼‰
- ğŸš¨ é‡è¦çº¦æŸï¼šåªèƒ½ä½¿ç”¨ç”¨æˆ·æ˜ç¡®æåˆ°çš„ä¿¡æ¯ï¼Œä¸èƒ½ç¼–é€ è™šå‡æ•°æ®
- ğŸš¨ å¦‚æœå·¥å…·è¿”å›çš„æ•°æ®åŒ…å«ç”¨æˆ·æœªæåˆ°çš„å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨nullæˆ–ç©ºå€¼
- æ ¹æ®ç§˜ä¹¦Agentçš„ReActæ¨¡å¼è®¾è®¡åˆç†çš„æ­¥éª¤æµç¨‹
- æ¯ä¸¤ä¸ªstepæ˜¯ä¸€ä¸ªå·¥å…·è°ƒç”¨çš„è¿‡ç¨‹åŒ…æ‹¬è¾“å…¥å‚æ•°ä»¥åŠå·¥å…·æ‰§è¡Œçš„ç»“æœ finishå·¥å…·åªæœ‰ä¸€ä¸ªstep
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå­—æ®µå®Œæ•´
- æè¿°è¦ç®€æ´æ˜äº†
- åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ€§æ–‡å­—
- ä¸è¦ä½¿ç”¨markdownä»£ç å—æ ‡è®°
- ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
- è¾“å‡ºå·¥å…·è¿”å›æ•°æ®è¦æ¨¡æ‹Ÿ ä¸èƒ½ç›´æ¥è¿”å›ä¸€å¥è¯
- æ¯æ¡æµ‹è¯•éƒ½æ˜¯ç‹¬ç«‹çš„æ•°æ® ä¸éœ€è¦æœ‰ä»»ä½•ä¾èµ–
- ğŸš¨ ä¸¥æ ¼ç¦æ­¢ï¼šä¸è¦åœ¨å·¥å…·è¿”å›æ•°æ®ä¸­ç¼–é€ ä»»ä½•ç”¨æˆ·æœªæåŠçš„ä¿¡æ¯
"""

    def _extract_json_from_response(self, response: str) -> Dict:
        """ä»GPTå“åº”ä¸­æå–JSON"""
        import re

        # å°è¯•ç›´æ¥è§£æJSON
        try:
            return json.loads(response)
        except:
            pass

        # å°è¯•ä»ä»£ç å—ä¸­æå–JSON
        json_pattern = r'```json\s*(\{.*?\})\s*```'
        match = re.search(json_pattern, response, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except:
                pass

        # å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        match = re.search(json_pattern, response, re.DOTALL)
        if match:
            try:
                return json.loads(match.group())
            except:
                pass

        # å¦‚æœéƒ½æ— æ³•è§£æï¼Œè¿”å›é»˜è®¤ç»“æ„
        print(f"   âš ï¸  æ— æ³•è§£æJSONï¼Œä½¿ç”¨é»˜è®¤ç»“æ„")
        return {
            "conversation": {
                "turns": [{
                    "user_input": {
                        "type": "text",
                        "content": "æ— æ³•è§£æçš„å†…å®¹"
                    },
                    "expected_behavior": {
                        "steps": [{
                            "step": 1,
                            "type": "finish",
                            "expected_response": "æ— æ³•è§£æå“åº”"
                        }]
                    }
                }]
            }
        }

    def _extract_required_tools(self, turns: List[Dict]) -> List[str]:
        """æå–æ‰€æœ‰éœ€è¦çš„å·¥å…·"""
        tools = set()
        for turn in turns:
            steps = turn.get("expected_behavior", {}).get("steps", [])
            for step in steps:
                if step.get("type") == "tool_call":
                    tool_name = step.get("tool_name")
                    if tool_name and tool_name != "finish":
                        tools.add(tool_name)
        return list(tools)


async def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='å¤šè½®Excelæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨')
    parser.add_argument('--count', type=int, help='æµ‹è¯•æŒ‡å®šæ•°é‡çš„æ•°æ®ï¼ˆä¾‹å¦‚ï¼š--count 2ï¼‰')
    parser.add_argument('--all', action='store_true', help='æµ‹è¯•æ‰€æœ‰æ•°æ®')
    parser.add_argument('--excel', required=True, help='Excelæ–‡ä»¶è·¯å¾„ï¼ˆä¾‹å¦‚ï¼šå¤šè½®.xlsxï¼‰')
    parser.add_argument('--output', default='multi_turn_test_cases.json', help='è¾“å‡ºJSONæ–‡ä»¶åï¼ˆé»˜è®¤ï¼šmulti_turn_test_cases.jsonï¼‰')
    args = parser.parse_args()

    if not args.count and not args.all:
        print("é”™è¯¯ï¼šå¿…é¡»æŒ‡å®š --count æˆ– --all å‚æ•°")
        return

    print("=" * 80)
    print("å¤šè½®Excelæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨")
    print("=" * 80)
    print("ç‰¹æ€§ï¼š")
    print("  âœ“ æ”¯æŒå¤šè½®å¯¹è¯æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ")
    print("  âœ“ æ¯è¡Œä¸€æ¡æµ‹è¯•æ•°æ®ï¼Œæ¯åˆ—ä¸€ä¸ªè½®æ¬¡")
    print("  âœ“ æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è‡ªåŠ¨å¤„ç†")
    print("  âœ“ åŠ¨æ€æ—¶é—´æˆ³")
    print("=" * 80)
    print()

    generator = MultiTurnTestCaseGenerator()

    # åˆå§‹åŒ–
    print("æ­£åœ¨åˆå§‹åŒ–GPT-4.1...")
    await generator.initialize()
    print("åˆå§‹åŒ–å®Œæˆï¼\n")

    # è¯»å–Excel
    excel_path = args.excel
    print(f"ğŸ“– è¯»å–Excelæ–‡ä»¶: {excel_path}")
    df = pd.read_excel(excel_path)
    print(f"   æ€»è¡Œæ•°: {len(df)}")
    print(f"   åˆ—å: {df.columns.tolist()}\n")

    # ç¡®å®šè¦å¤„ç†çš„æ•°æ®èŒƒå›´
    if args.all:
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹ (å…¨éƒ¨æ•°æ®)")
        start_idx = 0
        end_idx = len(df)
        total_count = end_idx - start_idx
    else:
        count = args.count
        print(f"ğŸš€ å¼€å§‹ç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹ (æŒ‡å®šæ•°é‡: {count})")
        start_idx = 0
        end_idx = min(count, len(df))
        total_count = count

    print("=" * 80)

    all_test_cases = []
    successful = 0
    failed = 0

    # å¤„ç†æ•°æ®
    for idx in range(start_idx, end_idx):
        try:
            # è·å–ä¸€è¡Œæ•°æ®ï¼ˆåŒ…å«å¤šä¸ªè½®æ¬¡ï¼‰
            row_data = df.iloc[idx].to_dict()

            test_case_id = f"MULTI_TURN_{idx:03d}"

            print(f"\n[è¿›åº¦] {idx - start_idx + 1}/{total_count}")
            print(f"   æµ‹è¯•ç”¨ä¾‹ID: {test_case_id}")
            print(f"   User IDå°†ä½¿ç”¨: {generator._generate_unique_user_id()[:30]}...")

            # è®¡ç®—è½®æ¬¡æ•°é‡
            turn_count = len([v for v in row_data.values() if pd.notna(v) and str(v).strip()])
            print(f"   è½®æ¬¡æ•°é‡: {turn_count}")

            test_case = await generator.generate_multi_turn_test_case(row_data, test_case_id)

            # æ·»åŠ åˆ°æ•°ç»„
            all_test_cases.append(test_case)

            print(f"âœ… æˆåŠŸç”Ÿæˆå¤šè½®æµ‹è¯•ç”¨ä¾‹")
            print(f"   å®é™…User ID: {test_case['user_id']}")
            print(f"   è½®æ¬¡æ•°é‡: {test_case['metadata']['turns']}")
            successful += 1

        except Exception as e:
            print(f"âŒ å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            failed += 1

    # ä¿å­˜åˆ°JSONæ–‡ä»¶
    output_file = args.output
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_test_cases, f, ensure_ascii=False, indent=2)

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š å¤šè½®æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ")
    print("=" * 80)
    print(f"âœ… æˆåŠŸ: {successful} ä¸ª")
    print(f"âŒ å¤±è´¥: {failed} ä¸ª")
    print(f"ğŸ“ æ€»è®¡: {successful + failed} ä¸ª")
    print(f"\nğŸ“„ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“Š JSONç»“æ„: æ•°ç»„åŒ…å« {len(all_test_cases)} ä¸ªå¤šè½®æµ‹è¯•ç”¨ä¾‹")
    print("\nğŸ“ ç‰¹ç‚¹:")
    print(f"   â€¢ æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹éƒ½æœ‰å”¯ä¸€çš„user_id")
    print(f"   â€¢ æ”¯æŒå¤šè½®å¯¹è¯")
    print(f"   â€¢ æœ¬åœ°å›¾ç‰‡æ–‡ä»¶è‡ªåŠ¨å¤„ç†")
    print(f"   â€¢ åŠ¨æ€æ—¶é—´æˆ³")
    print(f"\nğŸ”§ ä½¿ç”¨æ–¹å¼:")
    print(f"   â€¢ æµ‹è¯•å‰2æ¡: python generate_multi_turn.py --count 2 --excel {args.excel}")
    print(f"   â€¢ æµ‹è¯•æ‰€æœ‰æ•°æ®: python generate_multi_turn.py --all --excel {args.excel}")


if __name__ == "__main__":
    asyncio.run(main())
