#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–è¯„ä¼°æµæ°´çº¿ä¸»æ§è„šæœ¬

ä¸€é”®è‡ªåŠ¨åŒ–è¯„ä¼°æµç¨‹ï¼Œæ— éœ€æ‰‹åŠ¨ä¿®æ”¹æ–‡ä»¶æˆ–æŒ‡å®šæ–‡ä»¶åã€‚
æ™ºèƒ½æ–‡ä»¶è¯†åˆ«æœºåˆ¶ä¼šè‡ªåŠ¨æ‰¾åˆ°ä¸Šä¸€æ­¥ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶ä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ã€‚

Usage:
    python run_evaluation_pipeline.py
    python run_evaluation_pipeline.py --limit 5
    python run_evaluation_pipeline.py --dry-run
    python run_evaluation_pipeline.py --step 1
"""

import os
import sys
import json
import time
import argparse
import subprocess
from datetime import datetime
from pathlib import Path


class EvaluationPipeline:
    """è¯„ä¼°æµæ°´çº¿ä¸»æ§ç±»"""

    def __init__(self, work_dir=None, timestamp=None):
        # é»˜è®¤ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•
        self.work_dir = Path(work_dir) if work_dir else Path(__file__).parent
        self.timestamp = timestamp or datetime.now().strftime('%Y%m%d_%H%M%S')
        # ç»Ÿä¸€å°†ç»“æœå’Œæ—¥å¿—ä¿å­˜åœ¨ pipline_results ç›®å½•ä¸‹
        self.pipeline_root_dir = self.work_dir / "pipline_results"
        self.run_dir = self.pipeline_root_dir / f"runs_{self.timestamp}"
        self.log_dir = self.run_dir / "logs"
        self.log_file = self.log_dir / f"pipeline_{self.timestamp}.log"

        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        self.pipeline_root_dir.mkdir(exist_ok=True)
        self.run_dir.mkdir(exist_ok=True)
        self.log_dir.mkdir(exist_ok=True)

    def log(self, message, level="INFO"):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_msg = f"[{timestamp}] [{level}] {message}\n"
        print(message)
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_msg)

    def run_command(self, command, dry_run=False):
        """æ‰§è¡Œå‘½ä»¤"""
        self.log(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {command}")

        if dry_run:
            self.log("âš ï¸  è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸æ‰§è¡Œå‘½ä»¤")
            return True

        try:
            # å¯¹äºPythonå‘½ä»¤ï¼Œæ·»åŠ  -u å‚æ•°å¼ºåˆ¶éç¼“å†²è¾“å‡º
            if command.strip().startswith('python '):
                command = command.replace('python ', 'python -u ', 1)

            # ä½¿ç”¨ Popen å®ç°å®æ—¶è¾“å‡º
            process = subprocess.Popen(
                command,
                shell=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                cwd=self.work_dir,
                bufsize=1,
                universal_newlines=True
            )

            # å®æ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
            for line in process.stdout:
                print(line.rstrip(), flush=True)  # å¼ºåˆ¶åˆ·æ–°è¾“å‡º

            # ç­‰å¾…è¿›ç¨‹å®Œæˆ
            process.wait()

            if process.returncode == 0:
                self.log(f"âœ… å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
                return True
            else:
                self.log(f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}", "ERROR")
                return False
        except Exception as e:
            self.log(f"âŒ å‘½ä»¤æ‰§è¡Œå¼‚å¸¸: {str(e)}", "ERROR")
            return False

    def find_latest_file(self, pattern, exclude_timestamp=None):
        """æŸ¥æ‰¾æœ€æ–°åŒ¹é…çš„æ–‡ä»¶"""
        files = list(self.work_dir.glob(pattern))

        if exclude_timestamp:
            files = [f for f in files if exclude_timestamp not in f.name]

        if not files:
            return None

        files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
        return files[0]

    def get_input_file_for_step(self, step, exclude_timestamp=None):
        """è·å–æ­¥éª¤çš„è¾“å…¥æ–‡ä»¶"""
        if step == 2:
            # æ­¥éª¤2éœ€è¦æ­¥éª¤1çš„è¾“å‡º
            pattern = "test_results_all_44_*.json"
        elif step == 3:
            # æ­¥éª¤3éœ€è¦æ­¥éª¤2çš„è¾“å‡º
            pattern = "test_results_merged_*.json"
        else:
            return None

        file = self.find_latest_file(pattern, exclude_timestamp)
        if file:
            self.log(f"ğŸ“¥ è‡ªåŠ¨å‘ç°è¾“å…¥æ–‡ä»¶: {file}")
        return file

    def step1_run_tests(self, limit=None, dry_run=False):
        """æ­¥éª¤1: è¿è¡Œæµ‹è¯•ç”¨ä¾‹"""
        self.log("\n" + "="*80)
        self.log("ğŸ“Œ å¼€å§‹æ‰§è¡Œ: è¿è¡Œæµ‹è¯•")
        self.log("ğŸ”„ æ­¥éª¤1: è¿è¡Œæµ‹è¯•ç”¨ä¾‹")
        self.log("="*80)

        output_file = self.run_dir / f"test_results_all_44_{self.timestamp}.json"

        # æ„å»ºå‘½ä»¤
        cmd_parts = [
            "python", "test_all_cases.py",
            "--output", str(output_file),
            "--timestamp", self.timestamp
        ]

        if limit:
            cmd_parts.extend(["--limit", str(limit)])

        command = " ".join(cmd_parts)

        self.log(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        self.log(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {command}")

        success = self.run_command(command, dry_run)

        if not dry_run and success and output_file.exists():
            self.log(f"âœ… æµ‹è¯•å®Œæˆ: {output_file}")
            return str(output_file)
        elif dry_run:
            self.log(f"âœ… æµ‹è¯•å‘½ä»¤å·²å‡†å¤‡: {output_file}")
            return str(output_file)
        else:
            self.log(f"âŒ æµ‹è¯•å¤±è´¥", "ERROR")
            return None

    def step2_merge_stream_data(self, input_file, dry_run=False):
        """æ­¥éª¤2: åˆå¹¶æµå¼æ•°æ®"""
        self.log("\n" + "="*80)
        self.log("ğŸ“Œ å¼€å§‹æ‰§è¡Œ: åˆå¹¶æµå¼æ•°æ®")
        self.log("ğŸ”„ æ­¥éª¤2: åˆå¹¶æµå¼æ•°æ®")
        self.log("="*80)

        output_file = self.run_dir / f"test_results_merged_{self.timestamp}.json"

        command = f"python convert_stream_data.py --input {input_file} --output {output_file}"

        self.log(f"ğŸ“¥ è¾“å…¥æ–‡ä»¶: {input_file}")
        self.log(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        self.log(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {command}")

        success = self.run_command(command, dry_run)

        if not dry_run and success and output_file.exists():
            self.log(f"âœ… åˆå¹¶å®Œæˆ: {output_file}")
            return str(output_file)
        elif dry_run:
            self.log(f"âœ… åˆå¹¶å‘½ä»¤å·²å‡†å¤‡: {output_file}")
            return str(output_file)
        else:
            self.log(f"âŒ åˆå¹¶å¤±è´¥", "ERROR")
            return None

    def step3_validate_results(self, input_file, dry_run=False):
        """æ­¥éª¤3: éªŒè¯æµ‹è¯•ç»“æœ"""
        self.log("\n" + "="*80)
        self.log("ğŸ“Œ å¼€å§‹æ‰§è¡Œ: éªŒè¯ç»“æœ")
        self.log("ğŸ”„ æ­¥éª¤3: éªŒè¯æµ‹è¯•ç»“æœ")
        self.log("="*80)

        output_file = self.run_dir / f"validation_report_{self.timestamp}.json"

        command = f"python validate_test_gemini_results.py --input {input_file} --output {output_file}"

        self.log(f"ğŸ“¥ è¾“å…¥æ–‡ä»¶: {input_file}")
        self.log(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        self.log(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {command}")

        success = self.run_command(command, dry_run)

        if not dry_run and success and output_file.exists():
            self.log(f"âœ… éªŒè¯å®Œæˆ: {output_file}")
            return str(output_file)
        elif dry_run:
            self.log(f"âœ… éªŒè¯å‘½ä»¤å·²å‡†å¤‡: {output_file}")
            return str(output_file)
        else:
            self.log(f"âŒ éªŒè¯å¤±è´¥", "ERROR")
            return None

    def generate_summary_report(self, step_results, dry_run=False):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        self.log("\n" + "="*80)
        self.log("ğŸ“Š ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š")
        self.log("="*80)

        summary_file = self.run_dir / f"pipeline_summary_{self.timestamp}.json"

        summary = {
            "timestamp": self.timestamp,
            "pipeline_status": "completed" if all(step_results.values()) else "partial",
            "steps": {
                "step1_run_tests": {
                    "status": "completed" if step_results.get(1) else "failed",
                    "output_file": step_results.get(1, "N/A")
                },
                "step2_merge_stream_data": {
                    "status": "completed" if step_results.get(2) else "failed",
                    "input_file": step_results.get(1, "N/A"),
                    "output_file": step_results.get(2, "N/A")
                },
                "step3_validate_results": {
                    "status": "completed" if step_results.get(3) else "failed",
                    "input_file": step_results.get(2, "N/A"),
                    "output_file": step_results.get(3, "N/A")
                }
            },
            "output_directory": str(self.run_dir),
            "summary": {
                "raw_response": step_results.get(1, "N/A"),
                "merged_response": step_results.get(2, "N/A"),
                "validation_report": step_results.get(3, "N/A")
            },
            "statistics": self._calculate_statistics(step_results)
        }

        if not dry_run:
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            self.log(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {summary_file}")
        else:
            self.log(f"âœ… æ±‡æ€»æŠ¥å‘Šå·²å‡†å¤‡: {summary_file}")

        return str(summary_file)

    def _calculate_statistics(self, step_results):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "success_rate": 0.0,
            "completed_steps": 0,
            "total_steps": 3
        }

        completed = sum(1 for v in step_results.values() if v)
        stats["completed_steps"] = completed
        stats["success_rate"] = (completed / stats["total_steps"]) * 100

        return stats

    def print_banner(self, limit=None, step=None, dry_run=False):
        """æ‰“å°å¯åŠ¨æ¨ªå¹…"""
        self.log("\n" + "="*80)
        self.log("ğŸš€ è‡ªåŠ¨åŒ–è¯„ä¼°æµæ°´çº¿å¯åŠ¨")
        self.log("="*80)
        self.log(f"â° æ—¶é—´æˆ³: {self.timestamp}")
        self.log(f"ğŸ“ å·¥ä½œç›®å½•: {self.work_dir}")
        self.log(f"ğŸ“ æµæ°´çº¿æ ¹ç›®å½•: {self.pipeline_root_dir}")
        self.log(f"ğŸ“ è¾“å‡ºç›®å½•: {self.run_dir}")
        self.log(f"ğŸ“ æ—¥å¿—ç›®å½•: {self.log_dir}")
        if limit:
            self.log(f"ğŸ”¢ é™åˆ¶æµ‹è¯•æ•°é‡: {limit}")
        if step:
            self.log(f"ğŸ¯ æ‰§è¡Œæ­¥éª¤: {step}")
        if dry_run:
            self.log(f"ğŸ” è¯•è¿è¡Œæ¨¡å¼: å¯ç”¨")
        self.log("="*80)

    def print_completion(self, step_results):
        """æ‰“å°å®Œæˆä¿¡æ¯"""
        self.log("\n" + "="*80)
        self.log("ğŸ‰ æµæ°´çº¿æ‰§è¡Œå®Œæˆ!")
        self.log("="*80)
        self.log(f"â° æ—¶é—´æˆ³: {self.timestamp}")
        self.log(f"ğŸ“ æµæ°´çº¿æ ¹ç›®å½•: {self.pipeline_root_dir}")
        self.log(f"ğŸ“ è¾“å‡ºç›®å½•: {self.run_dir}")
        self.log(f"ğŸ“ æ—¥å¿—ç›®å½•: {self.log_dir}")
        self.log("ğŸ“„ ç”Ÿæˆæ–‡ä»¶:")

        for key, value in step_results.items():
            if value:
                if key == 1:
                    self.log(f"   - raw_response: {Path(value).name}")
                elif key == 2:
                    self.log(f"   - merged_response: {Path(value).name}")
                elif key == 3:
                    self.log(f"   - validation_report: {Path(value).name}")

        stats = self._calculate_statistics(step_results)
        self.log(f"ğŸ“Š æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        self.log("="*80)

    def run_full_pipeline(self, limit=None, dry_run=False):
        """è¿è¡Œå®Œæ•´æµæ°´çº¿"""
        step_results = {}

        # æ­¥éª¤1: è¿è¡Œæµ‹è¯•
        result1 = self.step1_run_tests(limit, dry_run)
        step_results[1] = result1

        # æ­¥éª¤2: åˆå¹¶æµå¼æ•°æ®
        if step_results[1] or dry_run:
            result2 = self.step2_merge_stream_data(step_results[1] or "dry_run_input.json", dry_run)
            step_results[2] = result2

            # æ­¥éª¤3: éªŒè¯ç»“æœ
            if step_results[2] or dry_run:
                result3 = self.step3_validate_results(step_results[2] or "dry_run_input.json", dry_run)
                step_results[3] = result3

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(step_results, dry_run)

        # æ‰“å°å®Œæˆä¿¡æ¯
        if not dry_run:
            self.print_completion(step_results)

        return all(step_results.values())


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è‡ªåŠ¨åŒ–è¯„ä¼°æµæ°´çº¿')
    parser.add_argument('--work-dir', type=str, default=None,
                      help='å·¥ä½œç›®å½• (é»˜è®¤: è„šæœ¬æ‰€åœ¨ç›®å½•)')
    parser.add_argument('--limit', type=int, help='é™åˆ¶æµ‹è¯•ç”¨ä¾‹æ•°é‡')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼ï¼ˆæ˜¾ç¤ºå°†è¦æ‰§è¡Œçš„å‘½ä»¤ä½†ä¸å®é™…æ‰§è¡Œï¼‰')
    parser.add_argument('--step', type=int, choices=[1, 2, 3], help='åªæ‰§è¡Œç‰¹å®šæ­¥éª¤')
    parser.add_argument('--timestamp', type=str, help='æŒ‡å®šæ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰')

    args = parser.parse_args()

    # åˆ›å»ºæµæ°´çº¿å®ä¾‹
    pipeline = EvaluationPipeline(work_dir=args.work_dir, timestamp=args.timestamp)

    # æ‰“å°å¯åŠ¨æ¨ªå¹…
    pipeline.print_banner(limit=args.limit, step=args.step, dry_run=args.dry_run)

    # æ‰§è¡Œæµæ°´çº¿
    if args.step:
        # å•æ­¥æ‰§è¡Œ
        if args.step == 1:
            result = pipeline.step1_run_tests(limit=args.limit, dry_run=args.dry_run)
        elif args.step == 2:
            # éœ€è¦æ­¥éª¤1çš„è¾“å‡ºæ–‡ä»¶
            input_file = pipeline.get_input_file_for_step(2, exclude_timestamp=pipeline.timestamp)
            if not input_file and not args.dry_run:
                pipeline.log("âŒ æ‰¾ä¸åˆ°æ­¥éª¤1çš„è¾“å‡ºæ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œæ­¥éª¤1", "ERROR")
                sys.exit(1)
            input_file = input_file or "dry_run_input.json"
            result = pipeline.step2_merge_stream_data(input_file, dry_run=args.dry_run)
        elif args.step == 3:
            # éœ€è¦æ­¥éª¤2çš„è¾“å‡ºæ–‡ä»¶
            input_file = pipeline.get_input_file_for_step(3, exclude_timestamp=pipeline.timestamp)
            if not input_file and not args.dry_run:
                pipeline.log("âŒ æ‰¾ä¸åˆ°æ­¥éª¤2çš„è¾“å‡ºæ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œæ­¥éª¤2", "ERROR")
                sys.exit(1)
            input_file = input_file or "dry_run_input.json"
            result = pipeline.step3_validate_results(input_file, dry_run=args.dry_run)

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        step_results = {args.step: result}
        pipeline.generate_summary_report(step_results, dry_run=args.dry_run)

        if not args.dry_run and result:
            pipeline.log(f"âœ… æ­¥éª¤{args.step}æ‰§è¡Œå®Œæˆ")
            sys.exit(0)
        elif args.dry_run:
            pipeline.log(f"âœ… æ­¥éª¤{args.step}å‘½ä»¤å·²å‡†å¤‡")
            sys.exit(0)
        else:
            pipeline.log(f"âŒ æ­¥éª¤{args.step}æ‰§è¡Œå¤±è´¥", "ERROR")
            sys.exit(1)
    else:
        # æ‰§è¡Œå®Œæ•´æµæ°´çº¿
        success = pipeline.run_full_pipeline(limit=args.limit, dry_run=args.dry_run)

        if not args.dry_run:
            sys.exit(0 if success else 1)
        else:
            sys.exit(0)


if __name__ == "__main__":
    main()
