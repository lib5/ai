#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Geminiæ¨¡å‹å¿«é€Ÿæµ‹è¯•è„šæœ¬
æµ‹è¯•ä¸€ä¸ªæ–‡æœ¬promptå’Œä¸€ä¸ªå›¾ç‰‡promptï¼Œè¾“å‡ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
"""

import os
import sys
import json
import asyncio
import time
import statistics
import numpy as np
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from config import settings
from speed_tests.gemini.adapter import GeminiTester


def load_test_prompts(file_path: str):
    """åŠ è½½æµ‹è¯•prompts - ä¸€ä¸ªæ–‡æœ¬ä¸€ä¸ªå›¾ç‰‡"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    prompts = data['prompts']
    text_prompts = [p for p in prompts if p.get('type') == 'text']
    image_prompts = [p for p in prompts if p.get('type') == 'image']

    selected = []
    if text_prompts:
        selected.append(text_prompts[0])
    if image_prompts:
        selected.append(image_prompts[0])

    return selected


def extract_question(prompt: dict) -> str:
    """æå–é—®é¢˜å†…å®¹"""
    prompt_type = prompt.get('type', 'text')
    query = prompt.get('query', '')

    if prompt_type == 'image':
        # å›¾ç‰‡ç±»å‹ï¼Œæ˜¾ç¤ºå›¾ç‰‡URLæˆ–æ ‡è®°
        image_urls = prompt.get('image_urls', [])
        if image_urls:
            return f"[å›¾ç‰‡] {query}" if query else f"[å›¾ç‰‡: {len(image_urls)}å¼ ]"
        return f"[å›¾ç‰‡] {query}"
    else:
        return query if query else "[æ–‡æœ¬]"


def parse_complete_prompt(complete_prompt) -> list:
    """
    è§£æcomplete_promptä¸ºæ¶ˆæ¯åˆ—è¡¨
    å¤„ç†ä¸¤ç§æ ¼å¼ï¼šJSONå­—ç¬¦ä¸² æˆ– ç›´æ¥çš„list
    """
    # å¦‚æœå·²ç»æ˜¯listï¼Œç›´æ¥ä½¿ç”¨
    if isinstance(complete_prompt, list):
        messages = complete_prompt
    else:
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè§£æJSON
        messages = json.loads(complete_prompt)

    # è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸ºGemini APIå…¼å®¹æ ¼å¼
    converted_messages = []
    for msg in messages:
        role = msg.get('role', 'user')
        content = msg.get('content', '')

        if isinstance(content, list):
            # å¤„ç†å¤åˆå†…å®¹ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰
            new_content = []
            for item in content:
                item_type = item.get('type', '')
                if item_type == 'input_text' or item_type == 'text':
                    new_content.append({
                        "type": "text",
                        "text": item.get('text', '')
                    })
                elif item_type == 'input_image' or item_type == 'image_url':
                    # Gemini APIå›¾ç‰‡æ ¼å¼
                    image_url = item.get('image_url', '')
                    if isinstance(image_url, dict):
                        image_url = image_url.get('url', '')
                    new_content.append({
                        "type": "image_url",
                        "image_url": {"url": image_url}
                    })

            if new_content:
                converted_messages.append({"role": role, "content": new_content})
        else:
            # æ™®é€šæ–‡æœ¬å†…å®¹
            converted_messages.append({"role": role, "content": content})

    return converted_messages


def print_detailed_stats(results: list):
    """æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
    successful = [r for r in results if r.get('success', False)]

    if not successful:
        print("\nâŒ æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ")
        return

    print("\n" + "=" * 70)
    print("ğŸ“Š è¯¦ç»†æµ‹è¯•ç»“æœ")
    print("=" * 70)

    # æ‰“å°æ¯ä¸ªæµ‹è¯•çš„è¯¦ç»†ä¿¡æ¯
    for i, r in enumerate(results, 1):
        print(f"\n--- æµ‹è¯• {i} ---")
        print(f"  ç±»å‹: {r['type']}")
        print(f"  é—®é¢˜: {r['question'][:60]}..." if len(r['question']) > 60 else f"  é—®é¢˜: {r['question']}")
        if r['success']:
            print(f"  âœ… å“åº”æ—¶é—´: {r['response_time_ms']:.2f} ms")
            print(f"  è¾“å‡ºToken: {r['output_tokens']}")
            print(f"  Tokené€Ÿåº¦: {r['tokens_per_second']:.2f} tokens/s")
            print(f"  å“åº”é¢„è§ˆ: {r['response_preview']}")
        else:
            print(f"  âŒ é”™è¯¯: {r['error']}")

    # åˆ†ç±»ç»Ÿè®¡
    text_results = [r for r in successful if r.get('type') == 'text']
    image_results = [r for r in successful if r.get('type') == 'image']

    print("\n" + "=" * 70)
    print("ğŸ“ˆ åˆ†ç±»ç»Ÿè®¡")
    print("=" * 70)

    def calc_stats(values, name, unit=""):
        print(f"\n{name}:")
        print(f"  å‡å€¼: {statistics.mean(values):.2f}{unit}")
        print(f"  ä¸­ä½æ•°: {statistics.median(values):.2f}{unit}")
        print(f"  æœ€å°å€¼: {min(values):.2f}{unit}")
        print(f"  æœ€å¤§å€¼: {max(values):.2f}{unit}")
        if len(values) >= 5:
            print(f"  P80: {np.percentile(values, 80):.2f}{unit}")
            print(f"  P90: {np.percentile(values, 90):.2f}{unit}")
            print(f"  P99: {np.percentile(values, 99):.2f}{unit}")

    # æ–‡æœ¬ç±»å‹ç»Ÿè®¡
    if text_results:
        text_times = [r['response_time_ms'] for r in text_results]
        text_tokens = [r['output_tokens'] for r in text_results]
        text_speed = [r['tokens_per_second'] for r in text_results]

        print("\nğŸ“ æ–‡æœ¬ç±»å‹ (æ— å›¾ç‰‡):")
        calc_stats(text_times, "  å“åº”æ—¶é—´", " ms")
        calc_stats(text_tokens, "  è¾“å‡ºTokenæ•°")
        calc_stats(text_speed, "  Tokenç”Ÿæˆé€Ÿåº¦", " tokens/s")
        print(f"  æµ‹è¯•æ•°é‡: {len(text_results)}")

    # å›¾ç‰‡ç±»å‹ç»Ÿè®¡
    if image_results:
        image_times = [r['response_time_ms'] for r in image_results]
        image_tokens = [r['output_tokens'] for r in image_results]
        image_speed = [r['tokens_per_second'] for r in image_results]

        print("\nğŸ“¸ å›¾ç‰‡ç±»å‹ (æœ‰å›¾ç‰‡):")
        calc_stats(image_times, "  å“åº”æ—¶é—´", " ms")
        calc_stats(image_tokens, "  è¾“å‡ºTokenæ•°")
        calc_stats(image_speed, "  Tokenç”Ÿæˆé€Ÿåº¦", " tokens/s")
        print(f"  æµ‹è¯•æ•°é‡: {len(image_results)}")

    # å›¾ç‰‡ vs æ–‡æœ¬å¯¹æ¯”
    if text_results and image_results:
        text_avg_time = statistics.mean([r['response_time_ms'] for r in text_results])
        image_avg_time = statistics.mean([r['response_time_ms'] for r in image_results])
        text_avg_speed = statistics.mean([r['tokens_per_second'] for r in text_results])
        image_avg_speed = statistics.mean([r['tokens_per_second'] for r in image_results])

        time_diff = ((image_avg_time - text_avg_time) / text_avg_time) * 100
        speed_diff = ((text_avg_speed - image_avg_speed) / image_avg_speed) * 100

        print("\n" + "=" * 70)
        print("ğŸ“Š å›¾ç‰‡ vs æ–‡æœ¬é€Ÿåº¦å¯¹æ¯”")
        print("=" * 70)
        print(f"\nâ±ï¸ å“åº”æ—¶é—´:")
        print(f"  æ–‡æœ¬å¹³å‡: {text_avg_time:.2f} ms")
        print(f"  å›¾ç‰‡å¹³å‡: {image_avg_time:.2f} ms")
        print(f"  å›¾ç‰‡æ¯”æ–‡æœ¬æ…¢: {time_diff:.1f}%")

        print(f"\nğŸš€ Tokenç”Ÿæˆé€Ÿåº¦:")
        print(f"  æ–‡æœ¬å¹³å‡: {text_avg_speed:.2f} tokens/s")
        print(f"  å›¾ç‰‡å¹³å‡: {image_avg_speed:.2f} tokens/s")
        if image_avg_speed > 0:
            print(f"  æ–‡æœ¬æ¯”å›¾ç‰‡å¿«: {speed_diff:.1f}%")
        else:
            print(f"  æ— æ³•è®¡ç®—é€Ÿåº¦å·®å¼‚")

    # æ•´ä½“ç»Ÿè®¡ï¼ˆå½“æµ‹è¯•æ•°é‡è¶…è¿‡2æ—¶ï¼‰
    if len(successful) >= 2:
        print("\n" + "=" * 70)
        print("ğŸ“ˆ æ•´ä½“ç»Ÿè®¡æ±‡æ€»")
        print("=" * 70)

        response_times = [r['response_time_ms'] for r in successful]
        output_tokens = [r['output_tokens'] for r in successful]
        tokens_per_second = [r['tokens_per_second'] for r in successful]

        calc_stats(response_times, "â±ï¸  å“åº”æ—¶é—´", " ms")
        calc_stats(output_tokens, "ğŸ“ è¾“å‡ºTokenæ•°")
        calc_stats(tokens_per_second, "ğŸš€ Tokenç”Ÿæˆé€Ÿåº¦", " tokens/s")


async def run_single_test(tester: GeminiTester, prompt: dict) -> dict:
    """è¿è¡Œå•ä¸ªæµ‹è¯•"""
    prompt_type = prompt.get('type', 'text')
    question = extract_question(prompt)

    print(f"\nğŸ”„ æµ‹è¯•ä¸­: [{prompt_type}] {question[:50]}...")

    start_time = time.time()

    try:
        # ä½¿ç”¨æœ¬åœ°çš„parse_complete_promptå‡½æ•°
        messages = parse_complete_prompt(prompt['complete_prompt'])

        # å‘é€è¯·æ±‚
        response = await tester.chat_completion(messages)

        end_time = time.time()
        response_time_ms = (end_time - start_time) * 1000

        # æå–å“åº”å†…å®¹
        content = tester.extract_content(response)
        output_tokens = tester.estimate_tokens(content)
        tokens_per_second = (output_tokens / response_time_ms) * 1000 if response_time_ms > 0 else 0

        return {
            'success': True,
            'type': prompt_type,
            'question': question,
            'response_time_ms': response_time_ms,
            'output_tokens': output_tokens,
            'tokens_per_second': tokens_per_second,
            'response_preview': content[:100] + "..." if len(content) > 100 else content
        }

    except Exception as e:
        end_time = time.time()
        return {
            'success': False,
            'type': prompt_type,
            'question': question,
            'response_time_ms': (end_time - start_time) * 1000,
            'output_tokens': 0,
            'tokens_per_second': 0,
            'error': str(e)
        }


async def main():
    print("=" * 70)
    print("ğŸš€ Geminiæ¨¡å‹å¿«é€Ÿæµ‹è¯• (1æ–‡æœ¬ + 1å›¾ç‰‡)")
    print("=" * 70)

    # æ£€æŸ¥APIå¯†é’¥
    if not settings.openai_api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY")
        return 1

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = GeminiTester(
        api_key=settings.openai_api_key,
        model=settings.openai_model,
        base_url=settings.openai_base_url,
        timeout=60
    )

    print(f"\nğŸ“Œ æ¨¡å‹: {tester.model_name}")
    print(f"   API: {tester.get_api_url()}")

    # åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆä½¿ç”¨base64ç‰ˆæœ¬ï¼‰
    prompts_file = os.path.join(
        os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))),
        'benchmark_prompts_20_base64.json'
    )

    prompts = load_test_prompts(prompts_file)
    print(f"\nğŸ“ åŠ è½½äº† {len(prompts)} ä¸ªæµ‹è¯•prompt")

    # è¿è¡Œæµ‹è¯•
    results = []
    for prompt in prompts:
        result = await run_single_test(tester, prompt)
        results.append(result)

        # å°†ç»“æœæ·»åŠ åˆ°testerä¸­ï¼Œè¿™æ ·save_resultså¯ä»¥è®¿é—®
        from speed_tests.base_tester import TestResult
        tester_result = TestResult(
            model_name=tester.model_name,
            prompt_id=prompt.get('id', 0),
            prompt_type=result['type'],
            response_time_ms=result['response_time_ms'],
            input_tokens=0,  # å¿«é€Ÿæµ‹è¯•ä¸è®¡ç®—è¾“å…¥token
            output_tokens=result['output_tokens'],
            tokens_per_second=result['tokens_per_second'],
            success=result['success'],
            error_message=result.get('error')
        )
        tester.results.append(tester_result)

        await asyncio.sleep(1)  # è¯·æ±‚é—´éš”

    # æ‰“å°ç»Ÿè®¡
    print_detailed_stats(results)

    # ä¿å­˜ç»“æœï¼ˆä½¿ç”¨base_testerçš„save_resultsæ–¹æ³•ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"gemini_quick_test_{timestamp}.json"

    # ä½¿ç”¨base_testerçš„save_resultsæ–¹æ³•ä¿å­˜å®Œæ•´ç»Ÿè®¡
    tester.save_results(output_file)

    print("\nâœ… æµ‹è¯•å®Œæˆ!")
    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
