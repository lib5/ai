#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµå¼æµ‹è¯•åŸºç±»æ¨¡å—
ä¸“é—¨ç”¨äºæµ‹è¯•æ¨¡å‹æµå¼è¿”å›çš„é¦–tokené€Ÿåº¦ (TTFT)
"""

import json
import time
import asyncio
import aiohttp
import statistics
import numpy as np
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Dict, List, Any, Optional, AsyncGenerator
from dataclasses import dataclass, asdict
import logging


@dataclass
class StreamTestResult:
    """æµå¼æµ‹è¯•ç»“æœæ•°æ®ç±»"""

    model_name: str
    prompt_id: int
    prompt_type: str

    # æ ¸å¿ƒæ€§èƒ½æŒ‡æ ‡
    ttft_ms: float  # é¦–tokenæ—¶é—´ (Time To First Token)
    total_response_time_ms: float  # æ€»å“åº”æ—¶é—´
    total_tokens: int  # æ€»tokenæ•°
    tokens_per_second: float  # tokenç”Ÿæˆé€Ÿåº¦

    # è¯¦ç»†æ—¶é—´ç»Ÿè®¡
    request_sent_time: str  # è¯·æ±‚å‘é€æ—¶é—´
    first_token_time: str  # é¦–tokenæ¥æ”¶æ—¶é—´
    last_token_time: str  # æœ€åä¸€ä¸ªtokenæ¥æ”¶æ—¶é—´

    success: bool
    error_message: Optional[str] = None

    # æµå¼æ•°æ®
    stream_chunks: Optional[List[Dict]] = None  # æµå¼æ•°æ®å—
    raw_response: Optional[Dict] = None


class BaseStreamTester(ABC):
    """
    æµå¼æµ‹è¯•å™¨æŠ½è±¡åŸºç±»

    ä¸“é—¨ç”¨äºæµ‹è¯•æ¨¡å‹çš„æµå¼å“åº”æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯é¦–tokené€Ÿåº¦
    """

    def __init__(self, model_name: str, api_key: str, **kwargs):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨

        Args:
            model_name: æ¨¡å‹åç§°
            api_key: APIå¯†é’¥
            **kwargs: å…¶ä»–é…ç½®å‚æ•°
        """
        self.model_name = model_name
        self.api_key = api_key
        self.base_url = kwargs.get('base_url', '')
        self.headers = kwargs.get('headers', {})
        self.model = kwargs.get('model', model_name)
        self.timeout = kwargs.get('timeout', 60)
        self.results: List[StreamTestResult] = []
        self.logger = logging.getLogger(self.__class__.__name__)

    @abstractmethod
    async def chat_completion_stream(self, messages: List[Dict]) -> AsyncGenerator[str, None]:
        """
        å‘é€æµå¼èŠå¤©è¯·æ±‚å¹¶è¿”å›æ•°æ®æµ

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Yields:
            æµå¼æ•°æ®å— (SSEæ ¼å¼æˆ–JSONæ ¼å¼)
        """
        pass

    @abstractmethod
    def extract_content_from_chunk(self, chunk: str) -> str:
        """
        ä»æµå¼æ•°æ®å—ä¸­æå–æ–‡æœ¬å†…å®¹

        Args:
            chunk: æµå¼æ•°æ®å—

        Returns:
            æå–çš„æ–‡æœ¬å†…å®¹
        """
        pass

    def get_api_url(self) -> str:
        """
        è·å–APIç«¯ç‚¹URL

        å­ç±»å¿…é¡»é‡å†™æ­¤æ–¹æ³•

        Returns:
            APIç«¯ç‚¹URL
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç° get_api_url æ–¹æ³•")

    def parse_complete_prompt(self, complete_prompt_str: str) -> List[Dict]:
        """
        è§£æcomplete_promptå­—ç¬¦ä¸²ä¸ºæ¶ˆæ¯åˆ—è¡¨

        Args:
            complete_prompt_str: JSONå­—ç¬¦ä¸²æ ¼å¼çš„prompt

        Returns:
            è§£æåçš„æ¶ˆæ¯åˆ—è¡¨
        """
        try:
            # å¦‚æœå·²ç»æ˜¯listï¼Œç›´æ¥è¿”å›
            if isinstance(complete_prompt_str, list):
                return complete_prompt_str
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè§£æJSON
            messages = json.loads(complete_prompt_str)
            return messages
        except Exception as e:
            self.logger.warning(f"è§£æpromptå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤æ¶ˆæ¯")
            return [{"role": "user", "content": str(complete_prompt_str)[:100]}]

    async def test_single_prompt_stream(self, prompt: Dict) -> StreamTestResult:
        """
        æµ‹è¯•å•ä¸ªpromptçš„æµå¼å“åº”

        Args:
            prompt: promptæ•°æ®

        Returns:
            æµå¼æµ‹è¯•ç»“æœ
        """
        prompt_id = prompt.get('id', 0)
        prompt_type = prompt.get('type', 'text')

        try:
            # è§£ææ¶ˆæ¯
            messages = self.parse_complete_prompt(prompt['complete_prompt'])

            # è®°å½•è¯·æ±‚å‘é€æ—¶é—´
            request_sent_time = datetime.now()
            request_sent_iso = request_sent_time.isoformat()

            first_token_received = False
            first_token_time = None
            last_token_time = None
            total_content = ""
            stream_chunks = []

            # å¼€å§‹æµå¼è¯·æ±‚
            async for chunk in self.chat_completion_stream(messages):
                chunk_time = datetime.now()

                # æå–å†…å®¹
                content = self.extract_content_from_chunk(chunk)
                if content:
                    # è®°å½•é¦–tokenæ—¶é—´ï¼ˆåªæœ‰å½“contentä¸ä¸ºç©ºä¸”ä¸æ˜¯ç¬¬ä¸€æ¬¡è®°å½•æ—¶ï¼‰
                    if not first_token_received:
                        first_token_time = chunk_time
                        first_token_received = True

                    # å¦‚æœcontentå¾ˆé•¿ï¼Œå¯èƒ½ä¸æ˜¯çœŸæ­£çš„"é¦–å­—ç¬¦"
                    # å°è¯•è¿›ä¸€æ­¥ç»†åˆ†ä¸ºæ›´å°çš„å—
                    if len(content) > 100 and not hasattr(self, '_detailed_timing'):
                        self.logger.info(f"æ£€æµ‹åˆ°å¤§å†…å®¹chunk: {len(content)} å­—ç¬¦")
                        self.logger.info(f"å†…å®¹é¢„è§ˆ: {content[:200]}...")

                    total_content += content
                    last_token_time = chunk_time

                # ä¿å­˜æµå¼å—ä¿¡æ¯
                stream_chunks.append({
                    "timestamp": chunk_time.isoformat(),
                    "content": content,
                    "chunk": chunk
                })

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            if first_token_time and request_sent_time:
                ttft_ms = (first_token_time - request_sent_time).total_seconds() * 1000
            else:
                ttft_ms = 0

            if last_token_time and request_sent_time:
                total_response_time_ms = (last_token_time - request_sent_time).total_seconds() * 1000
            else:
                total_response_time_ms = 0

            total_tokens = len(total_content.split())
            tokens_per_second = (total_tokens / total_response_time_ms * 1000) if total_response_time_ms > 0 else 0

            return StreamTestResult(
                model_name=self.model_name,
                prompt_id=prompt_id,
                prompt_type=prompt_type,
                ttft_ms=ttft_ms,
                total_response_time_ms=total_response_time_ms,
                total_tokens=total_tokens,
                tokens_per_second=tokens_per_second,
                request_sent_time=request_sent_iso,
                first_token_time=first_token_time.isoformat() if first_token_time else None,
                last_token_time=last_token_time.isoformat() if last_token_time else None,
                success=True,
                stream_chunks=stream_chunks
            )

        except Exception as e:
            self.logger.error(f"æµå¼æµ‹è¯•å¤±è´¥ (ID: {prompt_id}): {e}")

            return StreamTestResult(
                model_name=self.model_name,
                prompt_id=prompt_id,
                prompt_type=prompt_type,
                ttft_ms=0,
                total_response_time_ms=0,
                total_tokens=0,
                tokens_per_second=0,
                request_sent_time=datetime.now().isoformat(),
                first_token_time=None,
                last_token_time=None,
                success=False,
                error_message=str(e)
            )

    async def run_stream_test(self,
                              prompts: List[Dict],
                              delay_between_requests: float = 2.0) -> List[StreamTestResult]:
        """
        è¿è¡Œæµå¼æ¨¡å‹æµ‹è¯•

        Args:
            prompts: promptåˆ—è¡¨
            delay_between_requests: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰

        Returns:
            æµå¼æµ‹è¯•ç»“æœåˆ—è¡¨
        """
        self.logger.info(f"ğŸš€ å¼€å§‹æµå¼æµ‹è¯•æ¨¡å‹: {self.model_name}")
        self.logger.info(f"ğŸ“Š æµ‹è¯•promptsæ•°é‡: {len(prompts)}")

        # ä¸ºæ¯ä¸ªpromptæ·»åŠ æ—¶é—´æˆ³
        for prompt in prompts:
            prompt['timestamp'] = datetime.now().isoformat()

        results = []
        for i, prompt in enumerate(prompts, 1):
            prompt_start_time = datetime.now()
            self.logger.info(f"[{prompt_start_time.strftime('%Y-%m-%d %H:%M:%S')}] [{i}/{len(prompts)}] æµ‹è¯•prompt ID: {prompt['id']}")

            result = await self.test_single_prompt_stream(prompt)
            results.append(result)
            self.results.append(result)

            # å»¶è¿Ÿé¿å…APIé™åˆ¶
            if delay_between_requests > 0:
                await asyncio.sleep(delay_between_requests)

            # æ˜¾ç¤ºç»“æœ
            if result.success:
                self.logger.info(
                    f"    âœ… TTFT: {result.ttft_ms:.0f}ms | "
                    f"æ€»æ—¶é—´: {result.total_response_time_ms:.0f}ms | "
                    f"Token: {result.total_tokens} | "
                    f"é€Ÿåº¦: {result.tokens_per_second:.1f} tok/s"
                )
            else:
                error_msg = result.error_message[:50] + "..." if result.error_message and len(result.error_message) > 50 else result.error_message
                self.logger.error(f"    âŒ é”™è¯¯: {error_msg}")

        return results

    def calculate_statistics(self) -> Dict[str, Any]:
        """
        è®¡ç®—æµå¼æµ‹è¯•ç»Ÿè®¡æŒ‡æ ‡

        Returns:
            ç»Ÿè®¡ç»“æœå­—å…¸
        """
        successful_results = [r for r in self.results if r.success]

        if not successful_results:
            return {"error": f"æ¨¡å‹ {self.model_name} æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ"}

        # æ•´ä½“ç»Ÿè®¡
        ttft_times = [r.ttft_ms for r in successful_results]
        response_times = [r.total_response_time_ms for r in successful_results]
        tokens_per_second = [r.tokens_per_second for r in successful_results]
        total_tokens = [r.total_tokens for r in successful_results]

        # æŒ‰ç±»å‹åˆ†ç±»ç»Ÿè®¡
        text_results = [r for r in successful_results if r.prompt_type == 'text']
        image_results = [r for r in successful_results if r.prompt_type == 'image']

        stats = {
            "model_name": self.model_name,
            "total_tests": len(self.results),
            "successful_tests": len(successful_results),
            "failed_tests": len(self.results) - len(successful_results),

            # TTFTç»Ÿè®¡
            "ttft_ms": {
                "mean": round(statistics.mean(ttft_times), 2),
                "median": round(statistics.median(ttft_times), 2),
                "min": round(min(ttft_times), 2),
                "max": round(max(ttft_times), 2),
                "p80": round(np.percentile(ttft_times, 80), 2),
                "p90": round(np.percentile(ttft_times, 90), 2),
                "p99": round(np.percentile(ttft_times, 99), 2),
            },

            # æ€»å“åº”æ—¶é—´ç»Ÿè®¡
            "total_response_time_ms": {
                "mean": round(statistics.mean(response_times), 2),
                "median": round(statistics.median(response_times), 2),
                "min": round(min(response_times), 2),
                "max": round(max(response_times), 2),
                "p80": round(np.percentile(response_times, 80), 2),
                "p90": round(np.percentile(response_times, 90), 2),
                "p99": round(np.percentile(response_times, 99), 2),
            },

            # Tokenç”Ÿæˆé€Ÿåº¦ç»Ÿè®¡
            "tokens_per_second": {
                "mean": round(statistics.mean(tokens_per_second), 2),
                "median": round(statistics.median(tokens_per_second), 2),
                "min": round(min(tokens_per_second), 2),
                "max": round(max(tokens_per_second), 2),
                "p80": round(np.percentile(tokens_per_second, 80), 2),
                "p90": round(np.percentile(tokens_per_second, 90), 2),
                "p99": round(np.percentile(tokens_per_second, 99), 2),
            },

            # æ€»tokenæ•°ç»Ÿè®¡
            "total_tokens": {
                "mean": round(statistics.mean(total_tokens), 2),
                "median": round(statistics.median(total_tokens), 2),
                "min": min(total_tokens),
                "max": max(total_tokens),
            }
        }

        # æ·»åŠ æ–‡æœ¬ç±»å‹ç»Ÿè®¡
        if text_results:
            text_ttft = [r.ttft_ms for r in text_results]
            text_response_time = [r.total_response_time_ms for r in text_results]
            text_tokens_per_second = [r.tokens_per_second for r in text_results]
            text_total_tokens = [r.total_tokens for r in text_results]

            stats["text_type"] = {
                "count": len(text_results),
                "ttft_ms": {
                    "mean": round(statistics.mean(text_ttft), 2),
                    "median": round(statistics.median(text_ttft), 2),
                    "min": round(min(text_ttft), 2),
                    "max": round(max(text_ttft), 2),
                },
                "total_response_time_ms": {
                    "mean": round(statistics.mean(text_response_time), 2),
                    "median": round(statistics.median(text_response_time), 2),
                    "min": round(min(text_response_time), 2),
                    "max": round(max(text_response_time), 2),
                },
                "tokens_per_second": {
                    "mean": round(statistics.mean(text_tokens_per_second), 2),
                    "median": round(statistics.median(text_tokens_per_second), 2),
                    "min": round(min(text_tokens_per_second), 2),
                    "max": round(max(text_tokens_per_second), 2),
                },
                "total_tokens": {
                    "mean": round(statistics.mean(text_total_tokens), 2),
                    "median": round(statistics.median(text_total_tokens), 2),
                    "min": min(text_total_tokens),
                    "max": max(text_total_tokens),
                }
            }

        # æ·»åŠ å›¾ç‰‡ç±»å‹ç»Ÿè®¡
        if image_results:
            image_ttft = [r.ttft_ms for r in image_results]
            image_response_time = [r.total_response_time_ms for r in image_results]
            image_tokens_per_second = [r.tokens_per_second for r in image_results]
            image_total_tokens = [r.total_tokens for r in image_results]

            stats["image_type"] = {
                "count": len(image_results),
                "ttft_ms": {
                    "mean": round(statistics.mean(image_ttft), 2),
                    "median": round(statistics.median(image_ttft), 2),
                    "min": round(min(image_ttft), 2),
                    "max": round(max(image_ttft), 2),
                },
                "total_response_time_ms": {
                    "mean": round(statistics.mean(image_response_time), 2),
                    "median": round(statistics.median(image_response_time), 2),
                    "min": round(min(image_response_time), 2),
                    "max": round(max(image_response_time), 2),
                },
                "tokens_per_second": {
                    "mean": round(statistics.mean(image_tokens_per_second), 2),
                    "median": round(statistics.median(image_tokens_per_second), 2),
                    "min": round(min(image_tokens_per_second), 2),
                    "max": round(max(image_tokens_per_second), 2),
                },
                "total_tokens": {
                    "mean": round(statistics.mean(image_total_tokens), 2),
                    "median": round(statistics.median(image_total_tokens), 2),
                    "min": min(image_total_tokens),
                    "max": max(image_total_tokens),
                }
            }

        return stats

    def print_statistics(self):
        """
        æ‰“å°æµå¼æµ‹è¯•ç»Ÿè®¡ç»“æœ
        """
        stats = self.calculate_statistics()

        if "error" in stats:
            print(f"\nâŒ {stats['error']}")
            return

        print(f"\nğŸ“Š {stats['model_name']} æµå¼æµ‹è¯•ç»Ÿè®¡ç»“æœ:")
        print(f"  æ€»æµ‹è¯•: {stats['total_tests']} | æˆåŠŸ: {stats['successful_tests']} | å¤±è´¥: {stats['failed_tests']}")

        # TTFTç»Ÿè®¡
        ttft = stats['ttft_ms']
        print(f"\nâš¡ é¦–Tokenæ—¶é—´ (TTFT) (ms):")
        print(f"  å‡å€¼: {ttft['mean']} | ä¸­ä½æ•°: {ttft['median']} | æœ€å°: {ttft['min']} | æœ€å¤§: {ttft['max']}")
        print(f"  P80: {ttft['p80']} | P90: {ttft['p90']} | P99: {ttft['p99']}")

        # æ€»å“åº”æ—¶é—´ç»Ÿè®¡
        total_rt = stats['total_response_time_ms']
        print(f"\nâ±ï¸ æ€»å“åº”æ—¶é—´ (ms):")
        print(f"  å‡å€¼: {total_rt['mean']} | ä¸­ä½æ•°: {total_rt['median']} | æœ€å°: {total_rt['min']} | æœ€å¤§: {total_rt['max']}")
        print(f"  P80: {total_rt['p80']} | P90: {total_rt['p90']} | P99: {total_rt['p99']}")

        # Tokenç”Ÿæˆé€Ÿåº¦ç»Ÿè®¡
        tps = stats['tokens_per_second']
        print(f"\nğŸš€ Tokenç”Ÿæˆé€Ÿåº¦ (tokens/s):")
        print(f"  å‡å€¼: {tps['mean']} | ä¸­ä½æ•°: {tps['median']} | æœ€å°: {tps['min']} | æœ€å¤§: {tps['max']}")
        print(f"  P80: {tps['p80']} | P90: {tps['p90']} | P99: {tps['p99']}")

        # æ€»tokenæ•°ç»Ÿè®¡
        tokens = stats['total_tokens']
        print(f"\nğŸ“ è¾“å‡ºTokenæ•°é‡:")
        print(f"  å‡å€¼: {tokens['mean']} | ä¸­ä½æ•°: {tokens['median']} | æœ€å°: {tokens['min']} | æœ€å¤§: {tokens['max']}")

        # æ–‡æœ¬ç±»å‹ç»Ÿè®¡
        if "text_type" in stats:
            text_stats = stats["text_type"]
            print(f"\nğŸ“ æ–‡æœ¬ç±»å‹ (æ— å›¾ç‰‡) - {text_stats['count']}ä¸ªæµ‹è¯•:")
            ttft = text_stats['ttft_ms']
            print(f"  TTFT: å‡å€¼{ttft['mean']}ms | ä¸­ä½æ•°{ttft['median']}ms | æœ€å°{ttft['min']}ms | æœ€å¤§{ttft['max']}ms")
            rt = text_stats['total_response_time_ms']
            print(f"  å“åº”æ—¶é—´: å‡å€¼{rt['mean']}ms | ä¸­ä½æ•°{rt['median']}ms | æœ€å°{rt['min']}ms | æœ€å¤§{rt['max']}ms")
            tps = text_stats['tokens_per_second']
            print(f"  Tokené€Ÿåº¦: å‡å€¼{tps['mean']} tok/s | ä¸­ä½æ•°{tps['median']} tok/s | æœ€å°{tps['min']} tok/s | æœ€å¤§{tps['max']} tok/s")

        # å›¾ç‰‡ç±»å‹ç»Ÿè®¡
        if "image_type" in stats:
            image_stats = stats["image_type"]
            print(f"\nğŸ“¸ å›¾ç‰‡ç±»å‹ (æœ‰å›¾ç‰‡) - {image_stats['count']}ä¸ªæµ‹è¯•:")
            ttft = image_stats['ttft_ms']
            print(f"  TTFT: å‡å€¼{ttft['mean']}ms | ä¸­ä½æ•°{ttft['median']}ms | æœ€å°{ttft['min']}ms | æœ€å¤§{ttft['max']}ms")
            rt = image_stats['total_response_time_ms']
            print(f"  å“åº”æ—¶é—´: å‡å€¼{rt['mean']}ms | ä¸­ä½æ•°{rt['median']}ms | æœ€å°{rt['min']}ms | æœ€å¤§{rt['max']}ms")
            tps = image_stats['tokens_per_second']
            print(f"  Tokené€Ÿåº¦: å‡å€¼{tps['mean']} tok/s | ä¸­ä½æ•°{tps['median']} tok/s | æœ€å°{tps['min']} tok/s | æœ€å¤§{tps['max']} tok/s")

    def save_results(self, filename: str):
        """
        ä¿å­˜æµå¼æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶

        Args:
            filename: è¾“å‡ºæ–‡ä»¶å
        """
        # ä¿å­˜è¯¦ç»†ç»“æœ
        detailed_results = [asdict(r) for r in self.results]

        output = {
            "test_info": {
                "timestamp": datetime.now().isoformat(),
                "model_name": self.model_name,
                "test_type": "stream_ttft_test",
                "total_results": len(self.results),
                "successful_results": len([r for r in self.results if r.success]),
                "failed_results": len([r for r in self.results if not r.success]),
            },
            "detailed_results": detailed_results
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)

        # è®¡ç®—ç»Ÿè®¡ç»“æœ
        statistics = self.calculate_statistics()

        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats_output = {
            "test_info": output["test_info"],
            "statistics": statistics
        }

        stats_filename = filename.replace('.json', '_stats.json')
        with open(stats_filename, 'w', encoding='utf-8') as f:
            json.dump(stats_output, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ æµå¼æµ‹è¯•ç»“æœå·²ä¿å­˜:")
        print(f"  â€¢ è¯¦ç»†ç»“æœ: {filename}")
        print(f"  â€¢ ç»Ÿè®¡ç»“æœ: {stats_filename}")

        # æ‰“å°ç»Ÿè®¡ç»“æœ
        self.print_statistics()
