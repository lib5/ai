#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰€æœ‰æ¨¡å‹æµå¼æµ‹è¯•è„šæœ¬
ç»Ÿä¸€æµ‹è¯•è±†åŒ…ã€Geminiç­‰æ¨¡å‹çš„TTFTæ€§èƒ½

ä½¿ç”¨æ–¹æ³•:
1. python test_all_stream.py --model doubao
2. python test_all_stream.py --model gemini
3. python test_all_stream.py --model all
"""

import os
import sys
import asyncio
import argparse
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config import settings
from stream_tests.doubao.stream_adapter import DoubaoStreamTester
from stream_tests.gemini.stream_adapter import GeminiStreamTester
from stream_tests.qwen.stream_adapter import QwenStreamTester
from stream_tests.gpt4.stream_adapter import GPT4StreamTester


async def load_prompts(file_path: str):
    """åŠ è½½æµ‹è¯•prompts"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        prompts = data['prompts']
        all_prompts = [p for p in prompts if p.get('type') in ['text', 'image']]
        return all_prompts
    except Exception as e:
        print(f"âŒ é”™è¯¯: åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
        return None


async def test_model(model_name: str, prompts: list, delay: float):
    """æµ‹è¯•æŒ‡å®šæ¨¡å‹"""
    tester = None

    if model_name.lower() == 'doubao':
        if not settings.doubao_api_key:
            print("âŒ è±†åŒ…APIå¯†é’¥æœªè®¾ç½®")
            return None

        tester = DoubaoStreamTester(
            api_key=settings.doubao_api_key,
            model=settings.doubao_model,
            base_url=settings.doubao_base_url,
            timeout=settings.doubao_timeout
        )

    elif model_name.lower() == 'gemini':
        if not settings.openai_api_key:
            print("âŒ Gemini APIå¯†é’¥æœªè®¾ç½®")
            return None

        tester = GeminiStreamTester(
            api_key=settings.openai_api_key,
            model=settings.openai_model,
            base_url=settings.openai_base_url,
            timeout=60
        )

    elif model_name.lower() == 'qwen':
        qwen_api_key = os.getenv("QWEN_API_KEY") or settings.qwen_api_key
        if not qwen_api_key:
            print("âŒ Qwen APIå¯†é’¥æœªè®¾ç½®")
            return None

        tester = QwenStreamTester(
            api_key=qwen_api_key,
            model='qwen3-vl-plus',
            timeout=60
        )

    elif model_name.lower() == 'gpt4':
        if not settings.azure_openai_api_key:
            print("âŒ Azure OpenAI APIå¯†é’¥æœªè®¾ç½®")
            return None

        tester = GPT4StreamTester(
            api_key=settings.azure_openai_api_key,
            deployment_name='gpt-4.1',
            endpoint=settings.azure_openai_endpoint,
            api_version=settings.azure_openai_api_version,
            timeout=30
        )

    if tester is None:
        print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
        return None

    print(f"\n{'='*60}")
    print(f"ğŸš€ å¼€å§‹æµ‹è¯• {model_name}")
    print(f"{'='*60}")

    await tester.run_stream_test(prompts, delay_between_requests=delay)

    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"{model_name}_stream_test_{timestamp}.json"
    tester.save_results(output_file)

    return tester


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ æ‰€æœ‰æ¨¡å‹æµå¼æµ‹è¯• (TTFT)")
    print("=" * 60)

    parser = argparse.ArgumentParser(
        description="æ‰€æœ‰æ¨¡å‹TTFTæµ‹è¯•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æµ‹è¯•è±†åŒ…
  python test_all_stream.py --model doubao

  # æµ‹è¯•Gemini
  python test_all_stream.py --model gemini

  # æµ‹è¯•Qwen
  python test_all_stream.py --model qwen

  # æµ‹è¯•GPT-4
  python test_all_stream.py --model gpt4

  # æµ‹è¯•æ‰€æœ‰å¯ç”¨æ¨¡å‹
  python test_all_stream.py --model all

  # ä½¿ç”¨è‡ªå®šä¹‰æµ‹è¯•æ•°æ®
  python test_all_stream.py --model doubao --prompts my_prompts.json
        """
    )

    parser.add_argument(
        '--model',
        type=str,
        required=True,
        choices=['doubao', 'gemini', 'qwen', 'gpt4', 'all'],
        help='è¦æµ‹è¯•çš„æ¨¡å‹'
    )

    parser.add_argument(
        '--prompts',
        type=str,
        default='benchmark_prompts_20_base64.json',
        help='æµ‹è¯•æ•°æ®æ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--delay',
        type=float,
        default=2.0,
        help='è¯·æ±‚é—´éš”æ—¶é—´ï¼Œå•ä½ç§’'
    )

    args = parser.parse_args()

    # åŠ è½½æµ‹è¯•æ•°æ®
    prompts = await load_prompts(args.prompts)
    if prompts is None:
        return 1

    print(f"\nğŸ“ æµ‹è¯•æ•°æ®: {args.prompts}")
    print(f"ğŸ“Š æµ‹è¯•prompts: {len(prompts)}")

    # ç¡®å®šè¦æµ‹è¯•çš„æ¨¡å‹
    models_to_test = []
    if args.model == 'all':
        models_to_test = ['doubao', 'gemini', 'qwen', 'gpt4']
    else:
        models_to_test = [args.model]

    results = {}
    for model in models_to_test:
        result = await test_model(model, prompts, args.delay)
        if result:
            results[model] = result

    # æ‰“å°æ€»ç»“
    print(f"\n{'='*60}")
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
    print(f"{'='*60}")

    if results:
        print("\nğŸ“Š æ¨¡å‹TTFTå¯¹æ¯”:")
        for model, tester in results.items():
            stats = tester.calculate_statistics()
            if 'ttft_ms' in stats:
                ttft = stats['ttft_ms']
                print(f"\n{model.upper()}:")
                print(f"  TTFTå‡å€¼: {ttft['mean']:.2f}ms")
                print(f"  TTFTä¸­ä½æ•°: {ttft['median']:.2f}ms")
                print(f"  TTFTæœ€å°: {ttft['min']:.2f}ms")
                print(f"  TTFTæœ€å¤§: {ttft['max']:.2f}ms")

    return 0


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
